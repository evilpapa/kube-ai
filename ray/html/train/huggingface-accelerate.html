
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>开始使用 Hugging Face Accelerate &#8212; Ray 2.7.2</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/versionwarning.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../_static/js/docsearch.js"></script>
    <script defer="defer" src="../_static/js/csat.js"></script>
    <script defer="defer" src="../_static/js/termynal.js"></script>
    <script defer="defer" src="../_static/js/custom.js"></script>
    <script defer="defer" src="../_static/js/top-navigation.js"></script>
    <script src="../_static/js/tags.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/train/huggingface-accelerate.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DeepSpeed 入门" href="deepspeed.html" />
    <link rel="prev" title="更多框架" href="more-frameworks.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
  data-modal-disclaimer = "Results are automated and may be incorrect or contain inappropriate information. Do not include any personal data or confidential information."
  data-modal-title = "Ray Docs AI - Ask a Question"
  data-button-position-bottom = "60px"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 2.7.2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    欢迎来到 Ray ！
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/index.html">
   概述「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/getting-started.html">
   入门「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/installation.html">
   安装「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/use-cases.html">
   用例「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/examples.html">
   示例库「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/ray-libraries.html">
   生态「3%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/walkthrough.html">
   Ray 核心「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data/data.html">
   Ray 数据「85%」
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="train.html">
   Ray 训练「95%」
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="overview.html">
     概述
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-pytorch.html">
     PyTorch 指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-pytorch-lightning.html">
     PyTorch Lightning 指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-transformers.html">
     Hugging Face Transformers 指南
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="more-frameworks.html">
     更多框架
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Hugging Face Accelerate 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="deepspeed.html">
       DeepSpeed 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="distributed-tensorflow-keras.html">
       TensorFlow 和 Keras 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="distributed-xgboost-lightgbm.html">
       XGBoost 和 LightGBM 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="horovod.html">
       Horovod 指南
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="user-guides.html">
     用户指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples.html">
     示例
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="benchmarks.html">
     基准
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="api/api.html">
     Ray 训练 API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tune/index.html">
   Ray 调参「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../serve/index.html">
   Ray Serve「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rllib/index.html">
   Ray RLlib「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/index.html">
   更多类库「40%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cluster/getting-started.html">
   Ray 集群「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-observability/index.html">
   监控调试「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-references/api.html">
   参考「20%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-contribute/index.html">
   开发者指引「30%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-security/index.html">
   安全「100%」
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Ftrain/huggingface-accelerate.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/train/huggingface-accelerate.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/train/huggingface-accelerate.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   配置加速
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acceleratetrainer">
   AccelerateTrainer 迁移指南
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>开始使用 Hugging Face Accelerate</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   配置加速
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acceleratetrainer">
   AccelerateTrainer 迁移指南
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="hugging-face-accelerate">
<span id="train-hf-accelerate"></span><h1>开始使用 Hugging Face Accelerate<a class="headerlink" href="#hugging-face-accelerate" title="Permalink to this headline">#</a></h1>
<p><a class="reference internal" href="api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a> 可以帮助您轻松地在分布式 Ray 集群中启动 <a class="reference external" href="https://huggingface.co/docs/accelerate">Accelerate</a>  训练。</p>
<p>您只需要使用 TorchTrainer 运行现有的训练代码。最终代码如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="c1"># Instantiate the accelerator</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Prepare everything for distributed training</span>
    <span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">train_dataloader</span><span class="p">,</span>
        <span class="n">eval_dataloader</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">eval_dataloader</span><span class="p">,</span> <span class="n">lr_scheduler</span>
    <span class="p">)</span>

    <span class="c1"># Start training</span>
    <span class="o">...</span>

<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
    <span class="o">...</span>
<span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>分布式训练的模型和数据准备完全由 <a class="reference external" href="https://huggingface.co/docs/accelerate/main/en/package_reference/accelerator#accelerate.Accelerator">Accelerator</a>
对象及其 <a class="reference external" href="https://huggingface.co/docs/accelerate/main/en/package_reference/accelerator#accelerate.Accelerator.prepare">Accelerator.prepare()</a>  方法处理。</p>
<p>与原生 PyTorch、PyTorch Lightning 或 Hugging Face Transformers 不同， <strong>不要</strong> 在训练函数中
调用任何其他 Ray Train 实用程序（如 <a class="reference internal" href="api/doc/ray.train.torch.prepare_model.html#ray.train.torch.prepare_model" title="ray.train.torch.prepare_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_model()</span></code></a> 或 <a class="reference internal" href="api/doc/ray.train.torch.prepare_data_loader.html#ray.train.torch.prepare_data_loader" title="ray.train.torch.prepare_data_loader"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data_loader()</span></code></a> ）。</p>
</div>
<section id="id1">
<h2>配置加速<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p>在 Ray Train 中，您可以通过训练函数中的 <a class="reference external" href="https://huggingface.co/docs/accelerate/main/en/package_reference/accelerator#accelerate.Accelerator">accelerate.Accelerator</a>
对象设置配置。以下是配置 Accelerate 的入门示例。</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" role="tablist"><button aria-controls="panel-0-RGVlcFNwZWVk" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-RGVlcFNwZWVk" name="RGVlcFNwZWVk" role="tab" tabindex="0">DeepSpeed</button><button aria-controls="panel-0-RlNEUA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-RlNEUA==" name="RlNEUA==" role="tab" tabindex="-1">FSDP</button></div><div aria-labelledby="tab-0-RGVlcFNwZWVk" class="sphinx-tabs-panel group-tab" id="panel-0-RGVlcFNwZWVk" name="RGVlcFNwZWVk" role="tabpanel" tabindex="0"><p>例如，要使用 Accelerate 运行 DeepSpeed，请创建 <a class="reference external" href="https://huggingface.co/docs/accelerate/main/en/package_reference/deepspeed">DeepSpeedPlugin</a> 字典：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span><span class="p">,</span> <span class="n">DeepSpeedPlugin</span>

<span class="n">DEEPSPEED_CONFIG</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">},</span>
    <span class="s2">&quot;zero_optimization&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;offload_optimizer&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">False</span>
        <span class="p">},</span>
        <span class="s2">&quot;overlap_comm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;contiguous_gradients&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;reduce_bucket_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="s2">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="s2">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="s2">&quot;gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;round_robin_gradients&quot;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">},</span>
    <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="s2">&quot;gradient_clipping&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="s2">&quot;steps_per_print&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="s2">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="s2">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span> <span class="kc">False</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="c1"># Create a DeepSpeedPlugin from config dict</span>
    <span class="n">ds_plugin</span> <span class="o">=</span> <span class="n">DeepSpeedPlugin</span><span class="p">(</span><span class="n">hf_ds_config</span><span class="o">=</span><span class="n">DEEPSPEED_CONFIG</span><span class="p">)</span>

    <span class="c1"># Initialize Accelerator</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="n">deepspeed_plugin</span><span class="o">=</span><span class="n">ds_plugin</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Start training</span>
    <span class="o">...</span>

<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
    <span class="o">...</span>
<span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-RlNEUA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-RlNEUA==" name="RlNEUA==" role="tabpanel" tabindex="0"><p>对于 PyTorch FSDP，创建一个 <a class="reference external" href="https://huggingface.co/docs/accelerate/main/en/package_reference/fsdp">FullyShardedDataParallelPlugin</a>
并将其传递给加速器。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributed.fsdp.fully_sharded_data_parallel</span> <span class="kn">import</span> <span class="n">FullOptimStateDictConfig</span><span class="p">,</span> <span class="n">FullStateDictConfig</span>
<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span><span class="p">,</span> <span class="n">FullyShardedDataParallelPlugin</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="n">fsdp_plugin</span> <span class="o">=</span> <span class="n">FullyShardedDataParallelPlugin</span><span class="p">(</span>
        <span class="n">state_dict_config</span><span class="o">=</span><span class="n">FullStateDictConfig</span><span class="p">(</span>
            <span class="n">offload_to_cpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">rank0_only</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">),</span>
        <span class="n">optim_state_dict_config</span><span class="o">=</span><span class="n">FullOptimStateDictConfig</span><span class="p">(</span>
            <span class="n">offload_to_cpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">rank0_only</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Initialize accelerator</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="n">fsdp_plugin</span><span class="o">=</span><span class="n">fsdp_plugin</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Start training</span>
    <span class="o">...</span>

<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
    <span class="o">...</span>
<span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div></div>
<p>请注意，Accelerate 还提供了一个 CLI 工具，<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;accelerate</span> <span class="pre">config&quot;</span></code> ，用于生成配置并使用  <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;accelerate</span> <span class="pre">launch&quot;</span></code> 启动训练作业。
但是，这里不需要它，因为 Ray 的 <code class="xref py py-obj docutils literal notranslate"><span class="pre">TorchTrainer</span></code> 已经设置了 Torch 分布式环境并在所有 worker 上启动了训练功能。</p>
<p>接下来，请参阅下面这些端到端示例以了解更多详细信息：</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" role="tablist"><button aria-controls="panel-1-UmF5IERhdGEg5L2/55So56S65L6L" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-UmF5IERhdGEg5L2/55So56S65L6L" name="UmF5IERhdGEg5L2/55So56S65L6L" role="tab" tabindex="0">Ray Data 使用示例</button><button aria-controls="panel-1-UHlUb3JjaCBEYXRhTG9hZGVyIOS9v+eUqOekuuS+iw==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-UHlUb3JjaCBEYXRhTG9hZGVyIOS9v+eUqOekuuS+iw==" name="UHlUb3JjaCBEYXRhTG9hZGVyIOS9v+eUqOekuuS+iw==" role="tab" tabindex="-1">PyTorch DataLoader 使用示例</button></div><div aria-labelledby="tab-1-UmF5IERhdGEg5L2/55So56S65L6L" class="sphinx-tabs-panel group-tab" id="panel-1-UmF5IERhdGEg5L2/55So56S65L6L" name="UmF5IERhdGEg5L2/55So56S65L6L" role="tabpanel" tabindex="0"><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
显示代码<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Minimal Ray Train + Accelerate example adapted from</span>
<span class="sd">https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py</span>

<span class="sd">Fine-tune a BERT model with Hugging Face Accelerate and Ray Train and Ray Data</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">evaluate</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">TemporaryDirectory</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
    <span class="n">AutoTokenizer</span><span class="p">,</span>
    <span class="n">get_linear_schedule_with_warmup</span><span class="p">,</span>
    <span class="n">set_seed</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.train</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">DataConfig</span><span class="p">,</span> <span class="n">ScalingConfig</span><span class="p">,</span> <span class="n">Checkpoint</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>


<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Your training function that will be launched on each worker.&quot;&quot;&quot;</span>

    <span class="c1"># Unpack training configs</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">]</span>
    <span class="n">train_batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">]</span>
    <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;eval_batch_size&quot;</span><span class="p">]</span>
    <span class="n">train_ds_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_dataset_size&quot;</span><span class="p">]</span>

    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># Initialize accelerator</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>

    <span class="c1"># Load datasets and metrics</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;glue&quot;</span><span class="p">,</span> <span class="s2">&quot;mrpc&quot;</span><span class="p">)</span>

    <span class="c1"># Prepare Ray Data loaders</span>
    <span class="c1"># ====================================================</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">eval_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">)</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-cased&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence1&quot;</span><span class="p">]),</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence2&quot;</span><span class="p">]),</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">outputs</span>

    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">train_batch_size</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
    <span class="p">)</span>
    <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">eval_ds</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">eval_batch_size</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
    <span class="p">)</span>
    <span class="c1"># ====================================================</span>

    <span class="c1"># Instantiate the model, optimizer, lr_scheduler</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;bert-base-cased&quot;</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">train_ds_size</span> <span class="o">//</span> <span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">num_processes</span> <span class="o">*</span> <span class="n">train_batch_size</span><span class="p">)</span>
    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
        <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">num_training_steps</span><span class="o">=</span><span class="p">(</span><span class="n">steps_per_epoch</span> <span class="o">*</span> <span class="n">num_epochs</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Prepare everything with accelerator</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="c1"># Training</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
            <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Evaluation</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">eval_dataloader</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">predictions</span><span class="p">,</span> <span class="n">references</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span>
                <span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span>
                <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span>
                <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">eval_metric</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">,</span> <span class="n">eval_metric</span><span class="p">)</span>

        <span class="c1"># Report Checkpoint and metrics to Ray Train</span>
        <span class="c1"># ==========================================</span>
        <span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
                <span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                <span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">unwrapped_model</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tmpdir</span><span class="si">}</span><span class="s2">/ckpt_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.bin&quot;</span><span class="p">)</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">eval_metric</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
        <span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
        <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
        <span class="s2">&quot;eval_batch_size&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># Prepare Ray Datasets</span>
    <span class="n">hf_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;glue&quot;</span><span class="p">,</span> <span class="s2">&quot;mrpc&quot;</span><span class="p">)</span>
    <span class="n">ray_datasets</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_huggingface</span><span class="p">(</span><span class="n">hf_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]),</span>
        <span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_huggingface</span><span class="p">(</span><span class="n">hf_datasets</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]),</span>
    <span class="p">}</span>
    <span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_dataset_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ray_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
        <span class="n">train_func</span><span class="p">,</span>
        <span class="n">train_loop_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">datasets</span><span class="o">=</span><span class="n">ray_datasets</span><span class="p">,</span>
        <span class="n">dataset_config</span><span class="o">=</span><span class="n">DataConfig</span><span class="p">(</span><span class="n">datasets_to_split</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">]),</span>
        <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

</pre></div>
</div>
</div>
</details></div><div aria-labelledby="tab-1-UHlUb3JjaCBEYXRhTG9hZGVyIOS9v+eUqOekuuS+iw==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-UHlUb3JjaCBEYXRhTG9hZGVyIOS9v+eUqOekuuS+iw==" name="UHlUb3JjaCBEYXRhTG9hZGVyIOS9v+eUqOekuuS+iw==" role="tabpanel" tabindex="0"><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
显示代码<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Minimal Ray Train + Accelerate example adapted from</span>
<span class="sd">https://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py</span>

<span class="sd">Fine-tune a BERT model with Hugging Face Accelerate and Ray Train</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">evaluate</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">TemporaryDirectory</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
    <span class="n">AutoTokenizer</span><span class="p">,</span>
    <span class="n">get_linear_schedule_with_warmup</span><span class="p">,</span>
    <span class="n">set_seed</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">ray.train</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span><span class="p">,</span> <span class="n">Checkpoint</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>


<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Your training function that will be launched on each worker.&quot;&quot;&quot;</span>

    <span class="c1"># Unpack training configs</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">]</span>
    <span class="n">train_batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">]</span>
    <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;eval_batch_size&quot;</span><span class="p">]</span>

    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># Initialize accelerator</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>

    <span class="c1"># Load datasets and metrics</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;glue&quot;</span><span class="p">,</span> <span class="s2">&quot;mrpc&quot;</span><span class="p">)</span>

    <span class="c1"># Prepare PyTorch DataLoaders</span>
    <span class="c1"># ====================================================</span>
    <span class="n">hf_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;glue&quot;</span><span class="p">,</span> <span class="s2">&quot;mrpc&quot;</span><span class="p">)</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-cased&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;sentence1&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span>
            <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;sentence2&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">outputs</span>

    <span class="c1"># Instantiate dataloaders.</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">hf_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">train_batch_size</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">hf_datasets</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">eval_batch_size</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># ====================================================</span>

    <span class="c1"># Instantiate the model, optimizer, lr_scheduler</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;bert-base-cased&quot;</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
        <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">num_training_steps</span><span class="o">=</span><span class="p">(</span><span class="n">steps_per_epoch</span> <span class="o">*</span> <span class="n">num_epochs</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Prepare everything with accelerator</span>
    <span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">train_dataloader</span><span class="p">,</span>
        <span class="n">eval_dataloader</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">eval_dataloader</span><span class="p">,</span> <span class="n">lr_scheduler</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="c1"># Training</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
            <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Evaluation</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">eval_dataloader</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">predictions</span><span class="p">,</span> <span class="n">references</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span>
                <span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span>
                <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span>
                <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">eval_metric</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">,</span> <span class="n">eval_metric</span><span class="p">)</span>

        <span class="c1"># Report Checkpoint and metrics to Ray Train</span>
        <span class="c1"># ==========================================</span>
        <span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
                <span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                <span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">unwrapped_model</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tmpdir</span><span class="si">}</span><span class="s2">/ckpt_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.bin&quot;</span><span class="p">)</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">eval_metric</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
        <span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
        <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
        <span class="s2">&quot;eval_batch_size&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
        <span class="n">train_func</span><span class="p">,</span>
        <span class="n">train_loop_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

</pre></div>
</div>
</div>
</details></div></div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>如果你正在寻找更高级的用例，请查看此 Llama-2 微调示例：</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/ray-project/ray/tree/master/doc/source/templates/04_finetuning_llms_with_deepspeed">使用 Deepspeed、Accelerate 和 Ray Train 对 Llama-2 系列模型进行微调。</a></p></li>
</ul>
</div>
<p>您可能还会发现这些用户指南很有帮助：</p>
<ul class="simple">
<li><p><a class="reference internal" href="user-guides/using-gpus.html#train-scaling-config"><span class="std std-ref">配置 Scale 和 GPU</span></a></p></li>
<li><p><a class="reference internal" href="user-guides/configuration-overview.html#train-run-config"><span class="std std-ref">配置和持久存储</span></a></p></li>
<li><p><a class="reference internal" href="user-guides/checkpoints.html#train-checkpointing"><span class="std std-ref">保存和加载检查点</span></a></p></li>
<li><p><a class="reference internal" href="user-guides/data-loading-preprocessing.html#data-ingest-torch"><span class="std std-ref">如何将 Ray Data 与 Ray Train 结合使用</span></a></p></li>
</ul>
</section>
<section id="acceleratetrainer">
<h2>AccelerateTrainer 迁移指南<a class="headerlink" href="#acceleratetrainer" title="Permalink to this headline">#</a></h2>
<p>在 Ray 2.7 之前，Ray Train 的 <code class="xref py py-class docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code> 是运行 Accelerate 代码的推荐方式。
作为 <a class="reference internal" href="api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a> 的子类，
AccelerateTrainer 接收由 <code class="docutils literal notranslate"><span class="pre">accelerate</span> <span class="pre">config</span></code> 生成的配置文件并将其应用于所有 worker 。
除此之外， <code class="docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code> 的功能与 <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> 相同。</p>
<p>然而，这引起了人们的困惑，即这是否是运行 Accelerate 代码的 <em>唯一</em> 方式。
由于您可以使用和 <code class="docutils literal notranslate"><span class="pre">Accelerator</span></code> 和 <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> 组合来表达完整的 Accelerate 功能， 因此计划在 Ray 2.8 中弃用 <code class="docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code> ，
并且建议直接使用 <code class="docutils literal notranslate"><span class="pre">TorchTrainer</span></code> 来运行加速代码。</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="more-frameworks.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">更多框架</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="deepspeed.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">DeepSpeed 入门</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>谢谢你的反馈！</span>
  </div>
  <div id="csat-inputs">
    <span>是否能帮助到你？</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>是<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>否<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">反馈</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">提交</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2024, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>