
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Fine-tune dolly-v2-7b with Ray Train, PyTorch Lightning and FSDP &#8212; Ray 2.7.2</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/versionwarning.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../_static/js/docsearch.js"></script>
    <script defer="defer" src="../../../_static/js/csat.js"></script>
    <script defer="defer" src="../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../_static/js/top-navigation.js"></script>
    <script src="../../../_static/js/tags.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/train/examples/lightning/dolly_lightning_fsdp_finetuning.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
  data-modal-disclaimer = "Results are automated and may be incorrect or contain inappropriate information. Do not include any personal data or confidential information."
  data-modal-title = "Ray Docs AI - Ask a Question"
  data-button-position-bottom = "60px"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 2.7.2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    欢迎来到 Ray ！
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/index.html">
   概述「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/getting-started.html">
   入门「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/installation.html">
   安装「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/use-cases.html">
   用例「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/examples.html">
   示例库「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/ray-libraries.html">
   生态「3%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/walkthrough.html">
   Ray 核心「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data/data.html">
   Ray 数据「85%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../train.html">
   Ray 训练「95%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../tune/index.html">
   Ray 调参「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../serve/index.html">
   Ray Serve「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rllib/index.html">
   Ray RLlib「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/index.html">
   更多类库「40%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cluster/getting-started.html">
   Ray 集群「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-observability/index.html">
   监控调试「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-references/api.html">
   参考「20%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-contribute/index.html">
   开发者指引「30%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-security/index.html">
   安全「100%」
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Ftrain/examples/lightning/dolly_lightning_fsdp_finetuning.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/train/examples/lightning/dolly_lightning_fsdp_finetuning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/train/examples/lightning/dolly_lightning_fsdp_finetuning.ipynb.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#set-up-ray-cluster">
   Set up ray cluster
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prepare-your-data">
   Prepare your data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-your-lightning-model">
   Define your lightning model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#configure-your-fsdp-strategy">
   Configure your FSDP strategy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fine-tune-with-ray-torchtrainer">
   Fine-tune with Ray TorchTrainer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-generation-with-huggingface-pipeline">
   Text-generation with HuggingFace Pipeline
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Fine-tune dolly-v2-7b with Ray Train, PyTorch Lightning and FSDP</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#set-up-ray-cluster">
   Set up ray cluster
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prepare-your-data">
   Prepare your data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-your-lightning-model">
   Define your lightning model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#configure-your-fsdp-strategy">
   Configure your FSDP strategy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fine-tune-with-ray-torchtrainer">
   Fine-tune with Ray TorchTrainer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-generation-with-huggingface-pipeline">
   Text-generation with HuggingFace Pipeline
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="fine-tune-dolly-v2-7b-with-ray-train-pytorch-lightning-and-fsdp">
<span id="dolly-lightning-fsdp-finetuning"></span><h1>Fine-tune <code class="docutils literal notranslate"><span class="pre">dolly-v2-7b</span></code> with Ray Train, PyTorch Lightning and FSDP<a class="headerlink" href="#fine-tune-dolly-v2-7b-with-ray-train-pytorch-lightning-and-fsdp" title="Permalink to this headline">#</a></h1>
<p>In this example, we demonstrate how to use Ray Train to fine-tune a <a class="reference external" href="https://huggingface.co/databricks/dolly-v2-7b"><code class="docutils literal notranslate"><span class="pre">dolly-v2-7b</span></code></a> model. <code class="docutils literal notranslate"><span class="pre">dolly-v2-7b</span></code> is a 7 billion parameter causal language model created by Databricks, derived from EleutherAI’s <a class="reference external" href="https://huggingface.co/EleutherAI/pythia-6.9b">Pythia-6.9b</a>, and fine-tuned on a <a class="reference external" href="https://github.com/databrickslabs/dolly/tree/master/data">~15K record instruction corpus</a>.</p>
<p>We load the pre-trained model from the HuggingFace model hub into a LightningModule and launch an FSDP fine-tuning job across 16 T4 GPUs with the help of <a class="reference internal" href="../../api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ray</span> <span class="pre">TorchTrainer</span></code></a>. It is also straightforward to fine-tune other similar large language models in a similar manner as shown in this example.</p>
<p>Before starting this example, we highly recommend reading <a class="reference internal" href="../../overview.html#train-key-concepts"><span class="std std-ref">Ray Train Key Concepts</span></a> and <a class="reference internal" href="../../../data/key-concepts.html#data-key-concepts"><span class="std std-ref">Ray Data Key Concepts</span></a>.</p>
<section id="set-up-ray-cluster">
<h2>Set up ray cluster<a class="headerlink" href="#set-up-ray-cluster" title="Permalink to this headline">#</a></h2>
<p>In this example, we are using a Ray cluster with a <code class="docutils literal notranslate"><span class="pre">g4dn.8xlarge</span></code> head node and 15 <code class="docutils literal notranslate"><span class="pre">g4dn.4xlarge</span></code> worker nodes. Each instance has one Tesla T4 GPU (16GiB Memory).</p>
<p>We define a <code class="docutils literal notranslate"><span class="pre">runtime_env</span></code> to install the necessary Python libraries on each node. You can skip this step if you have already installed all the required packages in your workers’ base image. We tested this example with <code class="docutils literal notranslate"><span class="pre">pytorch_lightning==2.0.2</span></code> and <code class="docutils literal notranslate"><span class="pre">transformers==4.29.2</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>

<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">runtime_env</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;pip&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;datasets&quot;</span><span class="p">,</span>
            <span class="s2">&quot;evaluate&quot;</span><span class="p">,</span>
            <span class="s2">&quot;transformers&gt;=4.26.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;torch&gt;=1.12.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pytorch_lightning&gt;=2.0&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;databricks/dolly-v2-7b&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="prepare-your-data">
<h2>Prepare your data<a class="headerlink" href="#prepare-your-data" title="Permalink to this headline">#</a></h2>
<p>We are using tiny_shakespeare for fine-tuning, which contains 40,000 lines of Shakespeare from a variety of Shakespeare’s plays. Featured in Andrej Karpathy’s blog post <a class="reference external" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">‘The Unreasonable Effectiveness of Recurrent Neural Networks’</a>.</p>
<p>Dataset samples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>BAPTISTA:
I know him well: you are welcome for his sake.

GREMIO:
Saving your tale, Petruchio, I pray,
Let us, that are poor petitioners, speak too:
Baccare! you are marvellous forward.

PETRUCHIO:
O, pardon me, Signior Gremio; I would fain be doing.
</pre></div>
</div>
<p>Here, we have adopted similar pre-processing logic from another demo: <a class="reference internal" href="../deepspeed/gptj_deepspeed_fine_tuning.html#gptj-deepspeed-finetune"><span class="std std-ref">GPT-J-6B Fine-Tuning with Ray Train and DeepSpeed</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>

<span class="k">def</span> <span class="nf">split_text</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
    <span class="n">flat_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">split_text</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">x</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">flat_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">strip</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;:&quot;</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">split_text</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>

<span class="n">hf_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tiny_shakespeare&quot;</span><span class="p">)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_huggingface</span><span class="p">(</span><span class="n">hf_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>We first split the original paragraphs into multiple sentences, then tokenize them. Here are some samples:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First split the dataset into multiple sentences.</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">split_text</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>
<span class="n">train_ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-08-30 11:03:12,182	INFO dataset.py:2380 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.
2023-08-30 11:03:12,185	INFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[MapBatches(split_text)] -&gt; LimitOperator[limit=10]
2023-08-30 11:03:12,186	INFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)
2023-08-30 11:03:12,187	INFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "e398e697cafb4b548fabc85020df5e87", "version_major": 2, "version_minor": 0}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;text&#39;: &#39;Before we proceed any further, hear me speak.&#39;},
 {&#39;text&#39;: &#39;Speak, speak.&#39;},
 {&#39;text&#39;: &#39;You are all resolved rather to die than to famish?&#39;},
 {&#39;text&#39;: &#39;Resolved. resolved.&#39;},
 {&#39;text&#39;: &#39;First, you know Caius Marcius is chief enemy to the people.&#39;},
 {&#39;text&#39;: &quot;We know&#39;t, we know&#39;t.&quot;},
 {&#39;text&#39;: &quot;Let us kill him, and we&#39;ll have corn at our own price.&quot;},
 {&#39;text&#39;: &quot;Is&#39;t a verdict?&quot;},
 {&#39;text&#39;: &quot;No more talking on&#39;t; let it be done: away, away!&quot;},
 {&#39;text&#39;: &#39;One word, good citizens.&#39;}]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Then tokenize the dataset.</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-your-lightning-model">
<h2>Define your lightning model<a class="headerlink" href="#define-your-lightning-model" title="Permalink to this headline">#</a></h2>
<p>In this example, we use the <a class="reference external" href="https://huggingface.co/databricks/dolly-v2-7b">dolly-v2-7b</a> model for finetuning. It is an instruction-following large language model trained on the Databricks machine learning platform that is licensed for commercial use. We load the model weights from Huggingface Model Hub and encapsulate it into a <code class="docutils literal notranslate"><span class="pre">pl.LightningModule</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Make sure you pass the FSDP wrapped model parameters <code class="docutils literal notranslate"><span class="pre">self.trainer.model.parameters()</span></code> into the optimizer, instead of <code class="docutils literal notranslate"><span class="pre">self.model.parameters()</span></code>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="k">class</span> <span class="nc">DollyV2Model</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span> 
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span> 
            <span class="n">labels</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="configure-your-fsdp-strategy">
<h2>Configure your FSDP strategy<a class="headerlink" href="#configure-your-fsdp-strategy" title="Permalink to this headline">#</a></h2>
<p>As <code class="docutils literal notranslate"><span class="pre">dolly-v2-7b</span></code> is a relatively large model, it cannot be properly fit into a single commercial GPU. In this example, we use the FSDP strategy to shard model parameters across multiple workers. This allows us to avoid GPU out-of-memory issues and support a larger global batch size.</p>
<p><img alt="" src="https://user-images.githubusercontent.com/26745457/236892936-d4b91751-4689-421e-ac5f-edfd2eeeb635.png" />
Image source: <a class="reference external" href="https://engineering.fb.com/2021/07/15/open-source/fsdp/">Fully Sharded Data Parallel: faster AI training with fewer GPUs</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>FSDP is a type of data parallelism that shards model parameters, optimizer states and gradients across DDP ranks. This was inspired by Xu et al. as well as the ZeRO Stage 3 from DeepSpeed. You may refer to these blogs for more information:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://engineering.fb.com/2021/07/15/open-source/fsdp/">Fully Sharded Data Parallel: faster AI training with fewer GPUs</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html#:~:text=FSDP%20is%20a%20type%20of,sizes%20for%20our%20training%20job.">Getting Started with Fully Sharded Data Parallel(FSDP)</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=8_k76AHu__s&amp;list=PL_lsbAsL_o2BT6aerEKgIoufVD_fodnuT">PyTorch FSDP Tutorial</a></p></li>
</ul>
</div>
<p>To start training with Lightning’s <a class="reference external" href="https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.strategies.FSDPStrategy.html#lightning.pytorch.strategies.FSDPStrategy">FSDPStrategy</a>, you only need to create a <a class="reference internal" href="../../api/doc/ray.train.lightning.RayFSDPStrategy.html#ray.train.lightning.RayFSDPStrategy" title="ray.train.lightning.RayFSDPStrategy"><code class="xref py py-class docutils literal notranslate"><span class="pre">RayFSDPStrategy</span></code></a> with the same initialization arguments.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span> 

<span class="kn">from</span> <span class="nn">torch.distributed.fsdp.wrap</span> <span class="kn">import</span> <span class="n">transformer_auto_wrap_policy</span>
<span class="kn">from</span> <span class="nn">torch.distributed.fsdp</span> <span class="kn">import</span> <span class="n">ShardingStrategy</span><span class="p">,</span> <span class="n">BackwardPrefetch</span>
<span class="kn">from</span> <span class="nn">transformers.models.gpt_neox.modeling_gpt_neox</span> <span class="kn">import</span> <span class="n">GPTNeoXLayer</span>

<span class="kn">from</span> <span class="nn">ray.train.lightning</span> <span class="kn">import</span> <span class="n">RayFSDPStrategy</span>


<span class="c1"># Define the model sharding policy:</span>
<span class="c1"># Wrap every GPTNeoXLayer as its own FSDP instance</span>
<span class="n">auto_wrap_policy</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
    <span class="n">transformer_auto_wrap_policy</span><span class="p">,</span>
    <span class="n">transformer_layer_cls</span> <span class="o">=</span> <span class="p">{</span><span class="n">GPTNeoXLayer</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">fsdp_strategy</span> <span class="o">=</span> <span class="n">RayFSDPStrategy</span><span class="p">(</span>
    <span class="n">sharding_strategy</span><span class="o">=</span><span class="n">ShardingStrategy</span><span class="o">.</span><span class="n">FULL_SHARD</span><span class="p">,</span>
    <span class="n">backward_prefetch</span><span class="o">=</span><span class="n">BackwardPrefetch</span><span class="o">.</span><span class="n">BACKWARD_PRE</span><span class="p">,</span>
    <span class="n">forward_prefetch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">auto_wrap_policy</span><span class="o">=</span><span class="n">auto_wrap_policy</span><span class="p">,</span>
    <span class="n">limit_all_gathers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">activation_checkpointing</span><span class="o">=</span><span class="p">[</span><span class="n">GPTNeoXLayer</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Some tips for FSDP configuration:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sharding_strategy</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">ShardingStrategy.NO_SHARD</span></code>: Parameters, gradients, and optimizer states are not sharded. Similar to DDP.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ShardingStrategy.SHARD_GRAD_OP</span></code>: Gradients and optimizer states are sharded during computation, and additionally, parameters are sharded outside computation. Similar to ZeRO stage-2.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ShardingStrategy.FULL_SHARD</span></code>: Parameters, gradients, and optimizer states are sharded. It has minimal GRAM usage among the 3 options. Similar to ZeRO stage-3.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">auto_wrap_policy</span></code>:</p>
<ul>
<li><p>Model layers are often wrapped with FSDP in a layered fashion. This means that only the layers in a single FSDP instance are required to aggregate all parameters to a single device during forwarding or backward calculations.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">transformer_auto_wrap_policy</span></code> to automatically wrap each Transformer Block into a single FSDP instance.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">backward_prefetch</span></code> and <code class="docutils literal notranslate"><span class="pre">forward_prefetch</span></code>:</p>
<ul>
<li><p>Overlap the upcoming all-gather while executing the current forward/backward pass. It can improve throughput but may slightly increase peak memory usage.</p></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="fine-tune-with-ray-torchtrainer">
<h2>Fine-tune with Ray TorchTrainer<a class="headerlink" href="#fine-tune-with-ray-torchtrainer" title="Permalink to this headline">#</a></h2>
<p>Ray TorchTrainer allows you to scale your PyTorch Lightning training workload over multiple nodes. See <a class="reference internal" href="../../user-guides/using-gpus.html#train-scaling-config"><span class="std std-ref">Configuring Scale and GPUs</span></a> for more details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_workers</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">batch_size_per_worker</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<p>Additionally, remember to define a Lightning callback that saves and reports checkpoints. Ray Train offers a simple implementation, <a class="reference internal" href="../../api/doc/ray.train.lightning.RayTrainReportCallback.html#ray.train.lightning.RayTrainReportCallback" title="ray.train.lightning.RayTrainReportCallback"><code class="xref py py-meth docutils literal notranslate"><span class="pre">RayTrainReportCallback()</span></code></a>, which persists your checkpoint and metrics in remote storage at the end of each training epoch.</p>
<p>Note you can also implement your own report callback with customized logics, such as saving customized checkpoint files or reporting at a different frequency.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">Checkpoint</span>
<span class="kn">from</span> <span class="nn">ray.train.lightning</span> <span class="kn">import</span> <span class="n">RayLightningEnvironment</span><span class="p">,</span> <span class="n">RayTrainReportCallback</span><span class="p">,</span> <span class="n">prepare_trainer</span>

<span class="c1"># Training function for each worker</span>
<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;eps&quot;</span><span class="p">]</span>
    <span class="n">strategy</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;strategy&quot;</span><span class="p">]</span>
    <span class="n">batch_size_per_worker</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size_per_worker&quot;</span><span class="p">]</span>

    <span class="c1"># Model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DollyV2Model</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span>

    <span class="c1"># Ray Data Ingestion</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size_per_worker</span><span class="p">)</span>

    <span class="c1"># Lightning Trainer</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">devices</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> 
        <span class="n">precision</span><span class="o">=</span><span class="s2">&quot;16-mixed&quot;</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span>
        <span class="n">plugins</span><span class="o">=</span><span class="p">[</span><span class="n">RayLightningEnvironment</span><span class="p">()],</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">RayTrainReportCallback</span><span class="p">()],</span>
        <span class="n">enable_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">prepare_trainer</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since this example runs with multiple nodes, we need to persist checkpoints
and other outputs to some external storage for access after training has completed.
<strong>You should set up cloud storage or NFS, then replace <code class="docutils literal notranslate"><span class="pre">storage_path</span></code> with your own cloud bucket URI or NFS path.</strong></p>
<p>See the <a class="reference internal" href="../../../tune/tutorials/tune-storage.html#tune-storage-options"><span class="std std-ref">storage guide</span></a> for more details.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">storage_path</span><span class="o">=</span><span class="s2">&quot;s3://your-bucket-here&quot;</span>  <span class="c1"># TODO: Set up cloud storage</span>
<span class="c1"># storage_path=&quot;/mnt/path/to/nfs&quot;     # TODO: Alternatively, set up NFS</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">RunConfig</span><span class="p">,</span> <span class="n">ScalingConfig</span><span class="p">,</span> <span class="n">CheckpointConfig</span>

<span class="c1"># Save Ray Train checkpoints according to the performance on validation set</span>
<span class="n">run_config</span> <span class="o">=</span> <span class="n">RunConfig</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;finetune_dolly-v2-7b&quot;</span><span class="p">,</span>
    <span class="n">storage_path</span><span class="o">=</span><span class="n">storage_path</span><span class="p">,</span>
    <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">num_to_keep</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Scale the FSDP training workload across 16 GPUs</span>
<span class="c1"># You can change this config based on your compute resources.</span>
<span class="n">scaling_config</span> <span class="o">=</span> <span class="n">ScalingConfig</span><span class="p">(</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainer_resources</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;memory&quot;</span><span class="p">:</span> <span class="mi">100</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">**</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Configuration to pass into train_func</span>
<span class="n">train_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
    <span class="s2">&quot;eps&quot;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="s2">&quot;strategy&quot;</span><span class="p">:</span> <span class="n">fsdp_strategy</span><span class="p">,</span>
    <span class="s2">&quot;batch_size_per_worker&quot;</span><span class="p">:</span> <span class="mi">10</span>
<span class="p">}</span>

<span class="c1"># Define a TorchTrainer and launch you training workload</span>
<span class="n">ray_trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="n">train_config</span><span class="p">,</span>
    <span class="n">run_config</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">scaling_config</span><span class="p">,</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_ds</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ray_trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">result</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2023-08-30 11:51:22</td></tr>
<tr><td>Running for: </td><td>00:47:57.19        </td></tr>
<tr><td>Memory:      </td><td>39.3/124.3 GiB     </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using FIFO scheduling algorithm.<br>Logical resource usage: 193.0/272 CPUs, 16.0/16 GPUs (0.0/16.0 accelerator_type:None)
    </div>

  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name              </th><th>status    </th><th>loc              </th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th><th style="text-align: right;">  train_loss</th><th style="text-align: right;">  epoch</th><th style="text-align: right;">  step</th></tr>
</thead>
<tbody>
<tr><td>TorchTrainer_839b5_00000</td><td>TERMINATED</td><td>10.0.23.226:66074</td><td style="text-align: right;">     1</td><td style="text-align: right;">         2868.15</td><td style="text-align: right;">    0.176025</td><td style="text-align: right;">      0</td><td style="text-align: right;">   135</td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span> StorageContext on SESSION (rank=None):
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span> StorageContext&lt;
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span>   storage_path=/mnt/cluster_storage
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span>   storage_local_path=/home/ray/ray_results
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span>   storage_filesystem=&lt;pyarrow._fs.LocalFileSystem object at 0x7f8b0a2cd7f0&gt;
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span>   storage_fs_path=/mnt/cluster_storage
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span>   experiment_dir_name=finetune_dolly-v2-7b
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span>   trial_dir_name=TorchTrainer_839b5_00000_0_2023-08-30_11-03-25
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span>   current_checkpoint_index=0
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TrainTrainable pid=66074)</span> &gt;
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(TorchTrainer pid=66074)</span> Starting distributed worker processes: [&#39;66181 (10.0.23.226)&#39;, &#39;14250 (10.0.40.16)&#39;, &#39;13932 (10.0.2.17)&#39;, &#39;13832 (10.0.41.56)&#39;, &#39;14288 (10.0.53.250)&#39;, &#39;13909 (10.0.41.152)&#39;, &#39;13803 (10.0.14.94)&#39;, &#39;47214 (10.0.44.99)&#39;, &#39;13836 (10.0.58.27)&#39;, &#39;13838 (10.0.58.206)&#39;, &#39;13755 (10.0.62.244)&#39;, &#39;13828 (10.0.9.99)&#39;, &#39;13771 (10.0.43.35)&#39;, &#39;13726 (10.0.59.245)&#39;, &#39;13829 (10.0.58.178)&#39;, &#39;13861 (10.0.46.116)&#39;]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> Setting up process group for: env:// [rank=0, world_size=16]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> StorageContext on SESSION (rank=0):
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=14250, ip=10.0.40.16)</span> StorageContext&lt;<span class=" -Color -Color-Green"> [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=14250, ip=10.0.40.16)</span>   storage_path=/mnt/cluster_storage<span class=" -Color -Color-Green"> [repeated 2x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=14250, ip=10.0.40.16)</span>   storage_local_path=/home/ray/ray_results<span class=" -Color -Color-Green"> [repeated 2x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=14250, ip=10.0.40.16)</span>   storage_filesystem=&lt;pyarrow._fs.LocalFileSystem object at 0x7ff145c40b30&gt;<span class=" -Color -Color-Green"> [repeated 2x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=14250, ip=10.0.40.16)</span>   storage_fs_path=/mnt/cluster_storage<span class=" -Color -Color-Green"> [repeated 2x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=14250, ip=10.0.40.16)</span>   current_checkpoint_index=0<span class=" -Color -Color-Green"> [repeated 6x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=14250, ip=10.0.40.16)</span> &gt;<span class=" -Color -Color-Green"> [repeated 2x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(SplitCoordinator pid=66292)</span> Auto configuring locality_with_output=[&#39;5ed99d043a52f67deb150f34202c09b77bd37409502ebf6e581b0544&#39;, &#39;8efe8198d7c04d45714ae757f298c316117405f3a8b25b87a71e0d9e&#39;, &#39;e3754d1e1017e68dd919b35d35ea62ed7b005ad96452f371721fc9fa&#39;, &#39;8bd0f431ab3733c4b423c1d50db06460e3c210de47355b3b4d215c31&#39;, &#39;73a8b9377fe9531a84eaa7b30c966fbb11bc36aff070d55c8f7acd1a&#39;, &#39;ef922c93f3b2fc93ebe5a521426d24fb8aae7e13c65f9fbd106aea2a&#39;, &#39;5249cff3eab41121f840c17a79e6a3cd0af0f059def707a39e055fcf&#39;, &#39;042b668e5553a589a4f6693c45deee0abe57a1d754812172af425acb&#39;, &#39;9ed138bfe1f9c7dca484ee08d8311806389adb3af7a76566a6f4dfaa&#39;, &#39;7e2fcb5dfe4ab1b572d87257f9e13bbc22b33ba968b1e67a79505589&#39;, &#39;39b1ef4da8493a22e321a1ea9dd13387f50d9a6e2d2fbad58ad5fe9c&#39;, &#39;9484193409a5346c0838a4a19a0a08eec122477682ea1cb0ad3e305a&#39;, &#39;0158084645ec305bdd2ab11a6f35c44ad206405ca810e65f24b09398&#39;, &#39;fe5b11633900d1c437b2e3ee4ea44c18cf68f3dece546537d2090c63&#39;, &#39;573645f42162f531a66d20776a95ba05102fae8e4b8090d48b94b233&#39;, &#39;47e317ad5d0eb94cabb78871541160763283629d0d3f3b77b69521ae&#39;]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> Using 16bit Automatic Mixed Precision (AMP)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> GPU available: True (cuda), used: True
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> TPU available: False, using: 0 TPU cores
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> IPU available: False, using: 0 IPUs
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> HPU available: False, using: 0 HPUs
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span> StorageContext on SESSION (rank=13):<span class=" -Color -Color-Green"> [repeated 15x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span> StorageContext&lt;<span class=" -Color -Color-Green"> [repeated 14x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span>   storage_path=/mnt/cluster_storage<span class=" -Color -Color-Green"> [repeated 14x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span>   storage_local_path=/home/ray/ray_results<span class=" -Color -Color-Green"> [repeated 14x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span>   storage_filesystem=&lt;pyarrow._fs.LocalFileSystem object at 0x7fc9841d7a70&gt;<span class=" -Color -Color-Green"> [repeated 14x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span>   storage_fs_path=/mnt/cluster_storage<span class=" -Color -Color-Green"> [repeated 14x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span>   current_checkpoint_index=0<span class=" -Color -Color-Green"> [repeated 42x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span> &gt;<span class=" -Color -Color-Green"> [repeated 14x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> Missing logger folder: /home/ray/ray_results/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25/lightning_logs
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13832, ip=10.0.41.56)</span> Using 16bit Automatic Mixed Precision (AMP)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13836, ip=10.0.58.27)</span> Using 16bit Automatic Mixed Precision (AMP)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13832, ip=10.0.41.56)</span> Missing logger folder: /home/ray/ray_results/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25/lightning_logs
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span> Using 16bit Automatic Mixed Precision (AMP)<span class=" -Color -Color-Green"> [repeated 13x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=47214, ip=10.0.44.99)</span> Missing logger folder: /home/ray/ray_results/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25/lightning_logs<span class=" -Color -Color-Green"> [repeated 13x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13909, ip=10.0.41.152)</span> LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> FullyShardedDataParallel(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>   (_fsdp_wrapped_module): _LightningModuleWrapperBase(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>     (_forward_module): DollyV2Model(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>       (model): GPTNeoXForCausalLM(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>         (gpt_neox): GPTNeoXModel(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>           (embed_in): Embedding(50280, 4096)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>           (layers): ModuleList(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>             (0-31): 32 x FullyShardedDataParallel(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>               (_fsdp_wrapped_module): CheckpointWrapper(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                 (_checkpoint_wrapped_module): GPTNeoXLayer(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                   (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                   (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                   (attention): GPTNeoXAttention(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                     (rotary_emb): RotaryEmbedding()
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                     (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                     (dense): Linear(in_features=4096, out_features=4096, bias=True)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                   )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                   (mlp): GPTNeoXMLP(
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                     (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                     (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                     (act): GELUActivation()
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                   )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>                 )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>               )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>             )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>           )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>           (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>         )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>         (embed_out): Linear(in_features=4096, out_features=50280, bias=False)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>       )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>     )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>   )
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> )
Epoch 0:   0%|          | 0/134 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> 
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span>   | Name  | Type               | Params
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> ---------------------------------------------
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> 0 | model | GPTNeoXForCausalLM | 402 M 
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> ---------------------------------------------
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> 402 M     Trainable params
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> 0         Non-trainable params
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> 402 M     Total params
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> 1,611.039 Total estimated model params size (MB)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13726, ip=10.0.59.245)</span> Missing logger folder: /home/ray/ray_results/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25/lightning_logs
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13803, ip=10.0.14.94)</span> LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]<span class=" -Color -Color-Green"> [repeated 15x across cluster]</span>
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(SplitCoordinator pid=66292)</span> Executing DAG InputDataBuffer[Input] -&gt; TaskPoolMapOperator[MapBatches(split_text)-&gt;MapBatches(tokenize)] -&gt; OutputSplitter[split(16, equal=True)]
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(SplitCoordinator pid=66292)</span> Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=[&#39;5ed99d043a52f67deb150f34202c09b77bd37409502ebf6e581b0544&#39;, &#39;8efe8198d7c04d45714ae757f298c316117405f3a8b25b87a71e0d9e&#39;, &#39;e3754d1e1017e68dd919b35d35ea62ed7b005ad96452f371721fc9fa&#39;, &#39;8bd0f431ab3733c4b423c1d50db06460e3c210de47355b3b4d215c31&#39;, &#39;73a8b9377fe9531a84eaa7b30c966fbb11bc36aff070d55c8f7acd1a&#39;, &#39;ef922c93f3b2fc93ebe5a521426d24fb8aae7e13c65f9fbd106aea2a&#39;, &#39;5249cff3eab41121f840c17a79e6a3cd0af0f059def707a39e055fcf&#39;, &#39;042b668e5553a589a4f6693c45deee0abe57a1d754812172af425acb&#39;, &#39;9ed138bfe1f9c7dca484ee08d8311806389adb3af7a76566a6f4dfaa&#39;, &#39;7e2fcb5dfe4ab1b572d87257f9e13bbc22b33ba968b1e67a79505589&#39;, &#39;39b1ef4da8493a22e321a1ea9dd13387f50d9a6e2d2fbad58ad5fe9c&#39;, &#39;9484193409a5346c0838a4a19a0a08eec122477682ea1cb0ad3e305a&#39;, &#39;0158084645ec305bdd2ab11a6f35c44ad206405ca810e65f24b09398&#39;, &#39;fe5b11633900d1c437b2e3ee4ea44c18cf68f3dece546537d2090c63&#39;, &#39;573645f42162f531a66d20776a95ba05102fae8e4b8090d48b94b233&#39;, &#39;47e317ad5d0eb94cabb78871541160763283629d0d3f3b77b69521ae&#39;], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(SplitCoordinator pid=66292)</span> Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "eb9d86f824ce4098bc4f081b87d47da4", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "186888f1b0ff4ed687052fe0bc3d1c8a", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "810e2b512ec048a0a53e6546dfec49a9", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0:   1%|          | 1/134 [00:25&lt;57:20, 25.87s/it, v_num=0, train_loss=12.90]
Epoch 0:   1%|▏         | 2/134 [00:43&lt;47:24, 21.55s/it, v_num=0, train_loss=12.50]
Epoch 0:   2%|▏         | 3/134 [01:00&lt;43:55, 20.12s/it, v_num=0, train_loss=12.50]
Epoch 0:   3%|▎         | 4/134 [01:21&lt;44:23, 20.49s/it, v_num=0, train_loss=12.50]
Epoch 0:   4%|▎         | 5/134 [01:39&lt;42:42, 19.87s/it, v_num=0, train_loss=12.50]
Epoch 0:   4%|▍         | 6/134 [01:56&lt;41:29, 19.45s/it, v_num=0, train_loss=12.50]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +4m7s)</span> Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +4m7s)</span> [workspace snapshot] New snapshot created successfully (size: 448.90 KB).
Epoch 0:   5%|▌         | 7/134 [02:13&lt;40:30, 19.14s/it, v_num=0, train_loss=12.50]
Epoch 0:   6%|▌         | 8/134 [02:31&lt;39:43, 18.92s/it, v_num=0, train_loss=12.50]
Epoch 0:   7%|▋         | 9/134 [02:48&lt;39:04, 18.76s/it, v_num=0, train_loss=12.50]
Epoch 0:   7%|▋         | 9/134 [02:48&lt;39:06, 18.77s/it, v_num=0, train_loss=12.50]
Epoch 0:   7%|▋         | 10/134 [03:06&lt;38:33, 18.66s/it, v_num=0, train_loss=12.50]
Epoch 0:   7%|▋         | 10/134 [03:06&lt;38:35, 18.67s/it, v_num=0, train_loss=0.587]
Epoch 0:   8%|▊         | 11/134 [03:24&lt;38:02, 18.56s/it, v_num=0, train_loss=0.587]
Epoch 0:   8%|▊         | 11/134 [03:24&lt;38:04, 18.57s/it, v_num=0, train_loss=0.600]
Epoch 0:   9%|▉         | 12/134 [03:41&lt;37:34, 18.48s/it, v_num=0, train_loss=0.600]
Epoch 0:   9%|▉         | 12/134 [03:41&lt;37:36, 18.49s/it, v_num=0, train_loss=0.590]
Epoch 0:  10%|▉         | 13/134 [03:59&lt;37:08, 18.41s/it, v_num=0, train_loss=0.590]
Epoch 0:  10%|▉         | 13/134 [03:59&lt;37:09, 18.43s/it, v_num=0, train_loss=0.591]
Epoch 0:  10%|█         | 14/134 [04:17&lt;36:44, 18.37s/it, v_num=0, train_loss=0.591]
Epoch 0:  10%|█         | 14/134 [04:17&lt;36:45, 18.38s/it, v_num=0, train_loss=0.590]
Epoch 0:  11%|█         | 15/134 [04:34&lt;36:19, 18.32s/it, v_num=0, train_loss=0.590]
Epoch 0:  11%|█         | 15/134 [04:34&lt;36:21, 18.33s/it, v_num=0, train_loss=0.551]
Epoch 0:  12%|█▏        | 16/134 [04:52&lt;35:57, 18.29s/it, v_num=0, train_loss=0.551]
Epoch 0:  12%|█▏        | 16/134 [04:52&lt;35:58, 18.29s/it, v_num=0, train_loss=0.521]
Epoch 0:  13%|█▎        | 17/134 [05:10&lt;35:35, 18.25s/it, v_num=0, train_loss=0.521]
Epoch 0:  13%|█▎        | 17/134 [05:10&lt;35:36, 18.26s/it, v_num=0, train_loss=0.522]
Epoch 0:  13%|█▎        | 18/134 [05:28&lt;35:14, 18.23s/it, v_num=0, train_loss=0.522]
Epoch 0:  13%|█▎        | 18/134 [05:28&lt;35:15, 18.23s/it, v_num=0, train_loss=0.518]
Epoch 0:  14%|█▍        | 19/134 [05:45&lt;34:52, 18.19s/it, v_num=0, train_loss=0.518]
Epoch 0:  14%|█▍        | 19/134 [05:45&lt;34:52, 18.20s/it, v_num=0, train_loss=0.476]
Epoch 0:  15%|█▍        | 20/134 [06:03&lt;34:30, 18.16s/it, v_num=0, train_loss=0.476]
Epoch 0:  15%|█▍        | 20/134 [06:03&lt;34:31, 18.17s/it, v_num=0, train_loss=0.457]
Epoch 0:  16%|█▌        | 21/134 [06:23&lt;34:23, 18.26s/it, v_num=0, train_loss=0.457]
Epoch 0:  16%|█▌        | 21/134 [06:23&lt;34:23, 18.27s/it, v_num=0, train_loss=0.476]
Epoch 0:  16%|█▋        | 22/134 [06:42&lt;34:09, 18.30s/it, v_num=0, train_loss=0.476]
Epoch 0:  16%|█▋        | 22/134 [06:42&lt;34:10, 18.31s/it, v_num=0, train_loss=0.447]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +9m7s)</span> [workspace snapshot] New snapshot created successfully (size: 451.39 KB).
Epoch 0:  17%|█▋        | 23/134 [07:00&lt;33:49, 18.28s/it, v_num=0, train_loss=0.447]
Epoch 0:  17%|█▋        | 23/134 [07:00&lt;33:49, 18.29s/it, v_num=0, train_loss=0.412]
Epoch 0:  18%|█▊        | 24/134 [07:19&lt;33:33, 18.31s/it, v_num=0, train_loss=0.412]
Epoch 0:  18%|█▊        | 24/134 [07:19&lt;33:34, 18.31s/it, v_num=0, train_loss=0.385]
Epoch 0:  19%|█▊        | 25/134 [07:37&lt;33:13, 18.29s/it, v_num=0, train_loss=0.385]
Epoch 0:  19%|█▊        | 25/134 [07:37&lt;33:13, 18.29s/it, v_num=0, train_loss=0.384]
Epoch 0:  19%|█▉        | 26/134 [07:54&lt;32:52, 18.27s/it, v_num=0, train_loss=0.384]
Epoch 0:  19%|█▉        | 26/134 [07:55&lt;32:53, 18.27s/it, v_num=0, train_loss=0.406]
Epoch 0:  20%|██        | 27/134 [08:12&lt;32:32, 18.25s/it, v_num=0, train_loss=0.406]
Epoch 0:  20%|██        | 27/134 [08:12&lt;32:32, 18.25s/it, v_num=0, train_loss=0.380]
Epoch 0:  21%|██        | 28/134 [08:30&lt;32:12, 18.23s/it, v_num=0, train_loss=0.380]
Epoch 0:  21%|██        | 28/134 [08:30&lt;32:12, 18.23s/it, v_num=0, train_loss=0.405]
Epoch 0:  22%|██▏       | 29/134 [08:48&lt;31:52, 18.21s/it, v_num=0, train_loss=0.405]
Epoch 0:  22%|██▏       | 29/134 [08:48&lt;31:52, 18.22s/it, v_num=0, train_loss=0.355]
Epoch 0:  22%|██▏       | 30/134 [09:06&lt;31:32, 18.20s/it, v_num=0, train_loss=0.355]
Epoch 0:  22%|██▏       | 30/134 [09:06&lt;31:33, 18.21s/it, v_num=0, train_loss=0.376]
Epoch 0:  23%|██▎       | 31/134 [09:23&lt;31:12, 18.18s/it, v_num=0, train_loss=0.376]
Epoch 0:  23%|██▎       | 31/134 [09:23&lt;31:13, 18.19s/it, v_num=0, train_loss=0.330]
Epoch 0:  24%|██▍       | 32/134 [09:41&lt;30:53, 18.17s/it, v_num=0, train_loss=0.330]
Epoch 0:  24%|██▍       | 32/134 [09:41&lt;30:53, 18.17s/it, v_num=0, train_loss=0.359]
Epoch 0:  25%|██▍       | 33/134 [09:59&lt;30:33, 18.15s/it, v_num=0, train_loss=0.359]
Epoch 0:  25%|██▍       | 33/134 [09:59&lt;30:33, 18.16s/it, v_num=0, train_loss=0.319]
Epoch 0:  25%|██▌       | 34/134 [10:16&lt;30:14, 18.14s/it, v_num=0, train_loss=0.319]
Epoch 0:  25%|██▌       | 34/134 [10:16&lt;30:14, 18.15s/it, v_num=0, train_loss=0.359]
Epoch 0:  26%|██▌       | 35/134 [10:34&lt;29:54, 18.13s/it, v_num=0, train_loss=0.359]
Epoch 0:  26%|██▌       | 35/134 [10:34&lt;29:54, 18.13s/it, v_num=0, train_loss=0.405]
Epoch 0:  27%|██▋       | 36/134 [10:52&lt;29:35, 18.12s/it, v_num=0, train_loss=0.405]
Epoch 0:  27%|██▋       | 36/134 [10:52&lt;29:35, 18.12s/it, v_num=0, train_loss=0.362]
Epoch 0:  28%|██▊       | 37/134 [11:09&lt;29:16, 18.10s/it, v_num=0, train_loss=0.362]
Epoch 0:  28%|██▊       | 37/134 [11:10&lt;29:16, 18.11s/it, v_num=0, train_loss=0.343]
Epoch 0:  28%|██▊       | 38/134 [11:27&lt;28:56, 18.09s/it, v_num=0, train_loss=0.343]
Epoch 0:  28%|██▊       | 38/134 [11:27&lt;28:57, 18.10s/it, v_num=0, train_loss=0.335]
Epoch 0:  29%|██▉       | 39/134 [11:45&lt;28:38, 18.08s/it, v_num=0, train_loss=0.335]
Epoch 0:  29%|██▉       | 39/134 [11:45&lt;28:38, 18.09s/it, v_num=0, train_loss=0.325]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +14m8s)</span> [workspace snapshot] New snapshot created successfully (size: 455.47 KB).
Epoch 0:  30%|██▉       | 40/134 [12:03&lt;28:19, 18.08s/it, v_num=0, train_loss=0.325]
Epoch 0:  30%|██▉       | 40/134 [12:03&lt;28:19, 18.08s/it, v_num=0, train_loss=0.344]
Epoch 0:  31%|███       | 41/134 [12:20&lt;27:59, 18.06s/it, v_num=0, train_loss=0.344]
Epoch 0:  31%|███       | 41/134 [12:20&lt;28:00, 18.06s/it, v_num=0, train_loss=0.312]
Epoch 0:  31%|███▏      | 42/134 [12:38&lt;27:40, 18.05s/it, v_num=0, train_loss=0.312]
Epoch 0:  31%|███▏      | 42/134 [12:38&lt;27:40, 18.05s/it, v_num=0, train_loss=0.338]
Epoch 0:  32%|███▏      | 43/134 [12:55&lt;27:21, 18.04s/it, v_num=0, train_loss=0.338]
Epoch 0:  32%|███▏      | 43/134 [12:55&lt;27:21, 18.04s/it, v_num=0, train_loss=0.315]
Epoch 0:  33%|███▎      | 44/134 [13:13&lt;27:02, 18.03s/it, v_num=0, train_loss=0.315]
Epoch 0:  33%|███▎      | 44/134 [13:13&lt;27:02, 18.03s/it, v_num=0, train_loss=0.330]
Epoch 0:  34%|███▎      | 45/134 [13:31&lt;26:44, 18.02s/it, v_num=0, train_loss=0.330]
Epoch 0:  34%|███▎      | 45/134 [13:31&lt;26:44, 18.03s/it, v_num=0, train_loss=0.253]
Epoch 0:  34%|███▍      | 46/134 [13:48&lt;26:25, 18.02s/it, v_num=0, train_loss=0.253]
Epoch 0:  34%|███▍      | 46/134 [13:49&lt;26:25, 18.02s/it, v_num=0, train_loss=0.310]
Epoch 0:  35%|███▌      | 47/134 [14:06&lt;26:07, 18.01s/it, v_num=0, train_loss=0.310]
Epoch 0:  35%|███▌      | 47/134 [14:06&lt;26:07, 18.01s/it, v_num=0, train_loss=0.294]
Epoch 0:  36%|███▌      | 48/134 [14:24&lt;25:48, 18.01s/it, v_num=0, train_loss=0.294]
Epoch 0:  36%|███▌      | 48/134 [14:24&lt;25:48, 18.01s/it, v_num=0, train_loss=0.302]
Epoch 0:  37%|███▋      | 49/134 [14:41&lt;25:29, 18.00s/it, v_num=0, train_loss=0.302]
Epoch 0:  37%|███▋      | 49/134 [14:42&lt;25:30, 18.00s/it, v_num=0, train_loss=0.325]
Epoch 0:  37%|███▋      | 50/134 [14:59&lt;25:11, 17.99s/it, v_num=0, train_loss=0.325]
Epoch 0:  37%|███▋      | 50/134 [14:59&lt;25:11, 18.00s/it, v_num=0, train_loss=0.250]
Epoch 0:  38%|███▊      | 51/134 [15:17&lt;24:53, 17.99s/it, v_num=0, train_loss=0.250]
Epoch 0:  38%|███▊      | 51/134 [15:17&lt;24:53, 17.99s/it, v_num=0, train_loss=0.291]
Epoch 0:  39%|███▉      | 52/134 [15:34&lt;24:34, 17.98s/it, v_num=0, train_loss=0.291]
Epoch 0:  39%|███▉      | 52/134 [15:35&lt;24:34, 17.98s/it, v_num=0, train_loss=0.261]
Epoch 0:  40%|███▉      | 53/134 [15:52&lt;24:15, 17.98s/it, v_num=0, train_loss=0.261]
Epoch 0:  40%|███▉      | 53/134 [15:52&lt;24:16, 17.98s/it, v_num=0, train_loss=0.292]
Epoch 0:  40%|████      | 54/134 [16:10&lt;23:57, 17.97s/it, v_num=0, train_loss=0.292]
Epoch 0:  40%|████      | 54/134 [16:10&lt;23:58, 17.98s/it, v_num=0, train_loss=0.245]
Epoch 0:  41%|████      | 55/134 [16:28&lt;23:39, 17.97s/it, v_num=0, train_loss=0.245]
Epoch 0:  41%|████      | 55/134 [16:28&lt;23:39, 17.97s/it, v_num=0, train_loss=0.265]
Epoch 0:  42%|████▏     | 56/134 [16:45&lt;23:20, 17.96s/it, v_num=0, train_loss=0.265]
Epoch 0:  42%|████▏     | 56/134 [16:45&lt;23:21, 17.96s/it, v_num=0, train_loss=0.233]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +19m8s)</span> [workspace snapshot] New snapshot created successfully (size: 458.23 KB).
Epoch 0:  43%|████▎     | 57/134 [17:03&lt;23:02, 17.96s/it, v_num=0, train_loss=0.233]
Epoch 0:  43%|████▎     | 57/134 [17:03&lt;23:02, 17.96s/it, v_num=0, train_loss=0.228]
Epoch 0:  43%|████▎     | 58/134 [17:21&lt;22:44, 17.96s/it, v_num=0, train_loss=0.228]
Epoch 0:  43%|████▎     | 58/134 [17:21&lt;22:45, 17.96s/it, v_num=0, train_loss=0.222]
Epoch 0:  44%|████▍     | 59/134 [17:39&lt;22:26, 17.96s/it, v_num=0, train_loss=0.222]
Epoch 0:  44%|████▍     | 59/134 [17:39&lt;22:27, 17.96s/it, v_num=0, train_loss=0.240]
Epoch 0:  45%|████▍     | 60/134 [17:57&lt;22:08, 17.96s/it, v_num=0, train_loss=0.240]
Epoch 0:  45%|████▍     | 60/134 [17:57&lt;22:08, 17.96s/it, v_num=0, train_loss=0.220]
Epoch 0:  46%|████▌     | 61/134 [18:15&lt;21:50, 17.95s/it, v_num=0, train_loss=0.220]
Epoch 0:  46%|████▌     | 61/134 [18:15&lt;21:50, 17.95s/it, v_num=0, train_loss=0.235]
Epoch 0:  46%|████▋     | 62/134 [18:32&lt;21:32, 17.95s/it, v_num=0, train_loss=0.235]
Epoch 0:  46%|████▋     | 62/134 [18:32&lt;21:32, 17.95s/it, v_num=0, train_loss=0.230]
Epoch 0:  47%|████▋     | 63/134 [18:50&lt;21:14, 17.95s/it, v_num=0, train_loss=0.230]
Epoch 0:  47%|████▋     | 63/134 [18:50&lt;21:14, 17.95s/it, v_num=0, train_loss=0.247]
Epoch 0:  48%|████▊     | 64/134 [19:08&lt;20:55, 17.94s/it, v_num=0, train_loss=0.247]
Epoch 0:  48%|████▊     | 64/134 [19:08&lt;20:56, 17.94s/it, v_num=0, train_loss=0.243]
Epoch 0:  49%|████▊     | 65/134 [19:25&lt;20:37, 17.94s/it, v_num=0, train_loss=0.243]
Epoch 0:  49%|████▊     | 65/134 [19:26&lt;20:37, 17.94s/it, v_num=0, train_loss=0.233]
Epoch 0:  49%|████▉     | 66/134 [19:43&lt;20:19, 17.93s/it, v_num=0, train_loss=0.233]
Epoch 0:  49%|████▉     | 66/134 [19:43&lt;20:19, 17.94s/it, v_num=0, train_loss=0.253]
Epoch 0:  50%|█████     | 67/134 [20:01&lt;20:01, 17.93s/it, v_num=0, train_loss=0.253]
Epoch 0:  50%|█████     | 67/134 [20:01&lt;20:01, 17.93s/it, v_num=0, train_loss=0.235]
Epoch 0:  51%|█████     | 68/134 [20:19&lt;19:43, 17.93s/it, v_num=0, train_loss=0.235]
Epoch 0:  51%|█████     | 68/134 [20:19&lt;19:43, 17.93s/it, v_num=0, train_loss=0.270]
Epoch 0:  51%|█████▏    | 69/134 [20:37&lt;19:25, 17.93s/it, v_num=0, train_loss=0.270]
Epoch 0:  51%|█████▏    | 69/134 [20:37&lt;19:25, 17.93s/it, v_num=0, train_loss=0.220]
Epoch 0:  52%|█████▏    | 70/134 [20:54&lt;19:07, 17.93s/it, v_num=0, train_loss=0.220]
Epoch 0:  52%|█████▏    | 70/134 [20:55&lt;19:07, 17.93s/it, v_num=0, train_loss=0.249]
Epoch 0:  53%|█████▎    | 71/134 [21:12&lt;18:49, 17.93s/it, v_num=0, train_loss=0.249]
Epoch 0:  53%|█████▎    | 71/134 [21:12&lt;18:49, 17.93s/it, v_num=0, train_loss=0.231]
Epoch 0:  54%|█████▎    | 72/134 [21:30&lt;18:31, 17.92s/it, v_num=0, train_loss=0.231]
Epoch 0:  54%|█████▎    | 72/134 [21:30&lt;18:31, 17.92s/it, v_num=0, train_loss=0.206]
Epoch 0:  54%|█████▍    | 73/134 [21:48&lt;18:13, 17.92s/it, v_num=0, train_loss=0.206]
Epoch 0:  54%|█████▍    | 73/134 [21:48&lt;18:13, 17.92s/it, v_num=0, train_loss=0.266]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +24m8s)</span> [workspace snapshot] New snapshot created successfully (size: 462.71 KB).
Epoch 0:  55%|█████▌    | 74/134 [22:05&lt;17:55, 17.92s/it, v_num=0, train_loss=0.266]
Epoch 0:  55%|█████▌    | 74/134 [22:06&lt;17:55, 17.92s/it, v_num=0, train_loss=0.252]
Epoch 0:  56%|█████▌    | 75/134 [22:23&lt;17:37, 17.92s/it, v_num=0, train_loss=0.252]
Epoch 0:  56%|█████▌    | 75/134 [22:23&lt;17:37, 17.92s/it, v_num=0, train_loss=0.218]
Epoch 0:  57%|█████▋    | 76/134 [22:41&lt;17:19, 17.92s/it, v_num=0, train_loss=0.218]
Epoch 0:  57%|█████▋    | 76/134 [22:41&lt;17:19, 17.92s/it, v_num=0, train_loss=0.195]
Epoch 0:  57%|█████▋    | 77/134 [22:59&lt;17:01, 17.91s/it, v_num=0, train_loss=0.195]
Epoch 0:  57%|█████▋    | 77/134 [22:59&lt;17:01, 17.91s/it, v_num=0, train_loss=0.210]
Epoch 0:  58%|█████▊    | 78/134 [23:17&lt;16:42, 17.91s/it, v_num=0, train_loss=0.210]
Epoch 0:  58%|█████▊    | 78/134 [23:17&lt;16:43, 17.91s/it, v_num=0, train_loss=0.198]
Epoch 0:  59%|█████▉    | 79/134 [23:34&lt;16:24, 17.91s/it, v_num=0, train_loss=0.198]
Epoch 0:  59%|█████▉    | 79/134 [23:34&lt;16:24, 17.91s/it, v_num=0, train_loss=0.232]
Epoch 0:  60%|█████▉    | 80/134 [23:52&lt;16:06, 17.90s/it, v_num=0, train_loss=0.232]
Epoch 0:  60%|█████▉    | 80/134 [23:52&lt;16:06, 17.90s/it, v_num=0, train_loss=0.267]
Epoch 0:  60%|██████    | 81/134 [24:09&lt;15:48, 17.90s/it, v_num=0, train_loss=0.267]
Epoch 0:  60%|██████    | 81/134 [24:10&lt;15:48, 17.90s/it, v_num=0, train_loss=0.244]
Epoch 0:  61%|██████    | 82/134 [24:27&lt;15:30, 17.90s/it, v_num=0, train_loss=0.244]
Epoch 0:  61%|██████    | 82/134 [24:27&lt;15:30, 17.90s/it, v_num=0, train_loss=0.173]
Epoch 0:  62%|██████▏   | 83/134 [24:45&lt;15:12, 17.89s/it, v_num=0, train_loss=0.173]
Epoch 0:  62%|██████▏   | 83/134 [24:45&lt;15:12, 17.89s/it, v_num=0, train_loss=0.225]
Epoch 0:  63%|██████▎   | 84/134 [25:02&lt;14:54, 17.89s/it, v_num=0, train_loss=0.225]
Epoch 0:  63%|██████▎   | 84/134 [25:03&lt;14:54, 17.89s/it, v_num=0, train_loss=0.231]
Epoch 0:  63%|██████▎   | 85/134 [25:20&lt;14:36, 17.89s/it, v_num=0, train_loss=0.231]
Epoch 0:  63%|██████▎   | 85/134 [25:20&lt;14:36, 17.89s/it, v_num=0, train_loss=0.235]
Epoch 0:  64%|██████▍   | 86/134 [25:38&lt;14:18, 17.88s/it, v_num=0, train_loss=0.235]
Epoch 0:  64%|██████▍   | 86/134 [25:38&lt;14:18, 17.89s/it, v_num=0, train_loss=0.257]
Epoch 0:  65%|██████▍   | 87/134 [25:55&lt;14:00, 17.88s/it, v_num=0, train_loss=0.257]
Epoch 0:  65%|██████▍   | 87/134 [25:56&lt;14:00, 17.89s/it, v_num=0, train_loss=0.297]
Epoch 0:  66%|██████▌   | 88/134 [26:13&lt;13:42, 17.88s/it, v_num=0, train_loss=0.297]
Epoch 0:  66%|██████▌   | 88/134 [26:13&lt;13:42, 17.88s/it, v_num=0, train_loss=0.277]
Epoch 0:  66%|██████▋   | 89/134 [26:31&lt;13:24, 17.88s/it, v_num=0, train_loss=0.277]
Epoch 0:  66%|██████▋   | 89/134 [26:31&lt;13:24, 17.88s/it, v_num=0, train_loss=0.264]
Epoch 0:  67%|██████▋   | 90/134 [26:49&lt;13:06, 17.88s/it, v_num=0, train_loss=0.264]
Epoch 0:  67%|██████▋   | 90/134 [26:49&lt;13:06, 17.88s/it, v_num=0, train_loss=0.269]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +29m8s)</span> [workspace snapshot] New snapshot created successfully (size: 465.81 KB).
Epoch 0:  68%|██████▊   | 91/134 [27:06&lt;12:48, 17.88s/it, v_num=0, train_loss=0.269]
Epoch 0:  68%|██████▊   | 91/134 [27:07&lt;12:48, 17.88s/it, v_num=0, train_loss=0.268]
Epoch 0:  69%|██████▊   | 92/134 [27:24&lt;12:30, 17.88s/it, v_num=0, train_loss=0.268]
Epoch 0:  69%|██████▊   | 92/134 [27:24&lt;12:30, 17.88s/it, v_num=0, train_loss=0.200]
Epoch 0:  69%|██████▉   | 93/134 [27:42&lt;12:12, 17.87s/it, v_num=0, train_loss=0.200]
Epoch 0:  69%|██████▉   | 93/134 [27:42&lt;12:12, 17.88s/it, v_num=0, train_loss=0.229]
Epoch 0:  70%|███████   | 94/134 [28:00&lt;11:54, 17.87s/it, v_num=0, train_loss=0.229]
Epoch 0:  70%|███████   | 94/134 [28:00&lt;11:54, 17.87s/it, v_num=0, train_loss=0.248]
Epoch 0:  71%|███████   | 95/134 [28:17&lt;11:37, 17.87s/it, v_num=0, train_loss=0.248]
Epoch 0:  71%|███████   | 95/134 [28:18&lt;11:37, 17.87s/it, v_num=0, train_loss=0.217]
Epoch 0:  72%|███████▏  | 96/134 [28:35&lt;11:19, 17.87s/it, v_num=0, train_loss=0.217]
Epoch 0:  72%|███████▏  | 96/134 [28:35&lt;11:19, 17.87s/it, v_num=0, train_loss=0.217]
Epoch 0:  72%|███████▏  | 97/134 [28:53&lt;11:01, 17.87s/it, v_num=0, train_loss=0.217]
Epoch 0:  72%|███████▏  | 97/134 [28:53&lt;11:01, 17.87s/it, v_num=0, train_loss=0.238]
Epoch 0:  73%|███████▎  | 98/134 [29:11&lt;10:43, 17.87s/it, v_num=0, train_loss=0.238]
Epoch 0:  73%|███████▎  | 98/134 [29:11&lt;10:43, 17.87s/it, v_num=0, train_loss=0.168]
Epoch 0:  74%|███████▍  | 99/134 [29:28&lt;10:25, 17.87s/it, v_num=0, train_loss=0.168]
Epoch 0:  74%|███████▍  | 99/134 [29:29&lt;10:25, 17.87s/it, v_num=0, train_loss=0.198]
Epoch 0:  75%|███████▍  | 100/134 [29:46&lt;10:07, 17.87s/it, v_num=0, train_loss=0.198]
Epoch 0:  75%|███████▍  | 100/134 [29:46&lt;10:07, 17.87s/it, v_num=0, train_loss=0.205]
Epoch 0:  75%|███████▌  | 101/134 [30:04&lt;09:49, 17.86s/it, v_num=0, train_loss=0.205]
Epoch 0:  75%|███████▌  | 101/134 [30:04&lt;09:49, 17.87s/it, v_num=0, train_loss=0.165]
Epoch 0:  76%|███████▌  | 102/134 [30:21&lt;09:31, 17.86s/it, v_num=0, train_loss=0.165]
Epoch 0:  76%|███████▌  | 102/134 [30:22&lt;09:31, 17.86s/it, v_num=0, train_loss=0.261]
Epoch 0:  77%|███████▋  | 103/134 [30:39&lt;09:13, 17.86s/it, v_num=0, train_loss=0.261]
Epoch 0:  77%|███████▋  | 103/134 [30:39&lt;09:13, 17.86s/it, v_num=0, train_loss=0.250]
Epoch 0:  78%|███████▊  | 104/134 [30:57&lt;08:55, 17.86s/it, v_num=0, train_loss=0.250]
Epoch 0:  78%|███████▊  | 104/134 [30:57&lt;08:55, 17.86s/it, v_num=0, train_loss=0.161]
Epoch 0:  78%|███████▊  | 105/134 [31:15&lt;08:37, 17.86s/it, v_num=0, train_loss=0.161]
Epoch 0:  78%|███████▊  | 105/134 [31:15&lt;08:38, 17.86s/it, v_num=0, train_loss=0.202]
Epoch 0:  79%|███████▉  | 106/134 [31:33&lt;08:20, 17.86s/it, v_num=0, train_loss=0.202]
Epoch 0:  79%|███████▉  | 106/134 [31:33&lt;08:20, 17.86s/it, v_num=0, train_loss=0.177]
Epoch 0:  80%|███████▉  | 107/134 [31:50&lt;08:02, 17.86s/it, v_num=0, train_loss=0.177]
Epoch 0:  80%|███████▉  | 107/134 [31:51&lt;08:02, 17.86s/it, v_num=0, train_loss=0.225]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +34m8s)</span> [workspace snapshot] New snapshot created successfully (size: 470.30 KB).
Epoch 0:  81%|████████  | 108/134 [32:08&lt;07:44, 17.86s/it, v_num=0, train_loss=0.225]
Epoch 0:  81%|████████  | 108/134 [32:08&lt;07:44, 17.86s/it, v_num=0, train_loss=0.188]
Epoch 0:  81%|████████▏ | 109/134 [32:26&lt;07:26, 17.86s/it, v_num=0, train_loss=0.188]
Epoch 0:  81%|████████▏ | 109/134 [32:26&lt;07:26, 17.86s/it, v_num=0, train_loss=0.205]
Epoch 0:  82%|████████▏ | 110/134 [32:44&lt;07:08, 17.86s/it, v_num=0, train_loss=0.205]
Epoch 0:  82%|████████▏ | 110/134 [32:44&lt;07:08, 17.86s/it, v_num=0, train_loss=0.218]
Epoch 0:  83%|████████▎ | 111/134 [33:02&lt;06:50, 17.86s/it, v_num=0, train_loss=0.218]
Epoch 0:  83%|████████▎ | 111/134 [33:02&lt;06:50, 17.86s/it, v_num=0, train_loss=0.259]
Epoch 0:  84%|████████▎ | 112/134 [33:20&lt;06:32, 17.86s/it, v_num=0, train_loss=0.259]
Epoch 0:  84%|████████▎ | 112/134 [33:20&lt;06:32, 17.86s/it, v_num=0, train_loss=0.255]
Epoch 0:  84%|████████▍ | 113/134 [33:38&lt;06:15, 17.86s/it, v_num=0, train_loss=0.255]
Epoch 0:  84%|████████▍ | 113/134 [33:38&lt;06:15, 17.86s/it, v_num=0, train_loss=0.221]
Epoch 0:  85%|████████▌ | 114/134 [33:55&lt;05:57, 17.86s/it, v_num=0, train_loss=0.221]
Epoch 0:  85%|████████▌ | 114/134 [33:56&lt;05:57, 17.86s/it, v_num=0, train_loss=0.185]
Epoch 0:  86%|████████▌ | 115/134 [34:13&lt;05:39, 17.86s/it, v_num=0, train_loss=0.185]
Epoch 0:  86%|████████▌ | 115/134 [34:13&lt;05:39, 17.86s/it, v_num=0, train_loss=0.189]
Epoch 0:  87%|████████▋ | 116/134 [34:31&lt;05:21, 17.86s/it, v_num=0, train_loss=0.189]
Epoch 0:  87%|████████▋ | 116/134 [34:31&lt;05:21, 17.86s/it, v_num=0, train_loss=0.168]
Epoch 0:  87%|████████▋ | 117/134 [34:48&lt;05:03, 17.85s/it, v_num=0, train_loss=0.168]
Epoch 0:  87%|████████▋ | 117/134 [34:49&lt;05:03, 17.86s/it, v_num=0, train_loss=0.166]
Epoch 0:  88%|████████▊ | 118/134 [35:06&lt;04:45, 17.85s/it, v_num=0, train_loss=0.166]
Epoch 0:  88%|████████▊ | 118/134 [35:06&lt;04:45, 17.86s/it, v_num=0, train_loss=0.184]
Epoch 0:  89%|████████▉ | 119/134 [35:24&lt;04:27, 17.85s/it, v_num=0, train_loss=0.184]
Epoch 0:  89%|████████▉ | 119/134 [35:24&lt;04:27, 17.86s/it, v_num=0, train_loss=0.230]
Epoch 0:  90%|████████▉ | 120/134 [35:42&lt;04:09, 17.85s/it, v_num=0, train_loss=0.230]
Epoch 0:  90%|████████▉ | 120/134 [35:42&lt;04:09, 17.86s/it, v_num=0, train_loss=0.251]
Epoch 0:  90%|█████████ | 121/134 [36:00&lt;03:52, 17.86s/it, v_num=0, train_loss=0.251]
Epoch 0:  90%|█████████ | 121/134 [36:00&lt;03:52, 17.86s/it, v_num=0, train_loss=0.244]
Epoch 0:  91%|█████████ | 122/134 [36:18&lt;03:34, 17.85s/it, v_num=0, train_loss=0.244]
Epoch 0:  91%|█████████ | 122/134 [36:18&lt;03:34, 17.86s/it, v_num=0, train_loss=0.232]
Epoch 0:  92%|█████████▏| 123/134 [36:35&lt;03:16, 17.85s/it, v_num=0, train_loss=0.232]
Epoch 0:  92%|█████████▏| 123/134 [36:36&lt;03:16, 17.85s/it, v_num=0, train_loss=0.200]
Epoch 0:  93%|█████████▎| 124/134 [36:53&lt;02:58, 17.85s/it, v_num=0, train_loss=0.200]
Epoch 0:  93%|█████████▎| 124/134 [36:53&lt;02:58, 17.85s/it, v_num=0, train_loss=0.152]
<span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +39m8s)</span> [workspace snapshot] New snapshot created successfully (size: 473.57 KB).
Epoch 0:  93%|█████████▎| 125/134 [37:11&lt;02:40, 17.86s/it, v_num=0, train_loss=0.152]
Epoch 0:  93%|█████████▎| 125/134 [37:12&lt;02:40, 17.86s/it, v_num=0, train_loss=0.162]
Epoch 0:  94%|█████████▍| 126/134 [37:29&lt;02:22, 17.86s/it, v_num=0, train_loss=0.162]
Epoch 0:  94%|█████████▍| 126/134 [37:29&lt;02:22, 17.86s/it, v_num=0, train_loss=0.184]
Epoch 0:  95%|█████████▍| 127/134 [37:47&lt;02:04, 17.86s/it, v_num=0, train_loss=0.184]
Epoch 0:  95%|█████████▍| 127/134 [37:47&lt;02:04, 17.86s/it, v_num=0, train_loss=0.186]
Epoch 0:  96%|█████████▌| 128/134 [38:05&lt;01:47, 17.85s/it, v_num=0, train_loss=0.186]
Epoch 0:  96%|█████████▌| 128/134 [38:05&lt;01:47, 17.86s/it, v_num=0, train_loss=0.208]
Epoch 0:  96%|█████████▋| 129/134 [38:23&lt;01:29, 17.85s/it, v_num=0, train_loss=0.208]
Epoch 0:  96%|█████████▋| 129/134 [38:23&lt;01:29, 17.85s/it, v_num=0, train_loss=0.243]
Epoch 0:  97%|█████████▋| 130/134 [38:40&lt;01:11, 17.85s/it, v_num=0, train_loss=0.243]
Epoch 0:  97%|█████████▋| 130/134 [38:41&lt;01:11, 17.85s/it, v_num=0, train_loss=0.243]
Epoch 0:  98%|█████████▊| 131/134 [38:58&lt;00:53, 17.85s/it, v_num=0, train_loss=0.243]
Epoch 0:  98%|█████████▊| 131/134 [38:58&lt;00:53, 17.85s/it, v_num=0, train_loss=0.213]
Epoch 0:  99%|█████████▊| 132/134 [39:16&lt;00:35, 17.85s/it, v_num=0, train_loss=0.213]
Epoch 0:  99%|█████████▊| 132/134 [39:16&lt;00:35, 17.85s/it, v_num=0, train_loss=0.214]
Epoch 0:  99%|█████████▉| 133/134 [39:34&lt;00:17, 17.85s/it, v_num=0, train_loss=0.214]
Epoch 0:  99%|█████████▉| 133/134 [39:34&lt;00:17, 17.85s/it, v_num=0, train_loss=0.182]
Epoch 0: 100%|██████████| 134/134 [39:52&lt;00:00, 17.85s/it, v_num=0, train_loss=0.182]
Epoch 0: 100%|██████████| 134/134 [39:52&lt;00:00, 17.85s/it, v_num=0, train_loss=0.174]
Epoch 0: : 135it [40:10, 17.85s/it, v_num=0, train_loss=0.174]                       
Epoch 0: : 135it [40:10, 17.85s/it, v_num=0, train_loss=0.176]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=13861, ip=10.0.46.116)</span> Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25/checkpoint_000000)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Faint -Color-Bold-Faint-Cyan">(autoscaler +44m9s)</span> [workspace snapshot] New snapshot created successfully (size: 477.63 KB).
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25/checkpoint_000000)<span class=" -Color -Color-Green"> [repeated 15x across cluster]</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0: : 135it [46:03, 20.47s/it, v_num=0, train_loss=0.176]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> `Trainer.fit` stopped: `max_epochs=1` reached.
<span class=" -Color -Color-Faint -Color-Faint-Cyan">(RayTrainWorker pid=66181)</span> RayFSDPStrategy: tearing down strategy...
2023-08-30 11:51:22,248	WARNING experiment_state.py:371 -- Experiment checkpoint syncing has been triggered multiple times in the last 30.0 seconds. A sync will be triggered whenever a trial has checkpointed more than `num_to_keep` times since last sync or if 300 seconds have passed since last sync. If you have set `num_to_keep` in your `CheckpointConfig`, consider increasing the checkpoint frequency or keeping more checkpoints. You can supress this warning by changing the `TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S` environment variable.
2023-08-30 11:51:22,253	INFO tune.py:1142 -- Total run time: 2877.24 seconds (2877.14 seconds for the tuning loop).
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Result(
  metrics={&#39;train_loss&#39;: 0.176025390625, &#39;epoch&#39;: 0, &#39;step&#39;: 135},
  path=&#39;/mnt/cluster_storage/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25&#39;,
  filesystem=&#39;local&#39;,
  checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/finetune_dolly-v2-7b/TorchTrainer_839b5_00000_0_2023-08-30_11-03-25/checkpoint_000000)
)
</pre></div>
</div>
</div>
</div>
<p>We finished training in 2877s. The price for an on-demand g4dn.4xlarge instance is <code class="docutils literal notranslate"><span class="pre">$1.204/hour</span></code>, while a g4dn.8xlarge instance costs <code class="docutils literal notranslate"><span class="pre">$2.176/hour</span></code>. The total cost would be <code class="docutils literal notranslate"><span class="pre">($1.204</span> <span class="pre">*</span> <span class="pre">15</span> <span class="pre">+</span> <span class="pre">$2.176)</span> <span class="pre">*</span> <span class="pre">2877</span> <span class="pre">/</span> <span class="pre">3600</span> <span class="pre">=</span> <span class="pre">$16.17</span></code>.</p>
</section>
<section id="text-generation-with-huggingface-pipeline">
<h2>Text-generation with HuggingFace Pipeline<a class="headerlink" href="#text-generation-with-huggingface-pipeline" title="Permalink to this headline">#</a></h2>
<p>We can use the <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/pipelines">HuggingFace Pipeline</a> to generate predictions from our fine-tuned model. Let’s input some prompts and see if our tuned Dolly can speak like Shakespeare:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">,</span> <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>

<span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;checkpoint.ckpt&quot;</span><span class="p">)</span>

<span class="n">dolly</span> <span class="o">=</span> <span class="n">DollyV2Model</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>

<span class="n">nlp_pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
    <span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span> 
    <span class="n">model</span><span class="o">=</span><span class="n">dolly</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> 
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;This is&quot;</span><span class="p">,</span> <span class="s2">&quot;I am&quot;</span><span class="p">,</span> <span class="s2">&quot;Once more&quot;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">nlp_pipeline</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;generated_text&#39;: &quot;This is the day that our hearts live to love. Now come, go in; I&#39;ll sit here:&quot;}]
[{&#39;generated_text&#39;: &#39;I am very sorry, not a jot. What would you have? your pardon? my good lord?&#39;}]
[{&#39;generated_text&#39;: &#39;Once more, look up, look up, my sovereign; look up this night!&#39;}]
</pre></div>
</div>
</div>
</div>
<p>References:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=8_k76AHu__s&amp;list=PL_lsbAsL_o2BT6aerEKgIoufVD_fodnuT">PyTorch FSDP Tutorial</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html#:~:text=FSDP%20is%20a%20type%20of,sizes%20for%20our%20training%20job.">Getting Started with Fully Sharded Data Parallel(FSDP)</a></p></li>
<li><p><a class="reference external" href="https://engineering.fb.com/2021/07/15/open-source/fsdp/">Fully Sharded Data Parallel: faster AI training with fewer GPUs</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/databricks/dolly-v2-7b">Hugging Face: dolly-v2-7b Model Card</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/docs/accelerate/usage_guides/big_modeling">Hugging Face: Handling big models for inference</a></p></li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>谢谢你的反馈！</span>
  </div>
  <div id="csat-inputs">
    <span>是否能帮助到你？</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>是<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>否<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">反馈</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">提交</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2024, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>