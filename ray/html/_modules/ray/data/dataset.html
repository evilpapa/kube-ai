
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.data.dataset &#8212; Ray 2.7.2</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/versionwarning.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../_static/js/docsearch.js"></script>
    <script defer="defer" src="../../../_static/js/csat.js"></script>
    <script defer="defer" src="../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../_static/js/top-navigation.js"></script>
    <script src="../../../_static/js/tags.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/data/dataset.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
  data-modal-disclaimer = "Results are automated and may be incorrect or contain inappropriate information. Do not include any personal data or confidential information."
  data-modal-title = "Ray Docs AI - Ask a Question"
  data-button-position-bottom = "60px"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 2.7.2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    欢迎来到 Ray ！
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/index.html">
   概述「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/getting-started.html">
   入门「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/installation.html">
   安装「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/use-cases.html">
   用例「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/examples.html">
   示例库「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/ray-libraries.html">
   生态「3%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/walkthrough.html">
   Ray 核心「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data/data.html">
   Ray 数据「75%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../train/train.html">
   Ray 训练「20%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../tune/index.html">
   Ray 调参「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../serve/index.html">
   Ray Serve「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rllib/index.html">
   Ray RLlib「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/index.html">
   更多类库「40%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cluster/getting-started.html">
   Ray 集群「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-observability/index.html">
   监控调试「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-references/api.html">
   参考「20%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-contribute/index.html">
   开发者指引「30%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-security/index.html">
   安全「100%」
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/data/dataset.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.data.dataset</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">html</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Generic</span><span class="p">,</span>
    <span class="n">Iterable</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Mapping</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">uuid</span> <span class="kn">import</span> <span class="n">uuid4</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.cloudpickle</span> <span class="k">as</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">ray._private.thirdparty.tabulate.tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">from</span> <span class="nn">ray._private.usage</span> <span class="kn">import</span> <span class="n">usage_lib</span>
<span class="kn">from</span> <span class="nn">ray.air.util.data_batch_conversion</span> <span class="kn">import</span> <span class="n">BlockFormat</span>
<span class="kn">from</span> <span class="nn">ray.air.util.tensor_extensions.utils</span> <span class="kn">import</span> <span class="n">_create_possibly_ragged_ndarray</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.block_list</span> <span class="kn">import</span> <span class="n">BlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.compute</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ActorPoolStrategy</span><span class="p">,</span>
    <span class="n">CallableClass</span><span class="p">,</span>
    <span class="n">ComputeStrategy</span><span class="p">,</span>
    <span class="n">TaskPoolStrategy</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.delegating_block_builder</span> <span class="kn">import</span> <span class="n">DelegatingBlockBuilder</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.equalize</span> <span class="kn">import</span> <span class="n">_equalize</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.execution.interfaces</span> <span class="kn">import</span> <span class="n">RefBundle</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.execution.legacy_compat</span> <span class="kn">import</span> <span class="n">_block_list_to_bundles</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.iterator.iterator_impl</span> <span class="kn">import</span> <span class="n">DataIteratorImpl</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.iterator.stream_split_iterator</span> <span class="kn">import</span> <span class="n">StreamSplitDataIterator</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.lazy_block_list</span> <span class="kn">import</span> <span class="n">LazyBlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.all_to_all_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">RandomizeBlocks</span><span class="p">,</span>
    <span class="n">RandomShuffle</span><span class="p">,</span>
    <span class="n">Repartition</span><span class="p">,</span>
    <span class="n">Sort</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.input_data_operator</span> <span class="kn">import</span> <span class="n">InputData</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.map_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Filter</span><span class="p">,</span>
    <span class="n">FlatMap</span><span class="p">,</span>
    <span class="n">MapBatches</span><span class="p">,</span>
    <span class="n">MapRows</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.n_ary_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Union</span> <span class="k">as</span> <span class="n">UnionLogicalOperator</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.n_ary_operator</span> <span class="kn">import</span> <span class="n">Zip</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.one_to_one_operator</span> <span class="kn">import</span> <span class="n">Limit</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.write_operator</span> <span class="kn">import</span> <span class="n">Write</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.optimizers</span> <span class="kn">import</span> <span class="n">LogicalPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">ExecutionPlan</span><span class="p">,</span> <span class="n">OneToOneStage</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.plan_udf_map_op</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">generate_filter_fn</span><span class="p">,</span>
    <span class="n">generate_flat_map_fn</span><span class="p">,</span>
    <span class="n">generate_map_batches_fn</span><span class="p">,</span>
    <span class="n">generate_map_rows_fn</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.plan_write_op</span> <span class="kn">import</span> <span class="n">generate_write_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.progress_bar</span> <span class="kn">import</span> <span class="n">ProgressBar</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.remote_fn</span> <span class="kn">import</span> <span class="n">cached_remote_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.sort</span> <span class="kn">import</span> <span class="n">SortKey</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.split</span> <span class="kn">import</span> <span class="n">_get_num_rows</span><span class="p">,</span> <span class="n">_split_at_indices</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.stage_impl</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LimitStage</span><span class="p">,</span>
    <span class="n">RandomizeBlocksStage</span><span class="p">,</span>
    <span class="n">RandomShuffleStage</span><span class="p">,</span>
    <span class="n">RepartitionStage</span><span class="p">,</span>
    <span class="n">SortStage</span><span class="p">,</span>
    <span class="n">ZipStage</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.stats</span> <span class="kn">import</span> <span class="n">DatasetStats</span><span class="p">,</span> <span class="n">DatasetStatsSummary</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.util</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConsumptionAPI</span><span class="p">,</span>
    <span class="n">_estimate_available_parallelism</span><span class="p">,</span>
    <span class="n">_is_local_scheme</span><span class="p">,</span>
    <span class="n">validate_compute</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.aggregate</span> <span class="kn">import</span> <span class="n">AggregateFn</span><span class="p">,</span> <span class="n">Max</span><span class="p">,</span> <span class="n">Mean</span><span class="p">,</span> <span class="n">Min</span><span class="p">,</span> <span class="n">Std</span><span class="p">,</span> <span class="n">Sum</span>
<span class="kn">from</span> <span class="nn">ray.data.block</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">VALID_BATCH_FORMATS</span><span class="p">,</span>
    <span class="n">Block</span><span class="p">,</span>
    <span class="n">BlockAccessor</span><span class="p">,</span>
    <span class="n">BlockMetadata</span><span class="p">,</span>
    <span class="n">BlockPartition</span><span class="p">,</span>
    <span class="n">DataBatch</span><span class="p">,</span>
    <span class="n">T</span><span class="p">,</span>
    <span class="n">U</span><span class="p">,</span>
    <span class="n">UserDefinedFunction</span><span class="p">,</span>
    <span class="n">_apply_strict_mode_batch_format</span><span class="p">,</span>
    <span class="n">_apply_strict_mode_batch_size</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.context</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ESTIMATED_SAFE_MEMORY_FRACTION</span><span class="p">,</span>
    <span class="n">OK_PREFIX</span><span class="p">,</span>
    <span class="n">WARN_PREFIX</span><span class="p">,</span>
    <span class="n">DataContext</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BlockWritePathProvider</span><span class="p">,</span>
    <span class="n">Connection</span><span class="p">,</span>
    <span class="n">CSVDatasource</span><span class="p">,</span>
    <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">DefaultBlockWritePathProvider</span><span class="p">,</span>
    <span class="n">ImageDatasource</span><span class="p">,</span>
    <span class="n">JSONDatasource</span><span class="p">,</span>
    <span class="n">NumpyDatasource</span><span class="p">,</span>
    <span class="n">ParquetDatasource</span><span class="p">,</span>
    <span class="n">ReadTask</span><span class="p">,</span>
    <span class="n">SQLDatasource</span><span class="p">,</span>
    <span class="n">TFRecordDatasource</span><span class="p">,</span>
    <span class="n">WriteResult</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.file_based_datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">,</span>
    <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.iterator</span> <span class="kn">import</span> <span class="n">DataIterator</span>
<span class="kn">from</span> <span class="nn">ray.data.random_access_dataset</span> <span class="kn">import</span> <span class="n">RandomAccessDataset</span>
<span class="kn">from</span> <span class="nn">ray.types</span> <span class="kn">import</span> <span class="n">ObjectRef</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">Deprecated</span><span class="p">,</span> <span class="n">DeveloperAPI</span><span class="p">,</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.util.scheduling_strategies</span> <span class="kn">import</span> <span class="n">NodeAffinitySchedulingStrategy</span>
<span class="kn">from</span> <span class="nn">ray.widgets</span> <span class="kn">import</span> <span class="n">Template</span>
<span class="kn">from</span> <span class="nn">ray.widgets.util</span> <span class="kn">import</span> <span class="n">repr_with_fallback</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">typing_extensions</span> <span class="kn">import</span> <span class="n">Literal</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dask</span>
    <span class="kn">import</span> <span class="nn">mars</span>
    <span class="kn">import</span> <span class="nn">modin</span>
    <span class="kn">import</span> <span class="nn">pandas</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span>
    <span class="kn">import</span> <span class="nn">pyspark</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.utils.data</span>
    <span class="kn">from</span> <span class="nn">tensorflow_metadata.proto.v0</span> <span class="kn">import</span> <span class="n">schema_pb2</span>

    <span class="kn">from</span> <span class="nn">ray.data._internal.execution.interfaces</span> <span class="kn">import</span> <span class="n">Executor</span><span class="p">,</span> <span class="n">NodeIdStr</span>
    <span class="kn">from</span> <span class="nn">ray.data.dataset_pipeline</span> <span class="kn">import</span> <span class="n">DatasetPipeline</span>
    <span class="kn">from</span> <span class="nn">ray.data.grouped_data</span> <span class="kn">import</span> <span class="n">GroupedData</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">TensorflowFeatureTypeSpec</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span>
    <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">TensorFlowTensorBatchType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">]]</span>

<span class="n">CollatedData</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;CollatedData&quot;</span><span class="p">)</span>
<span class="n">TorchBatchType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">],</span> <span class="n">CollatedData</span><span class="p">]</span>


<div class="viewcode-block" id="Dataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.html#ray.data.Dataset">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A Dataset is a distributed data collection for data loading and processing.</span>

<span class="sd">    Datasets are distributed pipelines that produce ``ObjectRef[Block]`` outputs,</span>
<span class="sd">    where each block holds data in Arrow format, representing a shard of the overall</span>
<span class="sd">    data collection. The block also determines the unit of parallelism. For more</span>
<span class="sd">    details, see :ref:`Ray Data Internals &lt;dataset_concept&gt;`.</span>

<span class="sd">    Datasets can be created in multiple ways: from synthetic data via ``range_*()``</span>
<span class="sd">    APIs, from existing memory data via ``from_*()`` APIs (this creates a subclass</span>
<span class="sd">    of Dataset called ``MaterializedDataset``), or from external storage</span>
<span class="sd">    systems such as local disk, S3, HDFS etc. via the ``read_*()`` APIs. The</span>
<span class="sd">    (potentially processed) Dataset can be saved back to external storage systems</span>
<span class="sd">    via the ``write_*()`` APIs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. testcode::</span>
<span class="sd">            :skipif: True</span>

<span class="sd">            import ray</span>
<span class="sd">            # Create dataset from synthetic data.</span>
<span class="sd">            ds = ray.data.range(1000)</span>
<span class="sd">            # Create dataset from in-memory data.</span>
<span class="sd">            ds = ray.data.from_items(</span>
<span class="sd">                [{&quot;col1&quot;: i, &quot;col2&quot;: i * 2} for i in range(1000)]</span>
<span class="sd">            )</span>
<span class="sd">            # Create dataset from external storage system.</span>
<span class="sd">            ds = ray.data.read_parquet(&quot;s3://bucket/path&quot;)</span>
<span class="sd">            # Save dataset back to external storage system.</span>
<span class="sd">            ds.write_csv(&quot;s3://bucket/output&quot;)</span>

<span class="sd">    Dataset has two kinds of operations: transformation, which takes in Dataset</span>
<span class="sd">    and outputs a new Dataset (e.g. :py:meth:`.map_batches()`); and consumption,</span>
<span class="sd">    which produces values (not a data stream) as output</span>
<span class="sd">    (e.g. :meth:`.iter_batches()`).</span>

<span class="sd">    Dataset transformations are lazy, with execution of the transformations being</span>
<span class="sd">    triggered by downstream consumption.</span>

<span class="sd">    Dataset supports parallel processing at scale: transformations such as</span>
<span class="sd">    :py:meth:`.map_batches()`, aggregations such as</span>
<span class="sd">    :py:meth:`.min()`/:py:meth:`.max()`/:py:meth:`.mean()`, grouping via</span>
<span class="sd">    :py:meth:`.groupby()`, shuffling operations such as :py:meth:`.sort()`,</span>
<span class="sd">    :py:meth:`.random_shuffle()`, and :py:meth:`.repartition()`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">        &gt;&gt;&gt; # Transform batches (Dict[str, np.ndarray]) with map_batches().</span>
<span class="sd">        &gt;&gt;&gt; ds.map_batches(lambda batch: {&quot;id&quot;: batch[&quot;id&quot;] * 2})  # doctest: +ELLIPSIS</span>
<span class="sd">        MapBatches(&lt;lambda&gt;)</span>
<span class="sd">        +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; # Compute the maximum.</span>
<span class="sd">        &gt;&gt;&gt; ds.max(&quot;id&quot;)</span>
<span class="sd">        999</span>
<span class="sd">        &gt;&gt;&gt; # Shuffle this dataset randomly.</span>
<span class="sd">        &gt;&gt;&gt; ds.random_shuffle()  # doctest: +ELLIPSIS</span>
<span class="sd">        RandomShuffle</span>
<span class="sd">        +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; # Sort it back in order.</span>
<span class="sd">        &gt;&gt;&gt; ds.sort(&quot;id&quot;)  # doctest: +ELLIPSIS</span>
<span class="sd">        Sort</span>
<span class="sd">        +- Dataset(num_blocks=..., num_rows=1000, schema={id: int64})</span>

<span class="sd">    Both unexecuted and materialized Datasets can be passed between Ray tasks and</span>
<span class="sd">    actors without incurring a copy. Dataset supports conversion to/from several</span>
<span class="sd">    more featureful dataframe libraries (e.g., Spark, Dask, Modin, MARS), and are also</span>
<span class="sd">    compatible with distributed TensorFlow / PyTorch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Dataset.__init__"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.__init__.html#ray.data.Dataset.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">plan</span><span class="p">:</span> <span class="n">ExecutionPlan</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">lazy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LogicalPlan</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a Dataset (internal API).</span>

<span class="sd">        The constructor is not part of the Dataset API. Use the ``ray.data.*``</span>
<span class="sd">        read methods to construct a dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">ExecutionPlan</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">plan</span><span class="p">)</span>
        <span class="n">usage_lib</span><span class="o">.</span><span class="n">record_library_usage</span><span class="p">(</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span>  <span class="c1"># Legacy telemetry name.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span> <span class="o">=</span> <span class="n">plan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">hex</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span> <span class="o">=</span> <span class="n">lazy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span> <span class="o">=</span> <span class="n">logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">link_logical_plan</span><span class="p">(</span><span class="n">logical_plan</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">lazy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">allow_clear_input_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Handle to currently running executor for this dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Executor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span>
        <span class="n">ds</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="n">_deep_copy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">_as</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">type</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_as</span><span class="p">:</span>
            <span class="n">_as</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_deep_copy</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_as</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">deep_copy</span><span class="p">(),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_as</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.map"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.map.html#ray.data.Dataset.map">[docs]</a>    <span class="k">def</span> <span class="nf">map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Apply the given function to each row of this dataset.</span>

<span class="sd">        Use this method to transform your data. To learn more, see</span>
<span class="sd">        :ref:`Transforming rows &lt;transforming_rows&gt;`.</span>

<span class="sd">        .. tip::</span>

<span class="sd">            If your transformation is vectorized like most NumPy or pandas operations,</span>
<span class="sd">            :meth:`~Dataset.map_batches` might be faster.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import os</span>
<span class="sd">                from typing import Any, Dict</span>
<span class="sd">                import ray</span>

<span class="sd">                def parse_filename(row: Dict[str, Any]) -&gt; Dict[str, Any]:</span>
<span class="sd">                    row[&quot;filename&quot;] = os.path.basename(row[&quot;path&quot;])</span>
<span class="sd">                    return row</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.read_images(&quot;s3://anonymous@ray-example-data/image-datasets/simple&quot;, include_paths=True)</span>
<span class="sd">                    .map(parse_filename)</span>
<span class="sd">                )</span>
<span class="sd">                print(ds.schema())</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                Column    Type</span>
<span class="sd">                ------    ----</span>
<span class="sd">                image     numpy.ndarray(shape=(32, 32, 3), dtype=uint8)</span>
<span class="sd">                path      string</span>
<span class="sd">                filename  string</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function to apply to each row, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy.</span>
<span class="sd">            compute: The compute strategy, either None (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            fn_constructor_args: Positional arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                You can only provide this if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map</span>
<span class="sd">                worker.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                Ray for each map worker.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.flat_map`</span>
<span class="sd">                Call this method to create new rows from existing ones. Unlike</span>
<span class="sd">                :meth:`~Dataset.map`, a function passed to</span>
<span class="sd">                :meth:`~Dataset.flat_map` can return multiple rows.</span>

<span class="sd">            :meth:`~Dataset.map_batches`</span>
<span class="sd">                Call this method to transform batches of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">,</span> <span class="n">fn_constructor_args</span><span class="p">)</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_map_rows_fn</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">OneToOneStage</span><span class="p">(</span>
                <span class="s2">&quot;Map&quot;</span><span class="p">,</span>
                <span class="n">transform_fn</span><span class="p">,</span>
                <span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="p">,</span>
                <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
                <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">map_op</span> <span class="o">=</span> <span class="n">MapRows</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="p">,</span>
                <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">map_op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.map_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.map_batches.html#ray.data.Dataset.map_batches">[docs]</a>    <span class="k">def</span> <span class="nf">map_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">DataBatch</span><span class="p">,</span> <span class="n">DataBatch</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">zero_copy_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fn_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Apply the given function to batches of data.</span>

<span class="sd">        This method is useful for preprocessing data and performing inference. To learn</span>
<span class="sd">        more, see :ref:`Transforming batches &lt;transforming_batches&gt;`.</span>

<span class="sd">        You can use either Ray Tasks or Ray Actors to perform the transformation. By</span>
<span class="sd">        default, Ray Data uses Tasks. To use Actors, see</span>
<span class="sd">        :ref:`Transforming batches with actors &lt;transforming_data_actors&gt;`.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If ``fn`` doesn&#39;t mutate its input, set ``zero_copy_batch=True`` to improve</span>
<span class="sd">            performance and decrease memory utilization.</span>

<span class="sd">        Examples:</span>

<span class="sd">            Call :meth:`~Dataset.map_batches` to transform your data.</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                from typing import Dict</span>
<span class="sd">                import numpy as np</span>
<span class="sd">                import ray</span>

<span class="sd">                def add_dog_years(batch: Dict[str, np.ndarray]) -&gt; Dict[str, np.ndarray]:</span>
<span class="sd">                    batch[&quot;age_in_dog_years&quot;] = 7 * batch[&quot;age&quot;]</span>
<span class="sd">                    return batch</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.from_items([</span>
<span class="sd">                        {&quot;name&quot;: &quot;Luna&quot;, &quot;age&quot;: 4},</span>
<span class="sd">                        {&quot;name&quot;: &quot;Rory&quot;, &quot;age&quot;: 14},</span>
<span class="sd">                        {&quot;name&quot;: &quot;Scout&quot;, &quot;age&quot;: 9},</span>
<span class="sd">                    ])</span>
<span class="sd">                    .map_batches(add_dog_years)</span>
<span class="sd">                )</span>
<span class="sd">                ds.show()</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                {&#39;name&#39;: &#39;Luna&#39;, &#39;age&#39;: 4, &#39;age_in_dog_years&#39;: 28}</span>
<span class="sd">                {&#39;name&#39;: &#39;Rory&#39;, &#39;age&#39;: 14, &#39;age_in_dog_years&#39;: 98}</span>
<span class="sd">                {&#39;name&#39;: &#39;Scout&#39;, &#39;age&#39;: 9, &#39;age_in_dog_years&#39;: 63}</span>

<span class="sd">            If your function returns large objects, yield outputs in chunks.</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                from typing import Dict</span>
<span class="sd">                import ray</span>
<span class="sd">                import numpy as np</span>

<span class="sd">                def map_fn_with_large_output(batch: Dict[str, np.ndarray]) -&gt; Dict[str, np.ndarray]:</span>
<span class="sd">                    for i in range(3):</span>
<span class="sd">                        yield {&quot;large_output&quot;: np.ones((100, 1000))}</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.from_items([1])</span>
<span class="sd">                    .map_batches(map_fn_with_large_output)</span>
<span class="sd">                )</span>

<span class="sd">            You can also use :meth:`~Dataset.map_batches` to perform offline inference.</span>
<span class="sd">            To learn more, see</span>
<span class="sd">            :ref:`End-to-end: Offline Batch Inference &lt;batch_inference_home&gt;`.</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function or generator to apply to a record batch, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy. Note ``fn`` must be</span>
<span class="sd">                pickle-able.</span>
<span class="sd">            batch_size: The desired number of rows in each batch, or ``None`` to use</span>
<span class="sd">                entire blocks as batches (blocks may contain different numbers of rows).</span>
<span class="sd">                The actual size of the batch provided to ``fn`` may be smaller than</span>
<span class="sd">                ``batch_size`` if ``batch_size`` doesn&#39;t evenly divide the block(s) sent</span>
<span class="sd">                to a given map task. Default batch_size is 4096 with &quot;default&quot;.</span>
<span class="sd">            compute: Either &quot;tasks&quot; (default) to use Ray Tasks or an</span>
<span class="sd">                :class:`~ray.data.ActorPoolStrategy` to use an autoscaling actor pool.</span>
<span class="sd">            batch_format: If ``&quot;default&quot;`` or ``&quot;numpy&quot;``, batches are</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``. If ``&quot;pandas&quot;``, batches are</span>
<span class="sd">                ``pandas.DataFrame``.</span>
<span class="sd">            zero_copy_batch: Whether ``fn`` should be provided zero-copy, read-only</span>
<span class="sd">                batches. If this is ``True`` and no copy is required for the</span>
<span class="sd">                ``batch_format`` conversion, the batch is a zero-copy, read-only</span>
<span class="sd">                view on data in Ray&#39;s object store, which can decrease memory</span>
<span class="sd">                utilization and improve performance. If this is ``False``, the batch</span>
<span class="sd">                is writable, which requires an extra copy to guarantee.</span>
<span class="sd">                If ``fn`` mutates its input, this needs to be ``False`` in order to</span>
<span class="sd">                avoid &quot;assignment destination is read-only&quot; or &quot;buffer source array is</span>
<span class="sd">                read-only&quot; errors. Default is ``False``.</span>
<span class="sd">            fn_args: Positional arguments to pass to ``fn`` after the first argument.</span>
<span class="sd">                These arguments are top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_kwargs: Keyword arguments to pass to ``fn``. These arguments are</span>
<span class="sd">                top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_constructor_args: Positional arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                You can only provide this if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            fn_constructor_kwargs: Keyword arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                This can only be provided if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map worker.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray for each map worker.</span>

<span class="sd">        .. note::</span>

<span class="sd">            The size of the batches provided to ``fn`` might be smaller than the</span>
<span class="sd">            specified ``batch_size`` if ``batch_size`` doesn&#39;t evenly divide the</span>
<span class="sd">            block(s) sent to a given map task.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.iter_batches`</span>
<span class="sd">                Call this function to iterate over batches of data.</span>

<span class="sd">            :meth:`~Dataset.flat_map`</span>
<span class="sd">                Call this method to create new records from existing ones. Unlike</span>
<span class="sd">                :meth:`~Dataset.map`, a function passed to :meth:`~Dataset.flat_map`</span>
<span class="sd">                can return multiple records.</span>

<span class="sd">            :meth:`~Dataset.map`</span>
<span class="sd">                Call this method to transform one record at time.</span>

<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_format</span> <span class="o">==</span> <span class="s2">&quot;native&quot;</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;The &#39;native&#39; batch format has been renamed &#39;default&#39;.&quot;</span><span class="p">)</span>

        <span class="n">target_block_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Batch size cannot be negative or 0&quot;</span><span class="p">)</span>
            <span class="c1"># Enable blocks bundling when batch_size is specified by caller.</span>
            <span class="n">target_block_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_size</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="s2">&quot;num_gpus&quot;</span> <span class="ow">in</span> <span class="n">ray_remote_args</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">batch_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">VALID_BATCH_FORMATS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The batch format must be one of </span><span class="si">{</span><span class="n">VALID_BATCH_FORMATS</span><span class="si">}</span><span class="s2">, got: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">batch_format</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">,</span> <span class="n">fn_constructor_args</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fn_constructor_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">compute</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="n">compute</span> <span class="o">!=</span> <span class="s2">&quot;actors&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">compute</span><span class="p">,</span> <span class="n">ActorPoolStrategy</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;fn_constructor_kwargs can only be specified if using the actor &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;pool compute strategy, but got: </span><span class="si">{</span><span class="n">compute</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">CallableClass</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;fn_constructor_kwargs can only be specified if providing a &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;CallableClass instance for fn, but got: </span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_map_batches_fn</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="n">zero_copy_batch</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># TODO(chengsu): pass function name to MapBatches logical operator.</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;__self__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">fn</span><span class="o">.</span><span class="vm">__self__</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">preprocessor</span><span class="o">.</span><span class="n">Preprocessor</span>
        <span class="p">):</span>
            <span class="n">stage_name</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="vm">__self__</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stage_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;MapBatches(</span><span class="si">{</span><span class="nb">getattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;__name__&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span><span class="si">}</span><span class="s1">)&#39;</span>

        <span class="n">stage</span> <span class="o">=</span> <span class="n">OneToOneStage</span><span class="p">(</span>
            <span class="n">stage_name</span><span class="p">,</span>
            <span class="n">transform_fn</span><span class="p">,</span>
            <span class="n">compute</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="c1"># TODO(Clark): Add a strict cap here.</span>
            <span class="n">target_block_size</span><span class="o">=</span><span class="n">target_block_size</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">map_batches_op</span> <span class="o">=</span> <span class="n">MapBatches</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
                <span class="n">zero_copy_batch</span><span class="o">=</span><span class="n">zero_copy_batch</span><span class="p">,</span>
                <span class="n">target_block_size</span><span class="o">=</span><span class="n">target_block_size</span><span class="p">,</span>
                <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
                <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
                <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
                <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">map_batches_op</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.add_column"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.add_column.html#ray.data.Dataset.add_column">[docs]</a>    <span class="k">def</span> <span class="nf">add_column</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">],</span> <span class="s2">&quot;pandas.Series&quot;</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Add the given column to the dataset.</span>

<span class="sd">        A function generating the new column values given the batch in pandas</span>
<span class="sd">        format must be specified.</span>

<span class="sd">        Examples:</span>


<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column  Type</span>
<span class="sd">            ------  ----</span>
<span class="sd">            id      int64</span>

<span class="sd">            Add a new column equal to ``id * 2``.</span>

<span class="sd">            &gt;&gt;&gt; ds.add_column(&quot;new_id&quot;, lambda df: df[&quot;id&quot;] * 2).schema()</span>
<span class="sd">            Column  Type</span>
<span class="sd">            ------  ----</span>
<span class="sd">            id      int64</span>
<span class="sd">            new_id  int64</span>

<span class="sd">            Overwrite the existing values with zeros.</span>

<span class="sd">            &gt;&gt;&gt; ds.add_column(&quot;id&quot;, lambda df: 0).take(3)</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 0}, {&#39;id&#39;: 0}]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            col: Name of the column to add. If the name already exists, the</span>
<span class="sd">                column is overwritten.</span>
<span class="sd">            fn: Map function generating the column values given a batch of</span>
<span class="sd">                records in pandas format.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">:</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">batch</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`fn` must be callable, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="n">process_batch</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>  <span class="c1"># TODO(ekl) we should make this configurable.</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.drop_columns"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.drop_columns.html#ray.data.Dataset.drop_columns">[docs]</a>    <span class="k">def</span> <span class="nf">drop_columns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cols</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Drop one or more columns from the dataset.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>
<span class="sd">            petal.length  double</span>
<span class="sd">            petal.width   double</span>
<span class="sd">            variety       string</span>
<span class="sd">            &gt;&gt;&gt; ds.drop_columns([&quot;variety&quot;]).schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>
<span class="sd">            petal.length  double</span>
<span class="sd">            petal.width   double</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            cols: Names of the columns to drop. If any name does not exist,</span>
<span class="sd">                an exception is raised.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">batch</span><span class="p">:</span> <span class="n">batch</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">),</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.select_columns"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.select_columns.html#ray.data.Dataset.select_columns">[docs]</a>    <span class="k">def</span> <span class="nf">select_columns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cols</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Select one or more columns from the dataset.</span>

<span class="sd">        Specified columns must be in the dataset schema.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>
<span class="sd">            petal.length  double</span>
<span class="sd">            petal.width   double</span>
<span class="sd">            variety       string</span>
<span class="sd">            &gt;&gt;&gt; ds.select_columns([&quot;sepal.length&quot;, &quot;sepal.width&quot;]).schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            cols: Names of the columns to select. If a name isn&#39;t in the</span>
<span class="sd">                dataset schema, an exception is raised.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">batch</span><span class="p">:</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">),</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.flat_map"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.flat_map.html#ray.data.Dataset.flat_map">[docs]</a>    <span class="k">def</span> <span class="nf">flat_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Apply the given function to each row and then flatten results.</span>

<span class="sd">        Use this method if your transformation returns multiple rows for each input</span>
<span class="sd">        row.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            :meth:`~Dataset.map_batches` can also modify the number of rows. If your</span>
<span class="sd">            transformation is vectorized like most NumPy and pandas operations,</span>
<span class="sd">            it might be faster.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                from typing import Any, Dict, List</span>
<span class="sd">                import ray</span>

<span class="sd">                def duplicate_row(row: Dict[str, Any]) -&gt; List[Dict[str, Any]]:</span>
<span class="sd">                    return [row] * 2</span>

<span class="sd">                print(</span>
<span class="sd">                    ray.data.range(3)</span>
<span class="sd">                    .flat_map(duplicate_row)</span>
<span class="sd">                    .take_all()</span>
<span class="sd">                )</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                [{&#39;id&#39;: 0}, {&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}, {&#39;id&#39;: 2}]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function or generator to apply to each record, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            fn_constructor_args: Positional arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                You can only provide this if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map</span>
<span class="sd">                worker.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray for each map worker.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.map_batches`</span>
<span class="sd">                Call this method to transform batches of data.</span>

<span class="sd">            :meth:`~Dataset.map`</span>
<span class="sd">                Call this method to transform one row at time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">,</span> <span class="n">fn_constructor_args</span><span class="p">)</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_flat_map_fn</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">OneToOneStage</span><span class="p">(</span>
                <span class="s2">&quot;FlatMap&quot;</span><span class="p">,</span>
                <span class="n">transform_fn</span><span class="p">,</span>
                <span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="p">,</span>
                <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
                <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">FlatMap</span><span class="p">(</span>
                <span class="n">input_op</span><span class="o">=</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
                <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.filter"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.filter.html#ray.data.Dataset.filter">[docs]</a>    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="nb">bool</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Filter out rows that don&#39;t satisfy the given predicate.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If you can represent your predicate with NumPy or pandas operations,</span>
<span class="sd">            :meth:`Dataset.map_batches` might be faster. You can implement filter by</span>
<span class="sd">            dropping rows.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.filter(lambda row: row[&quot;id&quot;] % 2 == 0).take_all()</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 2}, {&#39;id&#39;: 4}, ...]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The predicate to apply to each row, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Callable classes are</span>
<span class="sd">                only supported for the actor compute strategy.</span>
<span class="sd">            compute: The compute strategy, either &quot;tasks&quot; (default) to use Ray</span>
<span class="sd">                tasks, ``ray.data.ActorPoolStrategy(size=n)`` to use a fixed-size actor</span>
<span class="sd">                pool, or ``ray.data.ActorPoolStrategy(min_size=m, max_size=n)`` for an</span>
<span class="sd">                autoscaling actor pool.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_compute</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">)</span>

        <span class="n">transform_fn</span> <span class="o">=</span> <span class="n">generate_filter_fn</span><span class="p">()</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">OneToOneStage</span><span class="p">(</span><span class="s2">&quot;Filter&quot;</span><span class="p">,</span> <span class="n">transform_fn</span><span class="p">,</span> <span class="n">compute</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Filter</span><span class="p">(</span>
                <span class="n">input_op</span><span class="o">=</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
                <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.repartition"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.repartition.html#ray.data.Dataset.repartition">[docs]</a>    <span class="k">def</span> <span class="nf">repartition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Repartition the :class:`Dataset` into exactly this number of :ref:`blocks &lt;dataset_concept&gt;`.</span>

<span class="sd">        This method can be useful to tune the performance of your pipeline. To learn</span>
<span class="sd">        more, see :ref:`Advanced: Performance Tips and Tuning &lt;data_performance_tips&gt;`.</span>

<span class="sd">        If you&#39;re writing data to files, you can also use this method to change the</span>
<span class="sd">        number of output files. To learn more, see</span>
<span class="sd">        :ref:`Changing the number of output files &lt;changing-number-output-files&gt;`.</span>

<span class="sd">        .. note::</span>

<span class="sd">            Repartition has two modes. If ``shuffle=False``, Ray Data performs the</span>
<span class="sd">            minimal data movement needed to equalize block sizes. Otherwise, Ray Data</span>
<span class="sd">            performs a full distributed shuffle.</span>

<span class="sd">            .. image:: /data/images/dataset-shuffle.svg</span>
<span class="sd">                :align: center</span>

<span class="sd">            ..</span>
<span class="sd">                https://docs.google.com/drawings/d/132jhE3KXZsf29ho1yUdPrCHB9uheHBWHJhDQMXqIVPA/edit</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.repartition(10).num_blocks()</span>
<span class="sd">            10</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            num_blocks: The number of blocks.</span>
<span class="sd">            shuffle: Whether to perform a distributed shuffle during the</span>
<span class="sd">                repartition. When shuffle is enabled, each output block</span>
<span class="sd">                contains a subset of data rows from each input block, which</span>
<span class="sd">                requires all-to-all data movement. When shuffle is disabled,</span>
<span class="sd">                output blocks are created from adjacent input blocks,</span>
<span class="sd">                minimizing data movement.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The repartitioned :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">RepartitionStage</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Repartition</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.random_shuffle"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.random_shuffle.html#ray.data.Dataset.random_shuffle">[docs]</a>    <span class="k">def</span> <span class="nf">random_shuffle</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Randomly shuffle the rows of this :class:`Dataset`.</span>

<span class="sd">        .. tip::</span>

<span class="sd">            This method can be slow. For better performance, try</span>
<span class="sd">            `Iterating over batches with shuffling &lt;iterating-over-data#iterating-over-batches-with-shuffling&gt;`_.</span>
<span class="sd">            Also, see :ref:`Optimizing shuffles &lt;optimizing_shuffles&gt;`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.random_shuffle().take(3)  # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: 41}, {&#39;id&#39;: 21}, {&#39;id&#39;: 92}]</span>
<span class="sd">            &gt;&gt;&gt; ds.random_shuffle(seed=42).take(3)  # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: 77}, {&#39;id&#39;: 21}, {&#39;id&#39;: 63}]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: Fix the random seed to use, otherwise one is chosen</span>
<span class="sd">                based on system randomness.</span>
<span class="sd">            num_blocks: The number of output blocks after the shuffle, or ``None``</span>
<span class="sd">                to retain the number of blocks.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The shuffled :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
            <span class="n">RandomShuffleStage</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">RandomShuffle</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
                <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.randomize_block_order"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.randomize_block_order.html#ray.data.Dataset.randomize_block_order">[docs]</a>    <span class="k">def</span> <span class="nf">randomize_block_order</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Randomly shuffle the :ref:`blocks &lt;dataset_concept&gt;` of this :class:`Dataset`.</span>

<span class="sd">        This method is useful if you :meth:`~Dataset.split` your dataset into shards and</span>
<span class="sd">        want to randomize the data in each shard without performing a full</span>
<span class="sd">        :meth:`~Dataset.random_shuffle`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.take(5)</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}, {&#39;id&#39;: 3}, {&#39;id&#39;: 4}]</span>
<span class="sd">            &gt;&gt;&gt; ds.randomize_block_order().take(5)  # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: 15}, {&#39;id&#39;: 16}, {&#39;id&#39;: 17}, {&#39;id&#39;: 18}, {&#39;id&#39;: 19}]</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: Fix the random seed to use, otherwise one is chosen</span>
<span class="sd">                based on system randomness.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The block-shuffled :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">RandomizeBlocksStage</span><span class="p">(</span><span class="n">seed</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">RandomizeBlocks</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.random_sample"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.random_sample.html#ray.data.Dataset.random_sample">[docs]</a>    <span class="k">def</span> <span class="nf">random_sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">fraction</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a new :class:`Dataset` containing a random fraction of the rows.</span>

<span class="sd">        .. note::</span>

<span class="sd">            This method returns roughly ``fraction * total_rows`` rows. An exact number</span>
<span class="sd">            of rows isn&#39;t guaranteed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.random_sample(0.1).count()  # doctest: +SKIP</span>
<span class="sd">            10</span>

<span class="sd">        Args:</span>
<span class="sd">            fraction: The fraction of elements to sample.</span>
<span class="sd">            seed: Seeds the python random pRNG generator.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Returns a :class:`Dataset` containing the sampled rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">random</span>

        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_blocks</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot sample from an empty Dataset.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fraction</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">fraction</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fraction must be between 0 and 1.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">):</span>
                <span class="c1"># Lets the item pass if weight generated for that item &lt;= fraction</span>
                <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)))</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="n">fraction</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">_create_possibly_ragged_ndarray</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported batch type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.streaming_split"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.streaming_split.html#ray.data.Dataset.streaming_split">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">streaming_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">equal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">locality_hints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;NodeIdStr&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">DataIterator</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns ``n`` :class:`DataIterators &lt;ray.data.DataIterator&gt;` that can</span>
<span class="sd">        be used to read disjoint subsets of the dataset in parallel.</span>

<span class="sd">        This method is the recommended way to consume :class:`Datasets &lt;Dataset&gt;` for</span>
<span class="sd">        distributed training.</span>

<span class="sd">        Streaming split works by delegating the execution of this :class:`Dataset` to a</span>
<span class="sd">        coordinator actor. The coordinator pulls block references from the executed</span>
<span class="sd">        stream, and divides those blocks among ``n`` output iterators. Iterators pull</span>
<span class="sd">        blocks from the coordinator actor to return to their caller on ``next``.</span>

<span class="sd">        The returned iterators are also repeatable; each iteration will trigger a</span>
<span class="sd">        new execution of the Dataset. There is an implicit barrier at the start of</span>
<span class="sd">        each iteration, which means that `next` must be called on all iterators before</span>
<span class="sd">        the iteration starts.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            Because iterators are pulling blocks from the same :class:`Dataset`</span>
<span class="sd">            execution, if one iterator falls behind, other iterators may be stalled.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.range(100)</span>
<span class="sd">                it1, it2 = ds.streaming_split(2, equal=True)</span>

<span class="sd">            Consume data from iterators in parallel.</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                @ray.remote</span>
<span class="sd">                def consume(it):</span>
<span class="sd">                    for batch in it.iter_batches():</span>
<span class="sd">                       pass</span>

<span class="sd">                ray.get([consume.remote(it1), consume.remote(it2)])</span>

<span class="sd">            You can loop over the iterators multiple times (multiple epochs).</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                @ray.remote</span>
<span class="sd">                def train(it):</span>
<span class="sd">                    NUM_EPOCHS = 2</span>
<span class="sd">                    for _ in range(NUM_EPOCHS):</span>
<span class="sd">                        for batch in it.iter_batches():</span>
<span class="sd">                            pass</span>

<span class="sd">                ray.get([train.remote(it1), train.remote(it2)])</span>

<span class="sd">            The following remote function call blocks waiting for a read on ``it2`` to</span>
<span class="sd">            start.</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :skipif: True</span>

<span class="sd">                ray.get(train.remote(it1))</span>

<span class="sd">        Args:</span>
<span class="sd">            n: Number of output iterators to return.</span>
<span class="sd">            equal: If ``True``, each output iterator sees an exactly equal number</span>
<span class="sd">                of rows, dropping data if necessary. If ``False``, some iterators may</span>
<span class="sd">                see slightly more or less rows than others, but no data is dropped.</span>
<span class="sd">            locality_hints: Specify the node ids corresponding to each iterator</span>
<span class="sd">                location. Dataset will try to minimize data movement based on the</span>
<span class="sd">                iterator output locations. This list must have length ``n``. You can</span>
<span class="sd">                get the current node id of a task or actor by calling</span>
<span class="sd">                ``ray.get_runtime_context().get_node_id()``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The output iterator splits. These iterators are Ray-serializable and can</span>
<span class="sd">            be freely passed to any Ray task or actor.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split`</span>
<span class="sd">                Unlike :meth:`~Dataset.streaming_split`, :meth:`~Dataset.split`</span>
<span class="sd">                materializes the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">StreamSplitDataIterator</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">equal</span><span class="p">,</span> <span class="n">locality_hints</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.split"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split.html#ray.data.Dataset.split">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">equal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">locality_hints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset into ``n`` disjoint pieces.</span>

<span class="sd">        This method returns a list of ``MaterializedDataset`` that can be passed to Ray</span>
<span class="sd">        Tasks and Actors and used to read the dataset rows in parallel.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                @ray.remote</span>
<span class="sd">                class Worker:</span>

<span class="sd">                    def train(self, data_iterator):</span>
<span class="sd">                        for batch in data_iterator.iter_batches(batch_size=8):</span>
<span class="sd">                            pass</span>

<span class="sd">                workers = [Worker.remote() for _ in range(4)]</span>
<span class="sd">                shards = ray.data.range(100).split(n=4, equal=True)</span>
<span class="sd">                ray.get([w.train.remote(s) for w, s in zip(workers, shards)])</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            n: Number of child datasets to return.</span>
<span class="sd">            equal: Whether to guarantee each split has an equal</span>
<span class="sd">                number of records. This might drop records if the rows can&#39;t be</span>
<span class="sd">                divided equally among the splits.</span>
<span class="sd">            locality_hints: [Experimental] A list of Ray actor handles of size ``n``.</span>
<span class="sd">                The system tries to co-locate the blocks of the i-th dataset</span>
<span class="sd">                with the i-th actor to maximize data locality.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of ``n`` disjoint dataset splits.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split_at_indices`</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, which splits a dataset into approximately</span>
<span class="sd">                equal splits, :meth:`Dataset.split_proportionately` lets you split a</span>
<span class="sd">                dataset into different sizes.</span>

<span class="sd">            :meth:`Dataset.split_proportionately`</span>
<span class="sd">                This method is equivalent to :meth:`Dataset.split_at_indices` if</span>
<span class="sd">                you compute indices manually.</span>

<span class="sd">            :meth:`Dataset.streaming_split`.</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, :meth:`~Dataset.streaming_split`</span>
<span class="sd">                doesn&#39;t materialize the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The number of splits </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is not positive.&quot;</span><span class="p">)</span>

        <span class="c1"># fallback to split_at_indices for equal split without locality hints.</span>
        <span class="c1"># simple benchmarks shows spilit_at_indices yields more stable performance.</span>
        <span class="c1"># https://github.com/ray-project/ray/pull/26641 for more context.</span>
        <span class="k">if</span> <span class="n">equal</span> <span class="ow">and</span> <span class="n">locality_hints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
            <span class="n">split_index</span> <span class="o">=</span> <span class="n">count</span> <span class="o">//</span> <span class="n">n</span>
            <span class="c1"># we are creating n split_indices which will generate</span>
            <span class="c1"># n + 1 splits; the last split will at most contains (n - 1)</span>
            <span class="c1"># rows, which could be safely dropped.</span>
            <span class="n">split_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">split_index</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">shards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">shards</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">locality_hints</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The length of locality_hints </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;doesn&#39;t equal the number of splits </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
            <span class="c1"># TODO: this is unreachable code.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;locality_hints must not contain duplicate actor handles&quot;</span>
                <span class="p">)</span>

        <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">owned_by_consumer</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="n">block_refs</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">blocks</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">locality_hints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">block_refs</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="n">meta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

            <span class="n">split_datasets</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">meta</span><span class="p">):</span>
                <span class="n">block_list</span> <span class="o">=</span> <span class="n">BlockList</span><span class="p">(</span>
                    <span class="n">b</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">m</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span>
                <span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span>
                <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">ref_bundles</span> <span class="o">=</span> <span class="n">_block_list_to_bundles</span><span class="p">(</span><span class="n">block_list</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="p">)</span>
                    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
                <span class="n">split_datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">MaterializedDataset</span><span class="p">(</span>
                        <span class="n">ExecutionPlan</span><span class="p">(</span>
                            <span class="n">block_list</span><span class="p">,</span>
                            <span class="n">stats</span><span class="p">,</span>
                            <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
                        <span class="n">logical_plan</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">split_datasets</span>

        <span class="n">metadata_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="n">b</span><span class="p">:</span> <span class="n">m</span> <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">block_refs</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)}</span>

        <span class="c1"># If the locality_hints is set, we use a two-round greedy algorithm</span>
        <span class="c1"># to co-locate the blocks with the actors based on block</span>
        <span class="c1"># and actor&#39;s location (node_id).</span>
        <span class="c1">#</span>
        <span class="c1"># The split algorithm tries to allocate equally-sized blocks regardless</span>
        <span class="c1"># of locality. Thus we first calculate the expected number of blocks</span>
        <span class="c1"># for each split.</span>
        <span class="c1">#</span>
        <span class="c1"># In the first round, for each actor, we look for all blocks that</span>
        <span class="c1"># match the actor&#39;s node_id, then allocate those matched blocks to</span>
        <span class="c1"># this actor until we reach the limit(expected number).</span>
        <span class="c1">#</span>
        <span class="c1"># In the second round: fill each actor&#39;s allocation with</span>
        <span class="c1"># remaining unallocated blocks until we reach the limit.</span>

        <span class="k">def</span> <span class="nf">build_allocation_size_map</span><span class="p">(</span>
            <span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">actors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Given the total number of blocks and a list of actors, calcuate</span>
<span class="sd">            the expected number of blocks to allocate for each actor.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">num_actors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actors</span><span class="p">)</span>
            <span class="n">num_blocks_per_actor</span> <span class="o">=</span> <span class="n">num_blocks</span> <span class="o">//</span> <span class="n">num_actors</span>
            <span class="n">num_blocks_left</span> <span class="o">=</span> <span class="n">num_blocks</span> <span class="o">-</span> <span class="n">num_blocks_per_actor</span> <span class="o">*</span> <span class="n">n</span>
            <span class="n">num_blocks_by_actor</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">actor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">actors</span><span class="p">):</span>
                <span class="n">num_blocks_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_blocks_per_actor</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_blocks_left</span><span class="p">:</span>
                    <span class="n">num_blocks_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">num_blocks_by_actor</span>

        <span class="k">def</span> <span class="nf">build_block_refs_by_node_id</span><span class="p">(</span>
            <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]],</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]]:</span>
            <span class="sd">&quot;&quot;&quot;Build the reverse index from node_id to block_refs. For</span>
<span class="sd">            simplicity, if the block is stored on multiple nodes we</span>
<span class="sd">            only pick the first one.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">block_ref_locations</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">get_object_locations</span><span class="p">(</span><span class="n">blocks</span><span class="p">)</span>
            <span class="n">block_refs_by_node_id</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">:</span>
                <span class="n">node_ids</span> <span class="o">=</span> <span class="n">block_ref_locations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block_ref</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node_ids&quot;</span><span class="p">,</span> <span class="p">[])</span>
                <span class="n">node_id</span> <span class="o">=</span> <span class="n">node_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">node_ids</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="n">block_refs_by_node_id</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block_ref</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">block_refs_by_node_id</span>

        <span class="k">def</span> <span class="nf">build_node_id_by_actor</span><span class="p">(</span><span class="n">actors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Build a map from a actor to its node_id.&quot;&quot;&quot;</span>
            <span class="n">actors_state</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">actors</span><span class="p">()</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">actor</span><span class="p">:</span> <span class="n">actors_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">actor</span><span class="o">.</span><span class="n">_actor_id</span><span class="o">.</span><span class="n">hex</span><span class="p">(),</span> <span class="p">{})</span>
                <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;Address&quot;</span><span class="p">,</span> <span class="p">{})</span>
                <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;NodeID&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">actors</span>
            <span class="p">}</span>

        <span class="c1"># expected number of blocks to be allocated for each actor</span>
        <span class="n">expected_block_count_by_actor</span> <span class="o">=</span> <span class="n">build_allocation_size_map</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">block_refs</span><span class="p">),</span> <span class="n">locality_hints</span>
        <span class="p">)</span>
        <span class="c1"># the reverse index from node_id to block_refs</span>
        <span class="n">block_refs_by_node_id</span> <span class="o">=</span> <span class="n">build_block_refs_by_node_id</span><span class="p">(</span><span class="n">block_refs</span><span class="p">)</span>
        <span class="c1"># the map from actor to its node_id</span>
        <span class="n">node_id_by_actor</span> <span class="o">=</span> <span class="n">build_node_id_by_actor</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span>

        <span class="n">allocation_per_actor</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

        <span class="c1"># In the first round, for each actor, we look for all blocks that</span>
        <span class="c1"># match the actor&#39;s node_id, then allocate those matched blocks to</span>
        <span class="c1"># this actor until we reach the limit(expected number)</span>
        <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span><span class="p">:</span>
            <span class="n">node_id</span> <span class="o">=</span> <span class="n">node_id_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="n">matching_blocks</span> <span class="o">=</span> <span class="n">block_refs_by_node_id</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span>
            <span class="n">expected_block_count</span> <span class="o">=</span> <span class="n">expected_block_count_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="n">allocation</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="n">matching_blocks</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">allocation</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">expected_block_count</span><span class="p">:</span>
                <span class="n">allocation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matching_blocks</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>
            <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">=</span> <span class="n">allocation</span>

        <span class="c1"># In the second round: fill each actor&#39;s allocation with</span>
        <span class="c1"># remaining unallocated blocks until we reach the limit</span>
        <span class="n">remaining_block_refs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">block_refs_by_node_id</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span><span class="p">:</span>
            <span class="k">while</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">expected_block_count_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="p">)</span>

        <span class="n">per_split_block_lists</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">BlockList</span><span class="p">(</span>
                <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">],</span>
                <span class="p">[</span><span class="n">metadata_mapping</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]],</span>
                <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">equal</span><span class="p">:</span>
            <span class="c1"># equalize the splits</span>
            <span class="n">per_split_block_lists</span> <span class="o">=</span> <span class="n">_equalize</span><span class="p">(</span><span class="n">per_split_block_lists</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="p">)</span>

        <span class="n">split_datasets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">block_split</span> <span class="ow">in</span> <span class="n">per_split_block_lists</span><span class="p">:</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span>
            <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ref_bundles</span> <span class="o">=</span> <span class="n">_block_list_to_bundles</span><span class="p">(</span><span class="n">block_split</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
            <span class="n">split_datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">MaterializedDataset</span><span class="p">(</span>
                    <span class="n">ExecutionPlan</span><span class="p">(</span>
                        <span class="n">block_split</span><span class="p">,</span>
                        <span class="n">stats</span><span class="p">,</span>
                        <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
                    <span class="n">logical_plan</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">split_datasets</span></div>

<div class="viewcode-block" id="Dataset.split_at_indices"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split_at_indices.html#ray.data.Dataset.split_at_indices">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">split_at_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset at the given indices (like ``np.split``).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; d1, d2, d3 = ds.split_at_indices([2, 5])</span>
<span class="sd">            &gt;&gt;&gt; d1.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1])}</span>
<span class="sd">            &gt;&gt;&gt; d2.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 4])}</span>
<span class="sd">            &gt;&gt;&gt; d3.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([5, 6, 7, 8, 9])}</span>

<span class="sd">        Time complexity: O(num splits)</span>

<span class="sd">        Args:</span>
<span class="sd">            indices: List of sorted integers which indicate where the dataset</span>
<span class="sd">                are split. If an index exceeds the length of the dataset,</span>
<span class="sd">                an empty dataset is returned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The dataset splits.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split`</span>
<span class="sd">                Unlike :meth:`~Dataset.split_at_indices`, which lets you split a</span>
<span class="sd">                dataset into different sizes, :meth:`Dataset.split` splits a dataset</span>
<span class="sd">                into approximately equal splits.</span>

<span class="sd">            :meth:`Dataset.split_proportionately`</span>
<span class="sd">                This method is equivalent to :meth:`Dataset.split_at_indices` if</span>
<span class="sd">                you compute indices manually.</span>

<span class="sd">            :meth:`Dataset.streaming_split`.</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, :meth:`~Dataset.streaming_split`</span>
<span class="sd">                doesn&#39;t materialize the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be at least of length 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">!=</span> <span class="n">indices</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be sorted&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be positive&quot;</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">block_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="n">_split_at_indices</span><span class="p">(</span>
            <span class="n">block_list</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">(),</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">split_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="n">parent_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
            <span class="n">stats</span> <span class="o">=</span> <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Split&quot;</span><span class="p">:</span> <span class="n">ms</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="n">parent_stats</span><span class="p">)</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">time_total_s</span> <span class="o">=</span> <span class="n">split_duration</span>

            <span class="n">split_block_list</span> <span class="o">=</span> <span class="n">BlockList</span><span class="p">(</span>
                <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span>
            <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ref_bundles</span> <span class="o">=</span> <span class="n">_block_list_to_bundles</span><span class="p">(</span>
                    <span class="n">split_block_list</span><span class="p">,</span> <span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
                <span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>

            <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">MaterializedDataset</span><span class="p">(</span>
                    <span class="n">ExecutionPlan</span><span class="p">(</span>
                        <span class="n">split_block_list</span><span class="p">,</span>
                        <span class="n">stats</span><span class="p">,</span>
                        <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
                    <span class="n">logical_plan</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">splits</span></div>

<div class="viewcode-block" id="Dataset.split_proportionately"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split_proportionately.html#ray.data.Dataset.split_proportionately">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">split_proportionately</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">proportions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset using proportions.</span>

<span class="sd">        A common use case for this is splitting the dataset into train</span>
<span class="sd">        and test sets (equivalent to eg. scikit-learn&#39;s ``train_test_split``).</span>
<span class="sd">        For a higher level abstraction, see :meth:`Dataset.train_test_split`.</span>

<span class="sd">        This method splits datasets so that all splits</span>
<span class="sd">        always contains at least one row. If that isn&#39;t possible,</span>
<span class="sd">        an exception is raised.</span>

<span class="sd">        This is equivalent to caulculating the indices manually and calling</span>
<span class="sd">        :meth:`Dataset.split_at_indices`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; d1, d2, d3 = ds.split_proportionately([0.2, 0.5])</span>
<span class="sd">            &gt;&gt;&gt; d1.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1])}</span>
<span class="sd">            &gt;&gt;&gt; d2.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 4, 5, 6])}</span>
<span class="sd">            &gt;&gt;&gt; d3.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([7, 8, 9])}</span>

<span class="sd">        Time complexity: O(num splits)</span>

<span class="sd">        Args:</span>
<span class="sd">            proportions: List of proportions to split the dataset according to.</span>
<span class="sd">                Must sum up to less than 1, and each proportion must be bigger</span>
<span class="sd">                than 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The dataset splits.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split`</span>
<span class="sd">                Unlike :meth:`~Dataset.split_proportionately`, which lets you split a</span>
<span class="sd">                dataset into different sizes, :meth:`Dataset.split` splits a dataset</span>
<span class="sd">                into approximately equal splits.</span>

<span class="sd">            :meth:`Dataset.split_at_indices`</span>
<span class="sd">                :meth:`Dataset.split_proportionately` uses this method under the hood.</span>

<span class="sd">            :meth:`Dataset.streaming_split`.</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, :meth:`~Dataset.streaming_split`</span>
<span class="sd">                doesn&#39;t materialize the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must be at least of length 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must sum to less than 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">proportions</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must be bigger than 0&quot;</span><span class="p">)</span>

        <span class="n">dataset_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
        <span class="n">cumulative_proportions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span>
        <span class="n">split_indices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">dataset_length</span> <span class="o">*</span> <span class="n">proportion</span><span class="p">)</span> <span class="k">for</span> <span class="n">proportion</span> <span class="ow">in</span> <span class="n">cumulative_proportions</span>
        <span class="p">]</span>

        <span class="c1"># Ensure each split has at least one element</span>
        <span class="n">subtract</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">subtract</span>
            <span class="k">if</span> <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="n">subtract</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">split_indices</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Couldn&#39;t create non-empty splits with the given proportions.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.train_test_split"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.train_test_split.html#ray.data.Dataset.train_test_split">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">train_test_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">test_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">,</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and split the dataset into train and test subsets.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(8)</span>
<span class="sd">            &gt;&gt;&gt; train, test = ds.train_test_split(test_size=0.25)</span>
<span class="sd">            &gt;&gt;&gt; train.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4, 5])}</span>
<span class="sd">            &gt;&gt;&gt; test.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([6, 7])}</span>

<span class="sd">        Args:</span>
<span class="sd">            test_size: If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">                proportion of the dataset to include in the test split. If int,</span>
<span class="sd">                represents the absolute number of test samples. The train split</span>
<span class="sd">                always complements the test split.</span>
<span class="sd">            shuffle: Whether or not to globally shuffle the dataset before splitting.</span>
<span class="sd">                Defaults to ``False``. This may be a very expensive operation with a</span>
<span class="sd">                large dataset.</span>
<span class="sd">            seed: Fix the random seed to use for shuffle, otherwise one is chosen</span>
<span class="sd">                based on system randomness. Ignored if ``shuffle=False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Train and test subsets as two ``MaterializedDatasets``.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split_proportionately`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">random_shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`test_size` must be int or float got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If `test_size` is a float, it must be bigger than 0 and smaller &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;than 1. Got </span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">split_proportionately</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ds_length</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="n">ds_length</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If `test_size` is an int, it must be bigger than 0 and smaller &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;than the size of the dataset (</span><span class="si">{</span><span class="n">ds_length</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">([</span><span class="n">ds_length</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">])</span></div>

<div class="viewcode-block" id="Dataset.union"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.union.html#ray.data.Dataset.union">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">union</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">other</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and concatenate :class:`Datasets &lt;ray.data.Dataset&gt;` across rows.</span>

<span class="sd">        The order of the blocks in the datasets is preserved, as is the</span>
<span class="sd">        relative ordering between the datasets passed in the argument list.</span>

<span class="sd">        .. caution::</span>
<span class="sd">            Unioned datasets aren&#39;t lineage-serializable. As a result, they can&#39;t be</span>
<span class="sd">            used as a tunable hyperparameter in Ray Tune.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds1 = ray.data.range(2)</span>
<span class="sd">            &gt;&gt;&gt; ds2 = ray.data.range(3)</span>
<span class="sd">            &gt;&gt;&gt; ds1.union(ds2).take_all()</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}]</span>

<span class="sd">        Args:</span>
<span class="sd">            other: List of datasets to combine with this one. The datasets</span>
<span class="sd">                must have the same schema as this dataset, otherwise the</span>
<span class="sd">                behavior is undefined.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new dataset holding the rows of the input datasets.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>

        <span class="n">owned_by_consumer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
        <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
        <span class="n">bls</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">has_nonlazy</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
            <span class="n">bl</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bl</span><span class="p">,</span> <span class="n">LazyBlockList</span><span class="p">):</span>
                <span class="n">has_nonlazy</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">bls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bl</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">has_nonlazy</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">ops_to_union</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">bl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bls</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bl</span><span class="p">,</span> <span class="n">LazyBlockList</span><span class="p">):</span>
                    <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span> <span class="o">=</span> <span class="n">bl</span><span class="o">.</span><span class="n">_get_blocks_with_metadata</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bl</span><span class="p">,</span> <span class="n">BlockList</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">bl</span><span class="p">)</span>
                    <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span> <span class="o">=</span> <span class="n">bl</span><span class="o">.</span><span class="n">_blocks</span><span class="p">,</span> <span class="n">bl</span><span class="o">.</span><span class="n">_metadata</span>
                <span class="n">op_logical_plan</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">_plan</span><span class="p">,</span> <span class="s2">&quot;_logical_plan&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op_logical_plan</span><span class="p">,</span> <span class="n">LogicalPlan</span><span class="p">):</span>
                    <span class="n">ops_to_union</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">ops_to_union</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="n">blocks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span>
                <span class="n">metadata</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ms</span><span class="p">)</span>
            <span class="n">blocklist</span> <span class="o">=</span> <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">)</span>

            <span class="n">logical_plan</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">ops_to_union</span><span class="p">):</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">UnionLogicalOperator</span><span class="p">(</span><span class="o">*</span><span class="n">ops_to_union</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tasks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ReadTask</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">block_partition_refs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">BlockPartition</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">block_partition_meta_refs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">BlockMetadata</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Gather read task names from input blocks of unioned Datasets,</span>
            <span class="c1"># and concat them before passing to resulting LazyBlockList</span>
            <span class="n">read_task_names</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">self_read_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_in_blocks</span><span class="o">.</span><span class="n">_read_stage_name</span> <span class="ow">or</span> <span class="s2">&quot;Read&quot;</span>
            <span class="n">read_task_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">self_read_name</span><span class="p">)</span>
            <span class="n">other_read_names</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">o</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_in_blocks</span><span class="o">.</span><span class="n">_read_stage_name</span> <span class="ow">or</span> <span class="s2">&quot;Read&quot;</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">other</span>
            <span class="p">]</span>
            <span class="n">read_task_names</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">other_read_names</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">bl</span> <span class="ow">in</span> <span class="n">bls</span><span class="p">:</span>
                <span class="n">tasks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bl</span><span class="o">.</span><span class="n">_tasks</span><span class="p">)</span>
                <span class="n">block_partition_refs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bl</span><span class="o">.</span><span class="n">_block_partition_refs</span><span class="p">)</span>
                <span class="n">block_partition_meta_refs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bl</span><span class="o">.</span><span class="n">_block_partition_meta_refs</span><span class="p">)</span>
            <span class="n">blocklist</span> <span class="o">=</span> <span class="n">LazyBlockList</span><span class="p">(</span>
                <span class="n">tasks</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;Union(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">read_task_names</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
                <span class="n">block_partition_refs</span><span class="p">,</span>
                <span class="n">block_partition_meta_refs</span><span class="p">,</span>
                <span class="n">owned_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
            <span class="n">logical_plans</span> <span class="o">=</span> <span class="p">[</span>
                <span class="nb">getattr</span><span class="p">(</span><span class="n">union_ds</span><span class="p">,</span> <span class="s2">&quot;_logical_plan&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">union_ds</span> <span class="ow">in</span> <span class="n">datasets</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">logical_plans</span><span class="p">):</span>
                <span class="n">op</span> <span class="o">=</span> <span class="n">UnionLogicalOperator</span><span class="p">(</span>
                    <span class="o">*</span><span class="p">[</span><span class="n">plan</span><span class="o">.</span><span class="n">dag</span> <span class="k">for</span> <span class="n">plan</span> <span class="ow">in</span> <span class="n">logical_plans</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="n">epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ds</span><span class="o">.</span><span class="n">_get_epoch</span><span class="p">()</span> <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
        <span class="n">max_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="o">*</span><span class="n">epochs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">log_once</span><span class="p">(</span><span class="s2">&quot;dataset_epoch_warned&quot;</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Dataset contains data from multiple epochs: </span><span class="si">{}</span><span class="s2">, &quot;</span>
                    <span class="s2">&quot;likely due to a `rewindow()` call. The higher epoch &quot;</span>
                    <span class="s2">&quot;number </span><span class="si">{}</span><span class="s2"> will be used. This warning will not &quot;</span>
                    <span class="s2">&quot;be shown again.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">max_epoch</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">DatasetStats</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Union&quot;</span><span class="p">:</span> <span class="p">[]},</span>
            <span class="n">parent</span><span class="o">=</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">time_total_s</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">blocklist</span><span class="p">,</span> <span class="n">stats</span><span class="p">,</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">),</span>
            <span class="n">max_epoch</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
            <span class="n">logical_plan</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.groupby"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.groupby.html#ray.data.Dataset.groupby">[docs]</a>    <span class="k">def</span> <span class="nf">groupby</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;GroupedData&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Group rows of a :class:`Dataset` according to a column.</span>

<span class="sd">        Use this method to transform data based on a</span>
<span class="sd">        categorical variable.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import pandas as pd</span>
<span class="sd">                import ray</span>

<span class="sd">                def normalize_variety(group: pd.DataFrame) -&gt; pd.DataFrame:</span>
<span class="sd">                    for feature in group.drop(&quot;variety&quot;).columns:</span>
<span class="sd">                        group[feature] = group[feature] / group[feature].abs().max()</span>
<span class="sd">                    return group</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;)</span>
<span class="sd">                    .groupby(&quot;variety&quot;)</span>
<span class="sd">                    .map_groups(normalize_variety, batch_format=&quot;pandas&quot;)</span>
<span class="sd">                )</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            key: A column name. If this is ``None``, place all rows in a single group.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A lazy :class:`~ray.data.grouped_data.GroupedData`.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~ray.data.grouped_data.GroupedData.map_groups`</span>
<span class="sd">                Call this method to transform groups of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data.grouped_data</span> <span class="kn">import</span> <span class="n">GroupedData</span>

        <span class="c1"># Always allow None since groupby interprets that as grouping all</span>
        <span class="c1"># records into a single global group.</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">SortKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">validate_schema</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">GroupedData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.unique"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.unique.html#ray.data.Dataset.unique">[docs]</a>    <span class="k">def</span> <span class="nf">unique</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;List the unique elements in a given column.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([1, 2, 3, 2, 3])</span>
<span class="sd">            &gt;&gt;&gt; ds.unique(&quot;item&quot;)</span>
<span class="sd">            [1, 2, 3]</span>

<span class="sd">            This function is very useful for computing labels</span>
<span class="sd">            in a machine learning dataset:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.unique(&quot;target&quot;)</span>
<span class="sd">            [0, 1, 2]</span>

<span class="sd">            One common use case is to convert the class labels</span>
<span class="sd">            into integers for training and inference:</span>

<span class="sd">            &gt;&gt;&gt; classes = {0: &#39;Setosa&#39;, 1: &#39;Versicolor&#39;, 2: &#39;Virginica&#39;}</span>
<span class="sd">            &gt;&gt;&gt; def preprocessor(df, classes):</span>
<span class="sd">            ...     df[&quot;variety&quot;] = df[&quot;target&quot;].map(classes)</span>
<span class="sd">            ...     return df</span>
<span class="sd">            &gt;&gt;&gt; train_ds = ds.map_batches(</span>
<span class="sd">            ...     preprocessor, fn_kwargs={&quot;classes&quot;: classes}, batch_format=&quot;pandas&quot;)</span>
<span class="sd">            &gt;&gt;&gt; train_ds.sort(&quot;sepal length (cm)&quot;).take(1)  # Sort to make it deterministic</span>
<span class="sd">            [{&#39;sepal length (cm)&#39;: 4.3, ..., &#39;variety&#39;: &#39;Setosa&#39;}]</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            column: The column to collect unique elements over.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list with unique elements in the given column.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">column</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">select_columns</span><span class="p">([</span><span class="n">column</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">take_all</span><span class="p">()]</span></div>

<div class="viewcode-block" id="Dataset.aggregate"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.aggregate.html#ray.data.Dataset.aggregate">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">aggs</span><span class="p">:</span> <span class="n">AggregateFn</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Aggregate values using one or more functions.</span>

<span class="sd">        Use this method to compute metrics like the product of a column.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>
<span class="sd">                from ray.data.aggregate import AggregateFn</span>

<span class="sd">                ds = ray.data.from_items([{&quot;number&quot;: i} for i in range(1, 10)])</span>
<span class="sd">                aggregation = AggregateFn(</span>
<span class="sd">                    init=lambda column: 1,</span>
<span class="sd">                    accumulate_row=lambda a, row: a * row[&quot;number&quot;],</span>
<span class="sd">                    merge = lambda a1, a2: a1 + a2,</span>
<span class="sd">                    name=&quot;prod&quot;</span>
<span class="sd">                )</span>
<span class="sd">                print(ds.aggregate(aggregation))</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                {&#39;prod&#39;: 45}</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            *aggs: :class:`Aggregations &lt;ray.data.aggregate.AggregateFn&gt;` to perform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A ``dict`` where each each value is an aggregation for a given column.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="o">*</span><span class="n">aggs</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Dataset.sum"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.sum.html#ray.data.Dataset.sum">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute the sum of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).sum(&quot;id&quot;)</span>
<span class="sd">            4950</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).sum([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;sum(A)&#39;: 4950, &#39;sum(B)&#39;: 328350}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the sum. If ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                Ray Data considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The sum result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: a dict containing the column-wise sum of all</span>
<span class="sd">              columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the sum of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column ``dict``</span>
<span class="sd">              containing the column-wise sum of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Sum</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.min"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.min.html#ray.data.Dataset.min">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">min</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return the minimum of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).min(&quot;id&quot;)</span>
<span class="sd">            0</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).min([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;min(A)&#39;: 0, &#39;min(B)&#39;: 0}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the min; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The min result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise min of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the min of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise min of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Min</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.max"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.max.html#ray.data.Dataset.max">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">max</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return the maximum of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).max(&quot;id&quot;)</span>
<span class="sd">            99</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).max([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;max(A)&#39;: 99, &#39;max(B)&#39;: 9801}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the max; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The max result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise max of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the max of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise max of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Max</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.mean"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.mean.html#ray.data.Dataset.mean">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute the mean of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).mean(&quot;id&quot;)</span>
<span class="sd">            49.5</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).mean([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;mean(A)&#39;: 49.5, &#39;mean(B)&#39;: 3283.5}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the mean; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The mean result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise mean of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the mean of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise mean of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Mean</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.std"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.std.html#ray.data.Dataset.std">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ddof</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Compute the standard deviation of one or more columns.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This method uses Welford&#39;s online method for an accumulator-style</span>
<span class="sd">            computation of the standard deviation. This method has</span>
<span class="sd">            numerical stability, and is computable in a single pass. This may give</span>
<span class="sd">            different (but more accurate) results than NumPy, Pandas, and sklearn, which</span>
<span class="sd">            use a less numerically stable two-pass algorithm.</span>
<span class="sd">            To learn more, see</span>
<span class="sd">            `the Wikapedia article &lt;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford&#39;s_online_algorithm&gt;`_.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; round(ray.data.range(100).std(&quot;id&quot;, ddof=0), 5)</span>
<span class="sd">            28.86607</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).std([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;std(A)&#39;: 29.011491975882016, &#39;std(B)&#39;: 2968.1748039269296}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ddof: Delta Degrees of Freedom. The divisor used in calculations</span>
<span class="sd">                is ``N - ddof``, where ``N`` represents the number of elements.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the std; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The standard deviation result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise std of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the std of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise std of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Std</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.sort"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.sort.html#ray.data.Dataset.sort">[docs]</a>    <span class="k">def</span> <span class="nf">sort</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">descending</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sort the dataset by the specified key column or key function.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The `descending` parameter must be a boolean, or a list of booleans.</span>
<span class="sd">            If it is a list, all items in the list must share the same direction.</span>
<span class="sd">            Multi-directional sort is not supported yet.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.sort(&quot;id&quot;, descending=True).take(3)</span>
<span class="sd">            [{&#39;id&#39;: 99}, {&#39;id&#39;: 98}, {&#39;id&#39;: 97}]</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            key: The column or a list of columns to sort by.</span>
<span class="sd">            descending: Whether to sort in descending order. Must be a boolean or a list</span>
<span class="sd">                of booleans matching the number of the columns.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new, sorted :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sort_key</span> <span class="o">=</span> <span class="n">SortKey</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">descending</span><span class="p">)</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">SortStage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sort_key</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Sort</span><span class="p">(</span>
                <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                <span class="n">sort_key</span><span class="o">=</span><span class="n">sort_key</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.zip"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.zip.html#ray.data.Dataset.zip">[docs]</a>    <span class="k">def</span> <span class="nf">zip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Materialize and zip the columns of this dataset with the columns of another.</span>

<span class="sd">        The datasets must have the same number of rows. Their column sets are</span>
<span class="sd">        merged, and any duplicate column names are disambiguated with suffixes like</span>
<span class="sd">        ``&quot;_1&quot;``.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The smaller of the two datasets is repartitioned to align the number</span>
<span class="sd">            of rows per block with the larger dataset.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Zipped datasets aren&#39;t lineage-serializable. As a result, they can&#39;t be used</span>
<span class="sd">            as a tunable hyperparameter in Ray Tune.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds1 = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds2 = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds1.zip(ds2).take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4]), &#39;id_1&#39;: array([0, 1, 2, 3, 4])}</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            other: The dataset to zip with on the right hand side.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A :class:`Dataset` containing the columns of the second dataset</span>
<span class="sd">            concatenated horizontally with the columns of the first dataset,</span>
<span class="sd">            with duplicate column names disambiguated with suffixes like ``&quot;_1&quot;``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">ZipStage</span><span class="p">(</span><span class="n">other</span><span class="p">))</span>

        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="n">other_logical_plan</span> <span class="o">=</span> <span class="n">other</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">other_logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Zip</span><span class="p">(</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span> <span class="n">other_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.limit"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.limit.html#ray.data.Dataset.limit">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">limit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Truncate the dataset to the first ``limit`` rows.</span>

<span class="sd">        Unlike :meth:`~Dataset.take`, this method doesn&#39;t move data to the caller&#39;s</span>
<span class="sd">        machine. Instead, it returns a new :class:`Dataset` pointing to the truncated</span>
<span class="sd">        distributed data.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; ds.limit(5).count()</span>
<span class="sd">            5</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The size of the dataset to truncate to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The truncated dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">LimitStage</span><span class="p">(</span><span class="n">limit</span><span class="p">))</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">Limit</span><span class="p">(</span><span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="n">limit</span><span class="p">)</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.take_batch"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take_batch.html#ray.data.Dataset.take_batch">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">take_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataBatch</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return up to ``batch_size`` rows from the :class:`Dataset` in a batch.</span>

<span class="sd">        Ray Data represents batches as NumPy arrays or pandas DataFrames. You can</span>
<span class="sd">        configure the batch type by specifying ``batch_format``.</span>

<span class="sd">        This method is useful for inspecting inputs to :meth:`~Dataset.map_batches`.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            :meth:`~Dataset.take_batch` moves up to ``batch_size`` rows to the caller&#39;s</span>
<span class="sd">            machine. If ``batch_size`` is large, this method can cause an `</span>
<span class="sd">            ``OutOfMemory`` error on the caller.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.take_batch(5)</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4])}</span>

<span class="sd">        Time complexity: O(batch_size specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size: The maximum number of rows to return.</span>
<span class="sd">            batch_format: If ``&quot;default&quot;`` or ``&quot;numpy&quot;``, batches are</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``. If ``&quot;pandas&quot;``, batches are</span>
<span class="sd">                ``pandas.DataFrame``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A batch of up to ``batch_size`` rows from the dataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ``ValueError``: if the dataset is empty.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="n">limited_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
                <span class="nb">iter</span><span class="p">(</span>
                    <span class="n">limited_ds</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">prefetch_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The dataset is empty.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>

        <span class="c1"># Save the computed stats to the original dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_snapshot_stats</span> <span class="o">=</span> <span class="n">limited_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="Dataset.take"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take.html#ray.data.Dataset.take">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">take</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return up to ``limit`` rows from the :class:`Dataset`.</span>

<span class="sd">        This method is useful for inspecting data.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            :meth:`~Dataset.take` moves up to ``limit`` rows to the caller&#39;s machine. If</span>
<span class="sd">            ``limit`` is large, this method can cause an ``OutOfMemory`` error on the</span>
<span class="sd">            caller.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.take(3)</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}]</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The maximum number of rows to return.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of up to ``limit`` rows from the dataset.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.take_all`</span>
<span class="sd">                Call this method to return all rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">log_once</span><span class="p">(</span><span class="s2">&quot;dataset_take&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Tip: Use `take_batch()` instead of `take() / show()` to return &quot;</span>
                <span class="s2">&quot;records in pandas or numpy batch format.&quot;</span>
            <span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">limited_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">limit</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">limited_ds</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">():</span>
            <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>

        <span class="c1"># Save the computed stats to the original dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_snapshot_stats</span> <span class="o">=</span> <span class="n">limited_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Dataset.take_all"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take_all.html#ray.data.Dataset.take_all">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">take_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return all of the rows in this :class:`Dataset`.</span>

<span class="sd">        This method is useful for inspecting small datasets.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            :meth:`~Dataset.take_all` moves the entire dataset to the caller&#39;s</span>
<span class="sd">            machine. If the dataset is large, this method can cause an</span>
<span class="sd">            ``OutOfMemory`` error on the caller.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds.take_all()</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}, {&#39;id&#39;: 3}, {&#39;id&#39;: 4}]</span>

<span class="sd">        Time complexity: O(dataset size)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: Raise an error if the size exceeds the specified limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of all the rows in the dataset.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.take`</span>
<span class="sd">                Call this method to return a specific number of rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">():</span>
            <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The dataset has more than the given limit of </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> records.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Dataset.show"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.show.html#ray.data.Dataset.show">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Print up to the given number of rows from the :class:`Dataset`.</span>

<span class="sd">        This method is useful for inspecting data.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.show(3)</span>
<span class="sd">            {&#39;id&#39;: 0}</span>
<span class="sd">            {&#39;id&#39;: 1}</span>
<span class="sd">            {&#39;id&#39;: 2}</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The maximum number of row to print.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.take`</span>
<span class="sd">                Call this method to get (not print) a given number of rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">limit</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.count"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.count.html#ray.data.Dataset.count">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;row count&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Count the number of records in the dataset.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism), O(1) for parquet</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; ds.count()</span>
<span class="sd">            10</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of records in the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle empty dataset.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_blocks</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="c1"># For parquet, we can return the count directly from metadata.</span>
        <span class="n">meta_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_meta_count</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">meta_count</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">meta_count</span>

        <span class="n">get_num_rows</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_num_rows</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="p">[</span><span class="n">get_num_rows</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()]</span>
            <span class="p">)</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.schema"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.schema.html#ray.data.Dataset.schema">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;schema&quot;</span><span class="p">,</span>
        <span class="n">extra_condition</span><span class="o">=</span><span class="s2">&quot;or if ``fetch_if_missing=True`` (the default)&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">schema</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetch_if_missing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Schema&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the schema of the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column  Type</span>
<span class="sd">            ------  ----</span>
<span class="sd">            id      int64</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            fetch_if_missing: If True, synchronously fetch the schema if it&#39;s</span>
<span class="sd">                not known. If False, None is returned if the schema is not known.</span>
<span class="sd">                Default is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The :class:`ray.data.Schema` class of the records, or None if the</span>
<span class="sd">            schema is not known and fetch_if_missing is False.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># First check if the schema is already known from materialized blocks.</span>
        <span class="n">base_schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">base_schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Schema</span><span class="p">(</span><span class="n">base_schema</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">fetch_if_missing</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Lazily execute only the first block to minimize computation.</span>
        <span class="c1"># We achieve this by appending a Limit[1] operation to a copy</span>
        <span class="c1"># of this Dataset, which we then execute to get its schema.</span>
        <span class="n">base_schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="n">fetch_if_missing</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">base_schema</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">cache_schema</span><span class="p">(</span><span class="n">base_schema</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Schema</span><span class="p">(</span><span class="n">base_schema</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Dataset.columns"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.columns.html#ray.data.Dataset.columns">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;schema&quot;</span><span class="p">,</span>
        <span class="n">extra_condition</span><span class="o">=</span><span class="s2">&quot;or if ``fetch_if_missing=True`` (the default)&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetch_if_missing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the columns of this Dataset.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Create dataset from synthetic data.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; ds.columns()</span>
<span class="sd">            [&#39;id&#39;]</span>

<span class="sd">        Args:</span>
<span class="sd">            fetch_if_missing: If True, synchronously fetch the column names from the</span>
<span class="sd">                schema if it&#39;s not known. If False, None is returned if the schema is</span>
<span class="sd">                not known. Default is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of the column names for this Dataset or None if schema is not known</span>
<span class="sd">            and `fetch_if_missing` is False.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="n">fetch_if_missing</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">schema</span><span class="o">.</span><span class="n">names</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Dataset.num_blocks"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.num_blocks.html#ray.data.Dataset.num_blocks">[docs]</a>    <span class="k">def</span> <span class="nf">num_blocks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the number of blocks of this dataset.</span>

<span class="sd">        Note that during read and transform operations, the number of blocks</span>
<span class="sd">        may be dynamically adjusted to respect memory limits, increasing the</span>
<span class="sd">        number of blocks at runtime.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100).repartition(10)</span>
<span class="sd">            &gt;&gt;&gt; ds.num_blocks()</span>
<span class="sd">            10</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of blocks of this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.size_bytes"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.size_bytes.html#ray.data.Dataset.size_bytes">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">size_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the in-memory size of the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; ds.size_bytes()</span>
<span class="sd">            80</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The in-memory size of the dataset in bytes, or None if the</span>
<span class="sd">            in-memory size is not known.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span> <span class="ow">or</span> <span class="n">metadata</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size_bytes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">size_bytes</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metadata</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.input_files"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.input_files.html#ray.data.Dataset.input_files">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">input_files</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the list of input files for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.input_files()</span>
<span class="sd">            [&#39;ray-example-data/iris.csv&#39;]</span>

<span class="sd">        Time complexity: O(num input files)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The list of input files used to create the dataset, or an empty</span>
<span class="sd">            list if the input files is not known.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
        <span class="n">files</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metadata</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">input_files</span><span class="p">:</span>
                <span class="n">files</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">files</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_parquet"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_parquet.html#ray.data.Dataset.write_parquet">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_parquet</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">arrow_parquet_args_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{},</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to parquet files under the provided ``path``.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        If pyarrow can&#39;t represent your data, this method errors.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.parquet``,</span>
<span class="sd">        where ``uuid`` is a unique</span>
<span class="sd">        id for the dataset. To modify this behavior, implement a custom</span>
<span class="sd">        :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">        and pass it in as the ``block_path_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_parquet(&quot;local:///tmp/data/&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                parquet files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            block_path_provider: A</span>
<span class="sd">                :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">                implementation specifying the filename structure for each output</span>
<span class="sd">                parquet file. By default, the format of the output files is</span>
<span class="sd">                ``{uuid}_{block_idx}.parquet``, where ``uuid`` is a unique id for the</span>
<span class="sd">                dataset.</span>
<span class="sd">            arrow_parquet_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments that are provided to `pyarrow.parquet.write_table() &lt;https:/\</span>
<span class="sd">                    /arrow.apache.org/docs/python/generated/\</span>
<span class="sd">                        pyarrow.parquet.write_table.html#pyarrow.parquet.write_table&gt;`_</span>
<span class="sd">                when writing each block to a file. Overrides</span>
<span class="sd">                any duplicate keys from ``arrow_parquet_args``. Use this argument</span>
<span class="sd">                instead of ``arrow_parquet_args`` if any of your write arguments</span>
<span class="sd">                can&#39;t pickled, or if you&#39;d like to lazily resolve the write</span>
<span class="sd">                arguments for each dataset block.</span>
<span class="sd">            ray_remote_args: Kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            arrow_parquet_args: Options to pass to</span>
<span class="sd">                `pyarrow.parquet.write_table() &lt;https://arrow.apache.org/docs/python\</span>
<span class="sd">                    /generated/pyarrow.parquet.write_table.html\</span>
<span class="sd">                        #pyarrow.parquet.write_table&gt;`_, which is used to write out each</span>
<span class="sd">                block to a file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">ParquetDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">write_args_fn</span><span class="o">=</span><span class="n">arrow_parquet_args_fn</span><span class="p">,</span>
            <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_json"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_json.html#ray.data.Dataset.write_json">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_json</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">pandas_json_args_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{},</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">pandas_json_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to JSON and JSONL files.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        This method is only supported for datasets with records that are convertible to</span>
<span class="sd">        pandas dataframes.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.json``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom</span>
<span class="sd">        :class:`~ray.data.file_based_datasource.BlockWritePathProvider`</span>
<span class="sd">        and pass it in as the ``block_path_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            Write the dataset as JSON file to a local directory.</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_pandas([pd.DataFrame({&quot;one&quot;: [1], &quot;two&quot;: [&quot;a&quot;]})])</span>
<span class="sd">            &gt;&gt;&gt; ds.write_json(&quot;local:///tmp/data&quot;)</span>

<span class="sd">            Write the dataset as JSONL files to a local directory.</span>

<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_json(&quot;s3://anonymous@ray-example-data/train.jsonl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_json(&quot;local:///tmp/data&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the JSON files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            block_path_provider: A</span>
<span class="sd">                :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">                implementation specifying the filename structure for each output</span>
<span class="sd">                parquet file. By default, the format of the output files is</span>
<span class="sd">                ``{uuid}_{block_idx}.json``, where ``uuid`` is a unique id for the</span>
<span class="sd">                dataset.</span>
<span class="sd">            pandas_json_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments that are provided to</span>
<span class="sd">                `pandas.DataFrame.to_json() &lt;https://pandas.pydata.org/docs/reference/\</span>
<span class="sd">                    api/pandas.DataFrame.to_json.html&gt;`_</span>
<span class="sd">                when writing each block to a file. Overrides</span>
<span class="sd">                any duplicate keys from ``pandas_json_args``. Use this parameter</span>
<span class="sd">                instead of ``pandas_json_args`` if any of your write arguments</span>
<span class="sd">                can&#39;t be pickled, or if you&#39;d like to lazily resolve the write</span>
<span class="sd">                arguments for each dataset block.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            pandas_json_args: These args are passed to</span>
<span class="sd">                `pandas.DataFrame.to_json() &lt;https://pandas.pydata.org/docs/reference/\</span>
<span class="sd">                    api/pandas.DataFrame.to_json.html&gt;`_,</span>
<span class="sd">                which is used under the hood to write out each</span>
<span class="sd">                :class:`~ray.data.Dataset` block. These</span>
<span class="sd">                are dict(orient=&quot;records&quot;, lines=True) by default.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">JSONDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">write_args_fn</span><span class="o">=</span><span class="n">pandas_json_args_fn</span><span class="p">,</span>
            <span class="o">**</span><span class="n">pandas_json_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_images"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_images.html#ray.data.Dataset.write_images">[docs]</a>    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_images</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">file_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;png&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to images.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_images(&quot;s3://anonymous@ray-example-data/image-datasets/simple&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_images(&quot;local:///tmp/images&quot;, column=&quot;image&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the images are written to.</span>
<span class="sd">            column: The column containing the data you want to write to images.</span>
<span class="sd">            file_format: The image file format to write with. For available options,</span>
<span class="sd">                see `Image file formats &lt;https://pillow.readthedocs.io/en/latest\</span>
<span class="sd">                /handbook/image-file-formats.html&gt;`_.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">ImageDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
            <span class="n">file_format</span><span class="o">=</span><span class="n">file_format</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_csv"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_csv.html#ray.data.Dataset.write_csv">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_csv</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">arrow_csv_args_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{},</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to CSV files.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        This method is only supported for datasets with records that are convertible to</span>
<span class="sd">        pyarrow tables.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.csv``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom</span>
<span class="sd">        :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">        and pass it in as the ``block_path_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            Write the dataset as CSV files to a local directory.</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_csv(&quot;local:///tmp/data&quot;)</span>

<span class="sd">            Write the dataset as CSV files to S3.</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_csv(&quot;s3://bucket/folder/)  # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the CSV files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path if ``True``. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            block_path_provider: A</span>
<span class="sd">                :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">                implementation specifying the filename structure for each output</span>
<span class="sd">                parquet file. By default,  the format of the output files is</span>
<span class="sd">                ``{uuid}_{block_idx}.csv``, where ``uuid`` is a unique id for the</span>
<span class="sd">                dataset.</span>
<span class="sd">            arrow_csv_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments that are provided to `pyarrow.write.write_csv &lt;https://\</span>
<span class="sd">                arrow.apache.org/docs/python/generated/\</span>
<span class="sd">                pyarrow.csv.write_csv.html#pyarrow.csv.write_csv&gt;`_ when writing each</span>
<span class="sd">                block to a file. Overrides any duplicate keys from ``arrow_csv_args``.</span>
<span class="sd">                Use this argument instead of ``arrow_csv_args`` if any of your write</span>
<span class="sd">                arguments cannot be pickled, or if you&#39;d like to lazily resolve the</span>
<span class="sd">                write arguments for each dataset block.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            arrow_csv_args: Options to pass to `pyarrow.write.write_csv &lt;https://\</span>
<span class="sd">                arrow.apache.org/docs/python/generated/pyarrow.csv.write_csv.html\</span>
<span class="sd">                    #pyarrow.csv.write_csv&gt;`_</span>
<span class="sd">                when writing each block to a file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">CSVDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">write_args_fn</span><span class="o">=</span><span class="n">arrow_csv_args_fn</span><span class="p">,</span>
            <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_tfrecords"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_tfrecords.html#ray.data.Dataset.write_tfrecords">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_tfrecords</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tf_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;schema_pb2.Schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write the :class:`~ray.data.Dataset` to TFRecord files.</span>

<span class="sd">        The `TFRecord &lt;https://www.tensorflow.org/tutorials/load_data/tfrecord&gt;`_</span>
<span class="sd">        files contain</span>
<span class="sd">        `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/\</span>
<span class="sd">            Example&gt;`_</span>
<span class="sd">        records, with one Example record for each row in the dataset.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            tf.train.Feature only natively stores ints, floats, and bytes,</span>
<span class="sd">            so this function only supports datasets with these data types,</span>
<span class="sd">            and will error if the dataset contains unsupported types.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        This method is only supported for datasets with records that are convertible to</span>
<span class="sd">        pyarrow tables.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.tfrecords``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom</span>
<span class="sd">        :class:`~ray.data.file_based_datasource.BlockWritePathProvider`</span>
<span class="sd">        and pass it in as the ``block_path_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_tfrecords(&quot;local:///tmp/data/&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where tfrecords</span>
<span class="sd">                files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            block_path_provider: A</span>
<span class="sd">                :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">                implementation specifying the filename structure for each output</span>
<span class="sd">                parquet file. By default, the format of the output files is</span>
<span class="sd">                ``{uuid}_{block_idx}.tfrecords``, where ``uuid`` is a unique id for the</span>
<span class="sd">                dataset.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">TFRecordDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">tf_schema</span><span class="o">=</span><span class="n">tf_schema</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_webdataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_webdataset.html#ray.data.Dataset.write_webdataset">[docs]</a>    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_webdataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">callable</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes the dataset to `WebDataset &lt;https://webdataset.github.io/webdataset/&gt;`_ files.</span>

<span class="sd">        The `TFRecord &lt;https://www.tensorflow.org/tutorials/load_data/tfrecord&gt;`_</span>
<span class="sd">        files will contain</span>
<span class="sd">        `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/Example&gt;`_ # noqa: E501</span>
<span class="sd">        records, with one Example record for each row in the dataset.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            tf.train.Feature only natively stores ints, floats, and bytes,</span>
<span class="sd">            so this function only supports datasets with these data types,</span>
<span class="sd">            and will error if the dataset contains unsupported types.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of files, use :meth:`Dataset.repartition`.</span>

<span class="sd">        Unless a custom block path provider is given, the format of the output</span>
<span class="sd">        files is ``{uuid}_{block_idx}.tfrecords``, where ``uuid`` is a unique id</span>
<span class="sd">        for the dataset.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :skipif: True</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.range(100)</span>
<span class="sd">                ds.write_webdataset(&quot;s3://bucket/folder/&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where tfrecords</span>
<span class="sd">                files are written to.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all</span>
<span class="sd">                directories in the destination path. Does nothing if all directories</span>
<span class="sd">                already exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                ``pyarrow.fs.FileSystem.open_output_stream``</span>
<span class="sd">            block_path_provider: :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">                implementation to write each dataset block to a custom output path.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ``ray.remote`` in the write tasks.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="kn">from</span> <span class="nn">ray.data.datasource.webdataset_datasource</span> <span class="kn">import</span> <span class="n">WebDatasetDatasource</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">WebDatasetDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_numpy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_numpy.html#ray.data.Dataset.write_numpy">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_numpy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">block_path_provider</span><span class="p">:</span> <span class="n">BlockWritePathProvider</span> <span class="o">=</span> <span class="n">DefaultBlockWritePathProvider</span><span class="p">(),</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes a column of the :class:`~ray.data.Dataset` to .npy files.</span>

<span class="sd">        This is only supported for columns in the datasets that can be converted to</span>
<span class="sd">        NumPy arrays.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.npy``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom</span>
<span class="sd">        :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">        and pass it in as the ``block_path_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_numpy(&quot;local:///tmp/data/&quot;, column=&quot;id&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the npy files are written to.</span>
<span class="sd">            column: The name of the column that contains the data to</span>
<span class="sd">                be written.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            block_path_provider: A</span>
<span class="sd">                :class:`~ray.data.datasource.BlockWritePathProvider`</span>
<span class="sd">                implementation specifying the filename structure for each output</span>
<span class="sd">                parquet file. By default,  the format of the output files is</span>
<span class="sd">                ``{uuid}_{block_idx}.npy``, where ``uuid`` is a unique id for the</span>
<span class="sd">                dataset.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">NumpyDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">block_path_provider</span><span class="o">=</span><span class="n">block_path_provider</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_sql"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_sql.html#ray.data.Dataset.write_sql">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_sql</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sql</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">connection_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Connection</span><span class="p">],</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Write to a database that provides a</span>
<span class="sd">        `Python DB API2-compliant &lt;https://peps.python.org/pep-0249/&gt;`_ connector.</span>

<span class="sd">        .. note::</span>

<span class="sd">            This method writes data in parallel using the DB API2 ``executemany``</span>
<span class="sd">            method. To learn more about this method, see</span>
<span class="sd">            `PEP 249 &lt;https://peps.python.org/pep-0249/#executemany&gt;`_.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import sqlite3</span>
<span class="sd">                import ray</span>

<span class="sd">                connection = sqlite3.connect(&quot;example.db&quot;)</span>
<span class="sd">                connection.cursor().execute(&quot;CREATE TABLE movie(title, year, score)&quot;)</span>
<span class="sd">                dataset = ray.data.from_items([</span>
<span class="sd">                    {&quot;title&quot;: &quot;Monty Python and the Holy Grail&quot;, &quot;year&quot;: 1975, &quot;score&quot;: 8.2},</span>
<span class="sd">                    {&quot;title&quot;: &quot;And Now for Something Completely Different&quot;, &quot;year&quot;: 1971, &quot;score&quot;: 7.5}</span>
<span class="sd">                ])</span>

<span class="sd">                dataset.write_sql(</span>
<span class="sd">                    &quot;INSERT INTO movie VALUES(?, ?, ?)&quot;, lambda: sqlite3.connect(&quot;example.db&quot;)</span>
<span class="sd">                )</span>

<span class="sd">                result = connection.cursor().execute(&quot;SELECT * FROM movie ORDER BY year&quot;)</span>
<span class="sd">                print(result.fetchall())</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                [(&#39;And Now for Something Completely Different&#39;, 1971, 7.5), (&#39;Monty Python and the Holy Grail&#39;, 1975, 8.2)]</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :hide:</span>

<span class="sd">                import os</span>
<span class="sd">                os.remove(&quot;example.db&quot;)</span>

<span class="sd">        Arguments:</span>
<span class="sd">            sql: An ``INSERT INTO`` statement that specifies the table to write to. The</span>
<span class="sd">                number of parameters must match the number of columns in the table.</span>
<span class="sd">            connection_factory: A function that takes no arguments and returns a</span>
<span class="sd">                Python DB API2</span>
<span class="sd">                `Connection object &lt;https://peps.python.org/pep-0249/#connection-objects&gt;`_.</span>
<span class="sd">            ray_remote_args: Keyword arguments passed to :meth:`~ray.remote` in the</span>
<span class="sd">                write tasks.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">SQLDatasource</span><span class="p">(</span><span class="n">connection_factory</span><span class="p">),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">sql</span><span class="o">=</span><span class="n">sql</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_mongo"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_mongo.html#ray.data.Dataset.write_mongo">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_mongo</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">database</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">collection</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to a MongoDB database.</span>

<span class="sd">        This method is only supported for datasets convertible to pyarrow tables.</span>

<span class="sd">        The number of parallel writes is determined by the number of blocks in the</span>
<span class="sd">        dataset. To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            This method supports only a subset of the PyArrow&#39;s types, due to the</span>
<span class="sd">            limitation of pymongoarrow which is used underneath. Writing unsupported</span>
<span class="sd">            types fails on type checking. See all the supported types at:</span>
<span class="sd">            https://mongo-arrow.readthedocs.io/en/latest/data_types.html.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The records are inserted into MongoDB as new documents. If a record has</span>
<span class="sd">            the _id field, this _id must be non-existent in MongoDB, otherwise the write</span>
<span class="sd">            is rejected and fail (hence preexisting documents are protected from</span>
<span class="sd">            being mutated). It&#39;s fine to not have _id field in record and MongoDB will</span>
<span class="sd">            auto generate one at insertion.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :skipif: True</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.range(100)</span>
<span class="sd">                ds.write_mongo(</span>
<span class="sd">                    uri=&quot;mongodb://username:password@mongodb0.example.com:27017/?authSource=admin&quot;,</span>
<span class="sd">                    database=&quot;my_db&quot;,</span>
<span class="sd">                    collection=&quot;my_collection&quot;</span>
<span class="sd">                )</span>

<span class="sd">        Args:</span>
<span class="sd">            uri: The URI to the destination MongoDB where the dataset is</span>
<span class="sd">                written to. For the URI format, see details in the</span>
<span class="sd">                `MongoDB docs &lt;https://www.mongodb.com/docs/manual/reference\</span>
<span class="sd">                    /connection-string/&gt;`_.</span>
<span class="sd">            database: The name of the database. This database must exist otherwise</span>
<span class="sd">                a ValueError is raised.</span>
<span class="sd">            collection: The name of the collection in the database. This collection</span>
<span class="sd">                must exist otherwise a ValueError is raised.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if ``database`` doesn&#39;t exist.</span>
<span class="sd">            ValueError: if ``collection`` doesn&#39;t exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="n">MongoDatasource</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasource</span><span class="p">(</span>
            <span class="n">MongoDatasource</span><span class="p">(),</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">uri</span><span class="o">=</span><span class="n">uri</span><span class="p">,</span>
            <span class="n">database</span><span class="o">=</span><span class="n">database</span><span class="p">,</span>
            <span class="n">collection</span><span class="o">=</span><span class="n">collection</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.write_datasource"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_datasource.html#ray.data.Dataset.write_datasource">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_datasource</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datasource</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">write_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes the dataset to a custom :class:`~ray.data.Datasource`.</span>

<span class="sd">        For an example of how to use this method, see</span>
<span class="sd">        :ref:`Implementing a Custom Datasource &lt;custom_datasources&gt;`.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            datasource: The :class:`~ray.data.Datasource` to write to.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ``ray.remote`` in the write tasks.</span>
<span class="sd">            write_args: Additional write args to pass to the :class:`~ray.data.Datasource`.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">if</span> <span class="n">ray_remote_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">write_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;path&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">and</span> <span class="n">_is_local_scheme</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">ray</span><span class="o">.</span><span class="n">is_connected</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The local scheme paths </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> are not supported in Ray Client.&quot;</span>
                <span class="p">)</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
                <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span>
                <span class="n">soft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">datasource</span><span class="p">)</span><span class="o">.</span><span class="n">write</span> <span class="o">!=</span> <span class="n">Datasource</span><span class="o">.</span><span class="n">write</span><span class="p">:</span>
            <span class="n">write_fn</span> <span class="o">=</span> <span class="n">generate_write_fn</span><span class="p">(</span><span class="n">datasource</span><span class="p">,</span> <span class="o">**</span><span class="n">write_args</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">write_fn_wrapper</span><span class="p">(</span><span class="n">blocks</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Block</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Block</span><span class="p">]:</span>
                <span class="k">return</span> <span class="n">write_fn</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>

            <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span>
                <span class="n">OneToOneStage</span><span class="p">(</span>
                    <span class="s2">&quot;Write&quot;</span><span class="p">,</span>
                    <span class="n">write_fn_wrapper</span><span class="p">,</span>
                    <span class="n">TaskPoolStrategy</span><span class="p">(),</span>
                    <span class="n">ray_remote_args</span><span class="p">,</span>
                    <span class="n">fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="n">logical_plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
            <span class="k">if</span> <span class="n">logical_plan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">write_op</span> <span class="o">=</span> <span class="n">Write</span><span class="p">(</span>
                    <span class="n">logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
                    <span class="n">datasource</span><span class="p">,</span>
                    <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">write_args</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">write_op</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_start</span><span class="p">(</span><span class="o">**</span><span class="n">write_args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                    <span class="n">plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan</span>
                <span class="p">)</span><span class="o">.</span><span class="n">materialize</span><span class="p">()</span>
                <span class="n">blocks</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_blocks</span><span class="p">())</span>
                <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
                    <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span>
                <span class="p">)</span>
                <span class="n">write_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">block</span><span class="p">[</span><span class="s2">&quot;write_result&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_complete</span><span class="p">(</span><span class="n">write_results</span><span class="p">,</span> <span class="o">**</span><span class="n">write_args</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_failed</span><span class="p">([],</span> <span class="n">e</span><span class="p">)</span>
                <span class="k">raise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;The Datasource.do_write() is deprecated in &quot;</span>
                <span class="s2">&quot;Ray 2.4 and will be removed in future release. Use &quot;</span>
                <span class="s2">&quot;Datasource.write() instead.&quot;</span>
            <span class="p">)</span>

            <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">())</span>
            <span class="c1"># Prepare write in a remote task so that in Ray client mode, we</span>
            <span class="c1"># don&#39;t do metadata resolution from the client machine.</span>
            <span class="n">do_write</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_do_write</span><span class="p">,</span> <span class="n">retry_exceptions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_cpus</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">write_results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">WriteResult</span><span class="p">]]</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="n">do_write</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span>
                    <span class="n">datasource</span><span class="p">,</span>
                    <span class="n">ctx</span><span class="p">,</span>
                    <span class="n">blocks</span><span class="p">,</span>
                    <span class="n">metadata</span><span class="p">,</span>
                    <span class="n">ray_remote_args</span><span class="p">,</span>
                    <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">write_args</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="n">progress</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Write Progress&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">write_results</span><span class="p">))</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">progress</span><span class="o">.</span><span class="n">block_until_complete</span><span class="p">(</span><span class="n">write_results</span><span class="p">)</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_complete</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">write_results</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">datasource</span><span class="o">.</span><span class="n">on_write_failed</span><span class="p">(</span><span class="n">write_results</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
                <span class="k">raise</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="n">progress</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.iterator"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iterator.html#ray.data.Dataset.iterator">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">delegate</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Calling any of the consumption methods on the returned ``DataIterator``&quot;</span>
        <span class="p">),</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Returns:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataIterator</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a :class:`~ray.data.DataIterator` over this dataset.</span>

<span class="sd">        Don&#39;t call this method directly. Use it internally.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A :class:`~ray.data.DataIterator` over this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">DataIteratorImpl</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_rows"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_rows.html#ray.data.Dataset.iter_rows">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return an iterator over the rows in this dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for row in ray.data.range(3).iter_rows():</span>
<span class="sd">            ...     print(row)</span>
<span class="sd">            {&#39;id&#39;: 0}</span>
<span class="sd">            {&#39;id&#39;: 1}</span>
<span class="sd">            {&#39;id&#39;: 2}</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_blocks: The number of blocks to prefetch ahead of the</span>
<span class="sd">                current block during the scan.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over the rows in this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">(</span><span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_batches.html#ray.data.Dataset.iter_batches">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">DataBatch</span><span class="p">],</span> <span class="n">CollatedData</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated.</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">DataBatch</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return an iterator over batches of data.</span>

<span class="sd">        This method is useful for model training.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_images(&quot;example://image-datasets/simple&quot;)</span>

<span class="sd">                for batch in ds.iter_batches(batch_size=2, batch_format=&quot;numpy&quot;):</span>
<span class="sd">                    print(batch)</span>

<span class="sd">            .. testoutput::</span>
<span class="sd">                :options: +MOCK</span>

<span class="sd">                {&#39;image&#39;: array([[[[...]]]], dtype=uint8)}</span>
<span class="sd">                ...</span>
<span class="sd">                {&#39;image&#39;: array([[[[...]]]], dtype=uint8)}</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node and format the batches. Defaults</span>
<span class="sd">                to 1.</span>
<span class="sd">            batch_size: The number of rows in each batch, or ``None`` to use entire</span>
<span class="sd">                blocks as batches (blocks may contain different numbers of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            batch_format: If ``&quot;default&quot;`` or ``&quot;numpy&quot;``, batches are</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``. If ``&quot;pandas&quot;``, batches are</span>
<span class="sd">                ``pandas.DataFrame``.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If not ``None``, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value serves as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer are drained.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over batches of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_strict_mode_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_format</span> <span class="o">==</span> <span class="s2">&quot;native&quot;</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;The &#39;native&#39; batch format has been renamed &#39;default&#39;.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
            <span class="n">_collate_fn</span><span class="o">=</span><span class="n">_collate_fn</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_torch_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_torch_batches.html#ray.data.Dataset.iter_torch_batches">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_torch_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.dtype&quot;</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span> <span class="n">CollatedData</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TorchBatchType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return an iterator over batches of data represented as Torch tensors.</span>

<span class="sd">        This iterator yields batches of type ``Dict[str, torch.Tensor]``.</span>
<span class="sd">        For more flexibility, call :meth:`~Dataset.iter_batches` and manually convert</span>
<span class="sd">        your data to Torch tensors.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for batch in ray.data.range(</span>
<span class="sd">            ...     12,</span>
<span class="sd">            ... ).iter_torch_batches(batch_size=4):</span>
<span class="sd">            ...     print(batch)</span>
<span class="sd">            {&#39;id&#39;: tensor([0, 1, 2, 3])}</span>
<span class="sd">            {&#39;id&#39;: tensor([4, 5, 6, 7])}</span>
<span class="sd">            {&#39;id&#39;: tensor([ 8,  9, 10, 11])}</span>

<span class="sd">            Use the ``collate_fn`` to customize how the tensor batch is created.</span>

<span class="sd">            &gt;&gt;&gt; from typing import Any, Dict</span>
<span class="sd">            &gt;&gt;&gt; import torch</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; def collate_fn(batch: Dict[str, np.ndarray]) -&gt; Any:</span>
<span class="sd">            ...     return torch.stack(</span>
<span class="sd">            ...         [torch.as_tensor(array) for array in batch.values()],</span>
<span class="sd">            ...         axis=1</span>
<span class="sd">            ...     )</span>
<span class="sd">            &gt;&gt;&gt; dataset = ray.data.from_items([</span>
<span class="sd">            ...     {&quot;col_1&quot;: 1, &quot;col_2&quot;: 2},</span>
<span class="sd">            ...     {&quot;col_1&quot;: 3, &quot;col_2&quot;: 4}])</span>
<span class="sd">            &gt;&gt;&gt; for batch in dataset.iter_torch_batches(collate_fn=collate_fn):</span>
<span class="sd">            ...     print(batch)</span>
<span class="sd">            tensor([[1, 2],</span>
<span class="sd">                    [3, 4]])</span>


<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the ``collate_fn``. Defaults to 1.</span>
<span class="sd">            batch_size: The number of rows in each batch, or ``None`` to use entire</span>
<span class="sd">                blocks as batches (blocks may contain different number of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            dtypes: The Torch dtype(s) for the created tensor(s); if ``None``, the dtype</span>
<span class="sd">                is inferred from the tensor data. You can&#39;t use this parameter with</span>
<span class="sd">                ``collate_fn``.</span>
<span class="sd">            device: The device on which the tensor should be placed. Defaults to</span>
<span class="sd">                &quot;auto&quot; which moves the tensors to the appropriate device when the</span>
<span class="sd">                Dataset is passed to Ray Train and ``collate_fn`` is not provided.</span>
<span class="sd">                Otherwise, defaults to CPU. You can&#39;t use this parameter with</span>
<span class="sd">                ``collate_fn``.</span>
<span class="sd">            collate_fn: A function to convert a Numpy batch to a PyTorch tensor batch.</span>
<span class="sd">                When this parameter is specified, the user should manually handle the</span>
<span class="sd">                host to device data transfer outside of collate_fn.</span>
<span class="sd">                This is useful for further processing the data after it has been</span>
<span class="sd">                batched. Potential use cases include collating along a dimension other</span>
<span class="sd">                than the first, padding sequences of various lengths, or generally</span>
<span class="sd">                handling batches of different length tensors. If not provided, the</span>
<span class="sd">                default collate function is used which simply converts the batch of</span>
<span class="sd">                numpy arrays to a batch of PyTorch tensors. This API is still</span>
<span class="sd">                experimental and is subject to change. You can&#39;t use this parameter in</span>
<span class="sd">                conjunction with ``dtypes`` or ``device``.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If not ``None``, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value serves as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer are drained.</span>
<span class="sd">                ``batch_size`` must also be specified when using local shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over Torch Tensor batches.</span>

<span class="sd">        .. seealso::</span>
<span class="sd">            :meth:`Dataset.iter_batches`</span>
<span class="sd">                Call this method to manually convert your data to Torch tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.iter_tf_batches"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_tf_batches.html#ray.data.Dataset.iter_tf_batches">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">iter_tf_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.dtypes.DType&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.dtypes.DType&quot;</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TensorFlowTensorBatchType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return an iterator over batches of data represented as TensorFlow tensors.</span>

<span class="sd">        This iterator yields batches of type ``Dict[str, tf.Tensor]``.</span>
<span class="sd">        For more flexibility, call :meth:`~Dataset.iter_batches` and manually convert</span>
<span class="sd">        your data to TensorFlow tensors.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If you don&#39;t need the additional flexibility provided by this method,</span>
<span class="sd">            consider using :meth:`~ray.data.Dataset.to_tf` instead. It&#39;s easier</span>
<span class="sd">            to use.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_csv(&quot;s3://anonymous@air-example-data/iris.csv&quot;)</span>

<span class="sd">                tf_dataset = ds.to_tf(</span>
<span class="sd">                    feature_columns=&quot;sepal length (cm)&quot;,</span>
<span class="sd">                    label_columns=&quot;target&quot;,</span>
<span class="sd">                    batch_size=2</span>
<span class="sd">                )</span>
<span class="sd">                for features, labels in tf_dataset:</span>
<span class="sd">                    print(features, labels)</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                tf.Tensor([5.1 4.9], shape=(2,), dtype=float64) tf.Tensor([0 0], shape=(2,), dtype=int64)</span>
<span class="sd">                ...</span>
<span class="sd">                tf.Tensor([6.2 5.9], shape=(2,), dtype=float64) tf.Tensor([2 2], shape=(2,), dtype=int64)</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the ``collate_fn``. Defaults to 1.</span>
<span class="sd">            batch_size: The number of rows in each batch, or ``None`` to use entire</span>
<span class="sd">                blocks as batches (blocks may contain different numbers of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            dtypes: The TensorFlow dtype(s) for the created tensor(s); if ``None``, the</span>
<span class="sd">                dtype is inferred from the tensor data.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If not ``None``, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value serves as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer are drained.</span>
<span class="sd">                ``batch_size`` must also be specified when using local shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over TensorFlow Tensor batches.</span>

<span class="sd">        .. seealso::</span>
<span class="sd">            :meth:`Dataset.iter_batches`</span>
<span class="sd">                Call this method to manually convert your data to TensorFlow tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_tf_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_torch"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_torch.html#ray.data.Dataset.to_torch">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_torch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">label_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">label_column_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_column_dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.dtype&quot;</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">unsqueeze_label_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">unsqueeze_feature_tensors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;torch.utils.data.IterableDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a</span>
<span class="sd">        `Torch IterableDataset &lt;https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset&gt;`_</span>
<span class="sd">        over this :class:`~ray.data.Dataset`.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>

<span class="sd">        It is recommended to use the returned ``IterableDataset`` directly</span>
<span class="sd">        instead of passing it into a torch ``DataLoader``.</span>

<span class="sd">        Each element in ``IterableDataset`` is a tuple consisting of 2</span>
<span class="sd">        elements. The first item contains the feature tensor(s), and the</span>
<span class="sd">        second item is the label tensor. Those can take on different</span>
<span class="sd">        forms, depending on the specified arguments.</span>

<span class="sd">        For the features tensor (N is the ``batch_size`` and n, m, k</span>
<span class="sd">        are the number of features per tensor):</span>

<span class="sd">        * If ``feature_columns`` is a ``List[str]``, the features is</span>
<span class="sd">          a tensor of shape (N, n), with columns corresponding to</span>
<span class="sd">          ``feature_columns``</span>

<span class="sd">        * If ``feature_columns`` is a ``List[List[str]]``, the features is</span>
<span class="sd">          a list of tensors of shape [(N, m),...,(N, k)], with columns of each</span>
<span class="sd">          tensor corresponding to the elements of ``feature_columns``</span>

<span class="sd">        * If ``feature_columns`` is a ``Dict[str, List[str]]``, the features</span>
<span class="sd">          is a dict of key-tensor pairs of shape</span>
<span class="sd">          {key1: (N, m),..., keyN: (N, k)}, with columns of each</span>
<span class="sd">          tensor corresponding to the value of ``feature_columns`` under the</span>
<span class="sd">          key.</span>

<span class="sd">        If ``unsqueeze_label_tensor=True`` (default), the label tensor is</span>
<span class="sd">        of shape (N, 1). Otherwise, it is of shape (N,).</span>
<span class="sd">        If ``label_column`` is specified as ``None``, then no column from the</span>
<span class="sd">        ``Dataset`` is treated as the label, and the output label tensor</span>
<span class="sd">        is ``None``.</span>

<span class="sd">        Note that you probably want to call :meth:`Dataset.split` on this dataset if</span>
<span class="sd">        there are to be multiple Torch workers consuming the data.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            label_column: The name of the column used as the</span>
<span class="sd">                label (second element of the output list). Can be None for</span>
<span class="sd">                prediction, in which case the second element of returned</span>
<span class="sd">                tuple will also be None.</span>
<span class="sd">            feature_columns: The names of the columns</span>
<span class="sd">                to use as the features. Can be a list of lists or</span>
<span class="sd">                a dict of string-list pairs for multi-tensor output.</span>
<span class="sd">                If ``None``, then use all columns except the label column as</span>
<span class="sd">                the features.</span>
<span class="sd">            label_column_dtype: The torch dtype to</span>
<span class="sd">                use for the label column. If ``None``, then automatically infer</span>
<span class="sd">                the dtype.</span>
<span class="sd">            feature_column_dtypes: The dtypes to use for the feature</span>
<span class="sd">                tensors. This should match the format of ``feature_columns``,</span>
<span class="sd">                or be a single dtype, in which case it is applied to</span>
<span class="sd">                all tensors. If ``None``, then automatically infer the dtype.</span>
<span class="sd">            batch_size: How many samples per batch to yield at a time.</span>
<span class="sd">                Defaults to 1.</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1. You can revert back to the old</span>
<span class="sd">                prefetching behavior that uses `prefetch_blocks` by setting</span>
<span class="sd">                `use_legacy_iter_batches` to True in the datasetContext.</span>
<span class="sd">            drop_last: Set to True to drop the last incomplete batch,</span>
<span class="sd">                if the dataset size is not divisible by the batch size. If</span>
<span class="sd">                False and the size of the stream is not divisible by the batch</span>
<span class="sd">                size, then the last batch is smaller. Defaults to False.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer is drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>
<span class="sd">            unsqueeze_label_tensor: If set to True, the label tensor</span>
<span class="sd">                is unsqueezed (reshaped to (N, 1)). Otherwise, it will</span>
<span class="sd">                be left as is, that is (N, ). In general, regression loss</span>
<span class="sd">                functions expect an unsqueezed tensor, while classification</span>
<span class="sd">                loss functions expect a squeezed one. Defaults to True.</span>
<span class="sd">            unsqueeze_feature_tensors: If set to True, the features tensors</span>
<span class="sd">                are unsqueezed (reshaped to (N, 1)) before being concatenated into</span>
<span class="sd">                the final features tensor. Otherwise, they are left as is, that is</span>
<span class="sd">                (N, ). Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Torch IterableDataset`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span>
            <span class="n">label_column</span><span class="o">=</span><span class="n">label_column</span><span class="p">,</span>
            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
            <span class="n">label_column_dtype</span><span class="o">=</span><span class="n">label_column_dtype</span><span class="p">,</span>
            <span class="n">feature_column_dtypes</span><span class="o">=</span><span class="n">feature_column_dtypes</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
            <span class="n">unsqueeze_label_tensor</span><span class="o">=</span><span class="n">unsqueeze_label_tensor</span><span class="p">,</span>
            <span class="n">unsqueeze_feature_tensors</span><span class="o">=</span><span class="n">unsqueeze_feature_tensors</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_tf"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_tf.html#ray.data.Dataset.to_tf">[docs]</a>    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">to_tf</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feature_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">label_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># Deprecated</span>
        <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;tf.data.Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a `TensorFlow Dataset &lt;https://www.tensorflow.org/api_docs/python/tf/data/Dataset/&gt;`_</span>
<span class="sd">        over this :class:`~ray.data.Dataset`.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            If your :class:`~ray.data.Dataset` contains ragged tensors, this method errors.</span>
<span class="sd">            To prevent errors, :ref:`resize your tensors &lt;transforming_tensors&gt;`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@air-example-data/iris.csv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            Dataset(</span>
<span class="sd">               num_blocks=...,</span>
<span class="sd">               num_rows=150,</span>
<span class="sd">               schema={</span>
<span class="sd">                  sepal length (cm): double,</span>
<span class="sd">                  sepal width (cm): double,</span>
<span class="sd">                  petal length (cm): double,</span>
<span class="sd">                  petal width (cm): double,</span>
<span class="sd">                  target: int64</span>
<span class="sd">               }</span>
<span class="sd">            )</span>

<span class="sd">            If your model accepts a single tensor as input, specify a single feature column.</span>

<span class="sd">            &gt;&gt;&gt; ds.to_tf(feature_columns=&quot;sepal length (cm)&quot;, label_columns=&quot;target&quot;)</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal length (cm)&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">            If your model accepts a dictionary as input, specify a list of feature columns.</span>

<span class="sd">            &gt;&gt;&gt; ds.to_tf([&quot;sepal length (cm)&quot;, &quot;sepal width (cm)&quot;], &quot;target&quot;)</span>
<span class="sd">            &lt;_OptionsDataset element_spec=({&#39;sepal length (cm)&#39;: TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal length (cm)&#39;), &#39;sepal width (cm)&#39;: TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal width (cm)&#39;)}, TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">            If your dataset contains multiple features but your model accepts a single</span>
<span class="sd">            tensor as input, combine features with</span>
<span class="sd">            :class:`~ray.data.preprocessors.Concatenator`.</span>

<span class="sd">            &gt;&gt;&gt; from ray.data.preprocessors import Concatenator</span>
<span class="sd">            &gt;&gt;&gt; preprocessor = Concatenator(output_column_name=&quot;features&quot;, exclude=&quot;target&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds = preprocessor.transform(ds)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            Concatenator</span>
<span class="sd">            +- Dataset(</span>
<span class="sd">                  num_blocks=...,</span>
<span class="sd">                  num_rows=150,</span>
<span class="sd">                  schema={</span>
<span class="sd">                     sepal length (cm): double,</span>
<span class="sd">                     sepal width (cm): double,</span>
<span class="sd">                     petal length (cm): double,</span>
<span class="sd">                     petal width (cm): double,</span>
<span class="sd">                     target: int64</span>
<span class="sd">                  }</span>
<span class="sd">               )</span>
<span class="sd">            &gt;&gt;&gt; ds.to_tf(&quot;features&quot;, &quot;target&quot;)</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=&#39;features&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">        Args:</span>
<span class="sd">            feature_columns: Columns that correspond to model inputs. If this is a</span>
<span class="sd">                string, the input data is a tensor. If this is a list, the input data</span>
<span class="sd">                is a ``dict`` that maps column names to their tensor representation.</span>
<span class="sd">            label_column: Columns that correspond to model targets. If this is a</span>
<span class="sd">                string, the target data is a tensor. If this is a list, the target data</span>
<span class="sd">                is a ``dict`` that maps column names to their tensor representation.</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1. You can revert back to the old</span>
<span class="sd">                prefetching behavior that uses `prefetch_blocks` by setting</span>
<span class="sd">                `use_legacy_iter_batches` to True in the :class:`~ray.data.DataContext`.</span>
<span class="sd">            batch_size: Record batch size. Defaults to 1.</span>
<span class="sd">            drop_last: Set to True to drop the last incomplete batch,</span>
<span class="sd">                if the dataset size is not divisible by the batch size. If</span>
<span class="sd">                False and the size of the stream is not divisible by the batch</span>
<span class="sd">                size, then the last batch is smaller. Defaults to False.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer is drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `TensorFlow Dataset`_ that yields inputs and targets.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~ray.data.Dataset.iter_tf_batches`</span>
<span class="sd">                Call this method if you need more flexibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">to_tf</span><span class="p">(</span>
            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
            <span class="n">label_columns</span><span class="o">=</span><span class="n">label_columns</span><span class="p">,</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_dask"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_dask.html#ray.data.Dataset.to_dask">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_dask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">meta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pandas.Series&quot;</span><span class="p">,</span>
            <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
            <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
            <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verify_meta</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;dask.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Dask DataFrame &lt;https://docs.dask.org/en/stable/generated/dask.dataframe.DataFrame.html#dask.dataframe.DataFrame&gt;`_.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>

<span class="sd">        Note that this function will set the Dask scheduler to Dask-on-Ray</span>
<span class="sd">        globally, via the config.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            meta: An empty `pandas DataFrame`_ or `Series`_ that matches the dtypes and column</span>
<span class="sd">                names of the stream. This metadata is necessary for many algorithms in</span>
<span class="sd">                dask dataframe to work. For ease of use, some alternative inputs are</span>
<span class="sd">                also available. Instead of a DataFrame, a dict of ``{name: dtype}`` or</span>
<span class="sd">                iterable of ``(name, dtype)`` can be provided (note that the order of</span>
<span class="sd">                the names should match the order of the columns). Instead of a series, a</span>
<span class="sd">                tuple of ``(name, dtype)`` can be used.</span>
<span class="sd">                By default, this is inferred from the underlying Dataset schema,</span>
<span class="sd">                with this argument supplying an optional override.</span>
<span class="sd">            verify_meta: If True, Dask will check that the partitions have consistent</span>
<span class="sd">                metadata. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Dask DataFrame`_ created from this dataset.</span>

<span class="sd">        .. _pandas DataFrame: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html</span>
<span class="sd">        .. _Series: https://pandas.pydata.org/docs/reference/api/pandas.Series.html</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="kn">import</span> <span class="nn">dask</span>
        <span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span>
        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">pa</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>
        <span class="kn">from</span> <span class="nn">ray.util.client.common</span> <span class="kn">import</span> <span class="n">ClientObjectRef</span>
        <span class="kn">from</span> <span class="nn">ray.util.dask</span> <span class="kn">import</span> <span class="n">ray_dask_get</span>

        <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">ray_dask_get</span><span class="p">)</span>

        <span class="nd">@dask</span><span class="o">.</span><span class="n">delayed</span>
        <span class="k">def</span> <span class="nf">block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">,</span> <span class="n">ClientObjectRef</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Dataset.to_dask() must be used with Dask-on-Ray, please &quot;</span>
                    <span class="s2">&quot;set the Dask scheduler to ray_dask_get (located in &quot;</span>
                    <span class="s2">&quot;ray.util.dask).&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">meta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">TensorDtype</span>

            <span class="c1"># Infer Dask metadata from Dataset schema.</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">):</span>
                <span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="n">col</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="p">(</span>
                                <span class="n">dtype</span>
                                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">TensorDtype</span><span class="p">)</span>
                                <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">object_</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">pa</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
                <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorType</span>

                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">type_</span><span class="p">,</span> <span class="n">ArrowTensorType</span><span class="p">)</span> <span class="k">for</span> <span class="n">type_</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
                    <span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="n">col</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="p">(</span>
                                    <span class="n">dtype</span><span class="o">.</span><span class="n">to_pandas_dtype</span><span class="p">()</span>
                                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ArrowTensorType</span><span class="p">)</span>
                                    <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">object_</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
                            <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">meta</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">empty_table</span><span class="p">()</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

        <span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">from_delayed</span><span class="p">(</span>
            <span class="p">[</span><span class="n">block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()],</span>
            <span class="n">meta</span><span class="o">=</span><span class="n">meta</span><span class="p">,</span>
            <span class="n">verify_meta</span><span class="o">=</span><span class="n">verify_meta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">ddf</span></div>

<div class="viewcode-block" id="Dataset.to_mars"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_mars.html#ray.data.Dataset.to_mars">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_mars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;mars.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Mars DataFrame &lt;https://mars-project.readthedocs.io/en/latest/reference/dataframe/index.html&gt;`_.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Mars DataFrame`_ created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
        <span class="kn">from</span> <span class="nn">mars.dataframe.datasource.read_raydataset</span> <span class="kn">import</span> <span class="n">DataFrameReadRayDataset</span>
        <span class="kn">from</span> <span class="nn">mars.dataframe.utils</span> <span class="kn">import</span> <span class="n">parse_index</span>

        <span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>

        <span class="n">refs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_pandas_refs</span><span class="p">()</span>
        <span class="c1"># remove this when https://github.com/mars-project/mars/issues/2945 got fixed</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>  <span class="c1"># Backwards compat with non strict mode.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">):</span>
            <span class="n">dtypes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="n">dtypes</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">empty_table</span><span class="p">()</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">dtypes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported format of schema </span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">index_value</span> <span class="o">=</span> <span class="n">parse_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">RangeIndex</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">columns_value</span> <span class="o">=</span> <span class="n">parse_index</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">store_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">DataFrameReadRayDataset</span><span class="p">(</span><span class="n">refs</span><span class="o">=</span><span class="n">refs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">op</span><span class="p">(</span><span class="n">index_value</span><span class="o">=</span><span class="n">index_value</span><span class="p">,</span> <span class="n">columns_value</span><span class="o">=</span><span class="n">columns_value</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_modin"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_modin.html#ray.data.Dataset.to_modin">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_modin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;modin.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Modin DataFrame &lt;https://modin.readthedocs.io/en/stable/flow/modin/pandas/dataframe.html&gt;`_.</span>

<span class="sd">        This works by first converting this dataset into a distributed set of</span>
<span class="sd">        Pandas DataFrames (using :meth:`Dataset.to_pandas_refs`).</span>
<span class="sd">        See caveats there. Then the individual DataFrames are used to</span>
<span class="sd">        create the Modin DataFrame using</span>
<span class="sd">        ``modin.distributed.dataframe.pandas.partitions.from_partitions()``.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using :meth:`.to_arrow_refs` or</span>
<span class="sd">        :meth:`.get_internal_block_refs`.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Modin DataFrame`_ created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="kn">from</span> <span class="nn">modin.distributed.dataframe.pandas.partitions</span> <span class="kn">import</span> <span class="n">from_partitions</span>

        <span class="n">pd_objs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_pandas_refs</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">from_partitions</span><span class="p">(</span><span class="n">pd_objs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_spark"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_spark.html#ray.data.Dataset.to_spark">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_spark</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spark</span><span class="p">:</span> <span class="s2">&quot;pyspark.sql.SparkSession&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pyspark.sql.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Spark DataFrame &lt;https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html&gt;`_.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            spark: A `SparkSession`_, which must be created by RayDP (Spark-on-Ray).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Spark DataFrame`_ created from this dataset.</span>

<span class="sd">        .. _SparkSession: https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.SparkSession.html</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="kn">import</span> <span class="nn">raydp</span>

        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>  <span class="c1"># Backwards compat with non strict mode.</span>
        <span class="k">return</span> <span class="n">raydp</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">ray_dataset_to_spark_dataframe</span><span class="p">(</span>
            <span class="n">spark</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_pandas"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_pandas.html#ray.data.Dataset.to_pandas">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_pandas</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` to a single pandas DataFrame.</span>

<span class="sd">        This method errors if the number of rows exceeds the provided ``limit``.</span>
<span class="sd">        To truncate the dataset beforehand, call :meth:`.limit`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([{&quot;a&quot;: i} for i in range(3)])</span>
<span class="sd">            &gt;&gt;&gt; ds.to_pandas()</span>
<span class="sd">               a</span>
<span class="sd">            0  0</span>
<span class="sd">            1  1</span>
<span class="sd">            2  2</span>

<span class="sd">        Time complexity: O(dataset size)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The maximum number of rows to return. An error is</span>
<span class="sd">                raised if the dataset has more rows than this limit. Defaults to</span>
<span class="sd">                ``None``, which means no limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A pandas DataFrame created from this dataset, containing a limited</span>
<span class="sd">            number of rows.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if the number of rows in the :class:`~ray.data.Dataset` exceeds</span>
<span class="sd">                ``limit``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;the dataset has more than the given limit of </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;rows: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">. If you are sure that a DataFrame with &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> rows will fit in local memory, set ds.to_pandas(limit=None) &quot;</span>
                <span class="s2">&quot;to disable limits.&quot;</span>
            <span class="p">)</span>
        <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">DelegatingBlockBuilder</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">:</span>
            <span class="n">output</span><span class="o">.</span><span class="n">add_block</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="p">))</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_pandas_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_pandas_refs.html#ray.data.Dataset.to_pandas_refs">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_pandas_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Converts this :class:`~ray.data.Dataset` into a distributed set of Pandas</span>
<span class="sd">        dataframes.</span>

<span class="sd">        One DataFrame is created for each block in this Dataset.</span>

<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using :meth:`Dataset.to_arrow` or</span>
<span class="sd">        :meth:`Dataset.get_internal_block_refs`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10, parallelism=2)</span>
<span class="sd">            &gt;&gt;&gt; refs = ds.to_pandas_refs()</span>
<span class="sd">            &gt;&gt;&gt; len(refs)</span>
<span class="sd">            2</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote pandas DataFrames created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">block_to_df</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_df</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">block_to_df</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()]</span></div>

<div class="viewcode-block" id="Dataset.to_numpy_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_numpy_refs.html#ray.data.Dataset.to_numpy_refs">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_numpy_refs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Converts this :class:`~ray.data.Dataset` into a distributed set of NumPy</span>
<span class="sd">        ndarrays or dictionary of NumPy ndarrays.</span>

<span class="sd">        This is only supported for datasets convertible to NumPy ndarrays.</span>
<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using :meth:`Dataset.to_arrow` or</span>
<span class="sd">        :meth:`Dataset.get_internal_block_refs`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10, parallelism=2)</span>
<span class="sd">            &gt;&gt;&gt; refs = ds.to_numpy_refs()</span>
<span class="sd">            &gt;&gt;&gt; len(refs)</span>
<span class="sd">            2</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            column: The name of the column to convert to numpy. If ``None``, all columns</span>
<span class="sd">                are used. If multiple columns are specified, each returned</span>
<span class="sd">            future represents a dict of ndarrays. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote NumPy ndarrays created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">block_to_ndarray</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_ndarray</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">block_to_ndarray</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="p">]</span></div>

<div class="viewcode-block" id="Dataset.to_arrow_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_arrow_refs.html#ray.data.Dataset.to_arrow_refs">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_arrow_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a distributed set of PyArrow</span>
<span class="sd">        tables.</span>

<span class="sd">        One PyArrow table is created for each block in this Dataset.</span>

<span class="sd">        This method is only supported for datasets convertible to PyArrow tables.</span>
<span class="sd">        This function is zero-copy if the existing data is already in PyArrow</span>
<span class="sd">        format. Otherwise, the data is converted to PyArrow format.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10, parallelism=2)</span>
<span class="sd">            &gt;&gt;&gt; refs = ds.to_arrow_refs()</span>
<span class="sd">            &gt;&gt;&gt; len(refs)</span>
<span class="sd">            2</span>

<span class="sd">        Time complexity: O(1) unless conversion is required.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote PyArrow tables created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()</span>
        <span class="c1"># Schema is safe to call since we have already triggered execution with</span>
        <span class="c1"># get_internal_block_refs.</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>  <span class="c1"># Backwards compat with non strict mode.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="c1"># Zero-copy path.</span>
            <span class="k">return</span> <span class="n">blocks</span>

        <span class="n">block_to_arrow</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_arrow</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">block_to_arrow</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span></div>

<div class="viewcode-block" id="Dataset.to_random_access_dataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_random_access_dataset.html#ray.data.Dataset.to_random_access_dataset">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Args:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_random_access_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RandomAccessDataset</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this dataset into a distributed RandomAccessDataset (EXPERIMENTAL).</span>

<span class="sd">        RandomAccessDataset partitions the dataset across the cluster by the given</span>
<span class="sd">        sort key, providing efficient random access to records via binary search. A</span>
<span class="sd">        number of worker actors are created, each of which has zero-copy access to the</span>
<span class="sd">        underlying sorted data blocks of the dataset.</span>

<span class="sd">        Note that the key must be unique in the dataset. If there are duplicate keys,</span>
<span class="sd">        an arbitrary value is returned.</span>

<span class="sd">        This is only supported for Arrow-format datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            key: The key column over which records can be queried.</span>
<span class="sd">            num_workers: The number of actors to use to serve random access queries.</span>
<span class="sd">                By default, this is determined by multiplying the number of Ray nodes</span>
<span class="sd">                in the cluster by four. As a rule of thumb, you can expect each worker</span>
<span class="sd">                to provide ~3000 records / second via ``get_async()``, and</span>
<span class="sd">                ~10000 records / second via ``multiget()``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_workers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">RandomAccessDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.repeat"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.repeat.html#ray.data.Dataset.repeat">[docs]</a>    <span class="nd">@Deprecated</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">times</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DatasetPipeline&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this into a DatasetPipeline by looping over this dataset.</span>

<span class="sd">        Transformations prior to the call to ``repeat()`` are evaluated once.</span>
<span class="sd">        Transformations done on the returned pipeline are evaluated on each</span>
<span class="sd">        loop of the pipeline over the base dataset.</span>

<span class="sd">        Note that every repeat of the dataset is considered an &quot;epoch&quot; for</span>
<span class="sd">        the purposes of ``DatasetPipeline.iter_epochs()``.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(5, parallelism=1)</span>
<span class="sd">            &gt;&gt;&gt; # Infinite pipeline of numbers [0, 5)</span>
<span class="sd">            &gt;&gt;&gt; ds.repeat().take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, ...])}</span>
<span class="sd">            &gt;&gt;&gt; # Can shuffle each epoch (dataset) in the pipeline.</span>
<span class="sd">            &gt;&gt;&gt; ds.repeat().random_shuffle().take_batch() # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 0, 4, 1, 4, 0, 2, 1, 3, ...])}</span>

<span class="sd">        Args:</span>
<span class="sd">            times: The number of times to loop over this dataset, or None</span>
<span class="sd">                to repeat indefinitely.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">_rewrite_read_stage</span>
        <span class="kn">from</span> <span class="nn">ray.data.dataset_pipeline</span> <span class="kn">import</span> <span class="n">DatasetPipeline</span>

        <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">is_read_stage_equivalent</span><span class="p">()</span> <span class="ow">and</span> <span class="n">ctx</span><span class="o">.</span><span class="n">optimize_fuse_read_stages</span><span class="p">:</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_get_source_blocks_and_stages</span><span class="p">()</span>
            <span class="n">blocks</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">outer_stats</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="n">_rewrite_read_stage</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">stages</span><span class="p">)</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
            <span class="n">outer_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">uuid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">()</span>
        <span class="n">outer_stats</span><span class="o">.</span><span class="n">dataset_uuid</span> <span class="o">=</span> <span class="n">uuid</span>

        <span class="k">if</span> <span class="n">times</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">times</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`times` must be &gt;= 1, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">times</span><span class="p">))</span>

        <span class="k">class</span> <span class="nc">Iterator</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">blocks</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span> <span class="o">=</span> <span class="n">blocks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_i</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">times</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_i</span> <span class="o">&gt;=</span> <span class="n">times</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">StopIteration</span>
                <span class="n">epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_i</span>
                <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_i</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">def</span> <span class="nf">gen</span><span class="p">():</span>
                    <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                        <span class="n">ExecutionPlan</span><span class="p">(</span>
                            <span class="n">blocks</span><span class="p">,</span>
                            <span class="n">outer_stats</span><span class="p">,</span>
                            <span class="n">dataset_uuid</span><span class="o">=</span><span class="n">uuid</span><span class="p">,</span>
                            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">epoch</span><span class="p">,</span>
                        <span class="n">lazy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">ds</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="n">uuid</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">ds</span>

                <span class="k">return</span> <span class="n">gen</span>

        <span class="k">class</span> <span class="nc">Iterable</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">blocks</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span> <span class="o">=</span> <span class="n">blocks</span>

            <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">Iterator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_blocks</span><span class="p">)</span>

        <span class="n">pipe</span> <span class="o">=</span> <span class="n">DatasetPipeline</span><span class="p">(</span><span class="n">Iterable</span><span class="p">(</span><span class="n">blocks</span><span class="p">),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">times</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">read_stage</span><span class="p">:</span>
            <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">foreach_window</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">ds</span><span class="p">,</span> <span class="n">read_stage</span><span class="o">=</span><span class="n">read_stage</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">(</span>
                    <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">read_stage</span><span class="p">),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="kc">True</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">pipe</span></div>

<div class="viewcode-block" id="Dataset.window"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.window.html#ray.data.Dataset.window">[docs]</a>    <span class="nd">@Deprecated</span>
    <span class="k">def</span> <span class="nf">window</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">blocks_per_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bytes_per_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DatasetPipeline&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Convert this into a DatasetPipeline by windowing over data blocks.</span>

<span class="sd">        Transformations prior to the call to ``window()`` are evaluated in</span>
<span class="sd">        bulk on the entire dataset. Transformations done on the returned</span>
<span class="sd">        pipeline are evaluated incrementally per window of blocks as data is</span>
<span class="sd">        read from the output of the pipeline.</span>

<span class="sd">        Windowing execution allows for output to be read sooner without</span>
<span class="sd">        waiting for all transformations to fully execute, and can also improve</span>
<span class="sd">        efficiency if transforms use different resources (e.g., GPUs).</span>

<span class="sd">        Without windowing::</span>

<span class="sd">            [preprocessing......]</span>
<span class="sd">                                  [inference.......]</span>
<span class="sd">                                                     [write........]</span>
<span class="sd">            Time -----------------------------------------------------------&gt;</span>

<span class="sd">        With windowing::</span>

<span class="sd">            [prep1] [prep2] [prep3]</span>
<span class="sd">                    [infer1] [infer2] [infer3]</span>
<span class="sd">                             [write1] [write2] [write3]</span>
<span class="sd">            Time -----------------------------------------------------------&gt;</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Create an inference pipeline.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_binary_files(dir) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; infer = ... # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; pipe = ds.window(blocks_per_window=10).map(infer) # doctest: +SKIP</span>
<span class="sd">            DatasetPipeline(num_windows=40, num_stages=2)</span>
<span class="sd">            &gt;&gt;&gt; # The higher the stage parallelism, the shorter the pipeline.</span>
<span class="sd">            &gt;&gt;&gt; pipe = ds.window(blocks_per_window=20).map(infer) # doctest: +SKIP</span>
<span class="sd">            DatasetPipeline(num_windows=20, num_stages=2)</span>
<span class="sd">            &gt;&gt;&gt; # Outputs can be incrementally read from the pipeline.</span>
<span class="sd">            &gt;&gt;&gt; for item in pipe.iter_rows(): # doctest: +SKIP</span>
<span class="sd">            ...    print(item) # doctest: +SKIP</span>

<span class="sd">        Args:</span>
<span class="sd">            blocks_per_window: The window size (parallelism) in blocks.</span>
<span class="sd">                Increasing window size increases pipeline throughput, but also</span>
<span class="sd">                increases the latency to initial output, since it decreases the</span>
<span class="sd">                length of the pipeline. Setting this to infinity effectively</span>
<span class="sd">                disables pipelining.</span>
<span class="sd">            bytes_per_window: Specify the window size in bytes instead of blocks.</span>
<span class="sd">                This is treated as an upper bound for the window size, but each</span>
<span class="sd">                window will still include at least one block. This is mutually</span>
<span class="sd">                exclusive with ``blocks_per_window``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">_rewrite_read_stage</span>
        <span class="kn">from</span> <span class="nn">ray.data.dataset_pipeline</span> <span class="kn">import</span> <span class="n">DatasetPipeline</span>

        <span class="k">if</span> <span class="n">blocks_per_window</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">bytes_per_window</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only one windowing scheme can be specified.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">blocks_per_window</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">blocks_per_window</span> <span class="o">=</span> <span class="mi">10</span>

        <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">is_read_stage_equivalent</span><span class="p">()</span> <span class="ow">and</span> <span class="n">ctx</span><span class="o">.</span><span class="n">optimize_fuse_read_stages</span><span class="p">:</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_get_source_blocks_and_stages</span><span class="p">()</span>
            <span class="n">blocks</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="n">blocks</span><span class="p">,</span> <span class="n">outer_stats</span><span class="p">,</span> <span class="n">stages</span> <span class="o">=</span> <span class="n">_rewrite_read_stage</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">stages</span><span class="p">)</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
            <span class="n">outer_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
            <span class="n">read_stage</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">class</span> <span class="nc">Iterator</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">splits</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span> <span class="o">=</span> <span class="n">splits</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

            <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">StopIteration</span>

                <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">gen</span><span class="p">():</span>
                    <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                        <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">outer_stats</span><span class="p">,</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
                        <span class="n">lazy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">return</span> <span class="n">ds</span>

                <span class="k">return</span> <span class="n">gen</span>

        <span class="k">class</span> <span class="nc">Iterable</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">blocks</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">bytes_per_window</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">split_by_bytes</span><span class="p">(</span><span class="n">bytes_per_window</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">split_size</span><span class="o">=</span><span class="n">blocks_per_window</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">size_bytes</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">]</span>
                    <span class="n">num_blocks</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">]</span>
                    <span class="k">assert</span> <span class="p">[</span><span class="n">s</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">],</span> <span class="n">sizes</span>

                    <span class="k">def</span> <span class="nf">fmt</span><span class="p">(</span><span class="n">size_bytes</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">size_bytes</span> <span class="o">&gt;</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">:</span>
                            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">GiB&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                <span class="nb">round</span><span class="p">(</span><span class="n">size_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
                            <span class="p">)</span>
                        <span class="k">elif</span> <span class="n">size_bytes</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">:</span>
                            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">MiB&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">size_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">b&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">size_bytes</span><span class="p">)</span>

                    <span class="n">mean_bytes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sizes</span><span class="p">))</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Created DatasetPipeline with </span><span class="si">{}</span><span class="s2"> windows: &quot;</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> min, </span><span class="si">{}</span><span class="s2"> max, </span><span class="si">{}</span><span class="s2"> mean&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">),</span>
                            <span class="n">fmt</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">sizes</span><span class="p">)),</span>
                            <span class="n">fmt</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">sizes</span><span class="p">)),</span>
                            <span class="n">fmt</span><span class="p">(</span><span class="n">mean_bytes</span><span class="p">),</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">mean_num_blocks</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">))</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Blocks per window: &quot;</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> min, </span><span class="si">{}</span><span class="s2"> max, </span><span class="si">{}</span><span class="s2"> mean&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="nb">min</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">),</span>
                            <span class="nb">max</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">),</span>
                            <span class="n">mean_num_blocks</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="c1"># TODO(ekl) we should try automatically choosing the default</span>
                    <span class="c1"># windowing settings to meet these best-practice constraints.</span>
                    <span class="n">avail_parallelism</span> <span class="o">=</span> <span class="n">_estimate_available_parallelism</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">mean_num_blocks</span> <span class="o">&lt;</span> <span class="n">avail_parallelism</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s parallelism is limited &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;by its blocks per window to ~</span><span class="si">{</span><span class="n">mean_num_blocks</span><span class="si">}</span><span class="s2"> &quot;</span>
                            <span class="s2">&quot;concurrent tasks per window. To maximize &quot;</span>
                            <span class="s2">&quot;performance, increase the blocks per window to at least &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">avail_parallelism</span><span class="si">}</span><span class="s2">. This may require increasing the &quot;</span>
                            <span class="s2">&quot;base dataset&#39;s parallelism and/or adjusting the &quot;</span>
                            <span class="s2">&quot;windowing parameters.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">OK_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s per-window parallelism &quot;</span>
                            <span class="s2">&quot;is high enough to fully utilize the cluster.&quot;</span>
                        <span class="p">)</span>
                    <span class="n">obj_store_mem</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">cluster_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;object_store_memory&quot;</span><span class="p">,</span> <span class="mi">0</span>
                    <span class="p">)</span>
                    <span class="n">safe_mem_bytes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">obj_store_mem</span> <span class="o">*</span> <span class="n">ESTIMATED_SAFE_MEMORY_FRACTION</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">mean_bytes</span> <span class="o">&gt;</span> <span class="n">safe_mem_bytes</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s windows are &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;~</span><span class="si">{</span><span class="n">fmt</span><span class="p">(</span><span class="n">mean_bytes</span><span class="p">)</span><span class="si">}</span><span class="s2"> in size each and may not fit in &quot;</span>
                            <span class="s2">&quot;object store memory without spilling. To improve &quot;</span>
                            <span class="s2">&quot;performance, consider reducing the size of each window &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;to </span><span class="si">{</span><span class="n">fmt</span><span class="p">(</span><span class="n">safe_mem_bytes</span><span class="p">)</span><span class="si">}</span><span class="s2"> or less.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">OK_PREFIX</span><span class="si">}</span><span class="s2"> This pipeline&#39;s windows likely fit in &quot;</span>
                            <span class="s2">&quot;object store memory without spilling.&quot;</span>
                        <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Created DatasetPipeline with </span><span class="si">{}</span><span class="s2"> windows; &quot;</span>
                        <span class="s2">&quot;error getting sizes: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">),</span>
                            <span class="n">e</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

            <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">Iterator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_splits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">)</span>

        <span class="n">it</span> <span class="o">=</span> <span class="n">Iterable</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">)</span>
        <span class="n">pipe</span> <span class="o">=</span> <span class="n">DatasetPipeline</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">_splits</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">read_stage</span><span class="p">:</span>
            <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">foreach_window</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">ds</span><span class="p">,</span> <span class="n">read_stage</span><span class="o">=</span><span class="n">read_stage</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">(</span>
                    <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">with_stage</span><span class="p">(</span><span class="n">read_stage</span><span class="p">),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="kc">True</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">pipe</span></div>

<div class="viewcode-block" id="Dataset.fully_executed"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.fully_executed.html#ray.data.Dataset.fully_executed">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Use `Dataset.materialize()` instead.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fully_executed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Deprecation warning: use Dataset.materialize() instead of &quot;</span>
            <span class="s2">&quot;fully_executed().&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">force_read</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Dataset.is_fully_executed"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.is_fully_executed.html#ray.data.Dataset.is_fully_executed">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Check `isinstance(Dataset, MaterializedDataset)` instead.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">is_fully_executed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Deprecation warning: Check &quot;</span>
            <span class="s2">&quot;`isinstance(Dataset, MaterializedDataset)` &quot;</span>
            <span class="s2">&quot;instead of using is_fully_executed().&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">has_computed_output</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.materialize"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.materialize.html#ray.data.Dataset.materialize">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;store memory.&quot;</span><span class="p">,</span> <span class="n">insert_after</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">materialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Execute and materialize this dataset into object store memory.</span>

<span class="sd">        This can be used to read all blocks into memory. By default, Dataset</span>
<span class="sd">        doesn&#39;t read blocks from the datasource until the first transform.</span>

<span class="sd">        Note that this does not mutate the original Dataset. Only the blocks of the</span>
<span class="sd">        returned MaterializedDataset class are pinned in memory.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; materialized_ds = ds.materialize()</span>
<span class="sd">            &gt;&gt;&gt; materialized_ds</span>
<span class="sd">            MaterializedDataset(num_blocks=..., num_rows=10, schema={id: int64})</span>

<span class="sd">        Returns:</span>
<span class="sd">            A MaterializedDataset holding the materialized data blocks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">copy</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_deep_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_as</span><span class="o">=</span><span class="n">MaterializedDataset</span><span class="p">)</span>
        <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">force_read</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">blocks</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_snapshot_blocks</span>
        <span class="n">blocks_with_metadata</span> <span class="o">=</span> <span class="n">blocks</span><span class="o">.</span><span class="n">get_blocks_with_metadata</span><span class="p">()</span> <span class="k">if</span> <span class="n">blocks</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="c1"># TODO(hchen): Here we generate the same number of blocks as</span>
        <span class="c1"># the original Dataset. Because the old code path does this, and</span>
        <span class="c1"># some unit tests implicily depend on this behavior.</span>
        <span class="c1"># After we remove the old code path, we should consider merging</span>
        <span class="c1"># some blocks for better perf.</span>
        <span class="n">ref_bundles</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">RefBundle</span><span class="p">(</span>
                <span class="n">blocks</span><span class="o">=</span><span class="p">[</span><span class="n">block_with_metadata</span><span class="p">],</span>
                <span class="n">owns_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">block_with_metadata</span> <span class="ow">in</span> <span class="n">blocks_with_metadata</span>
        <span class="p">]</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">blocks</span><span class="p">,</span>
                <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span>
                <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">copy</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="n">copy</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
            <span class="n">logical_plan</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">output</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>  <span class="c1"># No-op that marks the plan as fully executed.</span>
        <span class="n">output</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_in_stats</span><span class="o">.</span><span class="n">dataset_uuid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Dataset.stats"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.stats.html#ray.data.Dataset.stats">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;timing information.&quot;</span><span class="p">,</span> <span class="n">insert_after</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a string containing execution timing information.</span>

<span class="sd">        Note that this does not trigger execution, so if the dataset has not yet</span>
<span class="sd">        executed, an empty string is returned.</span>

<span class="sd">        Examples:</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import ray</span>

<span class="sd">            ds = ray.data.range(10)</span>
<span class="sd">            assert ds.stats() == &quot;&quot;</span>

<span class="sd">            ds = ds.materialize()</span>
<span class="sd">            print(ds.stats())</span>

<span class="sd">        .. testoutput::</span>
<span class="sd">            :options: +MOCK</span>

<span class="sd">            Stage 0 Read: 20/20 blocks executed in 0.3s</span>
<span class="sd">            * Remote wall time: 16.29us min, 7.29ms max, 1.21ms mean, 24.17ms total</span>
<span class="sd">            * Remote cpu time: 16.0us min, 2.54ms max, 810.45us mean, 16.21ms total</span>
<span class="sd">            * Peak heap memory usage (MiB): 137968.75 min, 142734.38 max, 139846 mean</span>
<span class="sd">            * Output num rows: 0 min, 1 max, 0 mean, 10 total</span>
<span class="sd">            * Output size bytes: 0 min, 8 max, 4 mean, 80 total</span>
<span class="sd">            * Tasks per node: 20 min, 20 max, 20 mean; 1 nodes used</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_stats_summary</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_get_stats_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DatasetStatsSummary</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats_summary</span><span class="p">()</span>

<div class="viewcode-block" id="Dataset.get_internal_block_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.get_internal_block_refs.html#ray.data.Dataset.get_internal_block_refs">[docs]</a>    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">get_internal_block_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Get a list of references to the underlying blocks of this dataset.</span>

<span class="sd">        This function can be used for zero-copy access to the data. It blocks</span>
<span class="sd">        until the underlying blocks are computed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1)</span>
<span class="sd">            &gt;&gt;&gt; ds.get_internal_block_refs()</span>
<span class="sd">            [ObjectRef(...)]</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of references to this dataset&#39;s blocks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">get_blocks</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">blocks</span></div>

<div class="viewcode-block" id="Dataset.lazy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.lazy.html#ray.data.Dataset.lazy">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span>
        <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Dataset is lazy by default, so this conversion call is no longer &quot;</span>
        <span class="s2">&quot;needed and this API will be removed in a future release&quot;</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">lazy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Enable lazy evaluation.</span>

<span class="sd">        Dataset is lazy by default, so this is only useful for datasets created</span>
<span class="sd">        from :func:`ray.data.from_items() &lt;ray.data.read_api.from_items&gt;`, which is</span>
<span class="sd">        eager.</span>

<span class="sd">        The returned dataset is a lazy dataset, where all subsequent operations</span>
<span class="sd">        on the stream won&#39;t be executed until the dataset is consumed</span>
<span class="sd">        (e.g. ``.take()``, ``.iter_batches()``, ``.to_torch()``, ``.to_tf()``, etc.)</span>
<span class="sd">        or execution is manually triggered via ``.materialize()``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span> <span class="n">lazy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">logical_plan</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span>
        <span class="p">)</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">ds</span></div>

<div class="viewcode-block" id="Dataset.has_serializable_lineage"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.has_serializable_lineage.html#ray.data.Dataset.has_serializable_lineage">[docs]</a>    <span class="k">def</span> <span class="nf">has_serializable_lineage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Whether this dataset&#39;s lineage is able to be serialized for storage and</span>
<span class="sd">        later deserialized, possibly on a different cluster.</span>

<span class="sd">        Only datasets that are created from data that we know will still exist at</span>
<span class="sd">        deserialization time, e.g. data external to this Ray cluster such as persistent</span>
<span class="sd">        cloud object stores, support lineage-based serialization. All of the</span>
<span class="sd">        ray.data.read_*() APIs support lineage-based serialization.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items(list(range(10))).has_serializable_lineage()</span>
<span class="sd">            False</span>
<span class="sd">            &gt;&gt;&gt; ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;).has_serializable_lineage()</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">has_lazy_input</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.serialize_lineage"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.serialize_lineage.html#ray.data.Dataset.serialize_lineage">[docs]</a>    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">serialize_lineage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Serialize this dataset&#39;s lineage, not the actual data or the existing data</span>
<span class="sd">        futures, to bytes that can be stored and later deserialized, possibly on a</span>
<span class="sd">        different cluster.</span>

<span class="sd">        Note that this will drop all computed data, and that everything is</span>
<span class="sd">        recomputed from scratch after deserialization.</span>

<span class="sd">        Use :py:meth:`Dataset.deserialize_lineage` to deserialize the serialized</span>
<span class="sd">        bytes returned from this method into a Dataset.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Unioned and zipped datasets, produced by :py:meth`Dataset.union` and</span>
<span class="sd">            :py:meth:`Dataset.zip`, are not lineage-serializable.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">                serialized_ds = ds.serialize_lineage()</span>
<span class="sd">                ds = ray.data.Dataset.deserialize_lineage(serialized_ds)</span>
<span class="sd">                print(ds)</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                Dataset(</span>
<span class="sd">                   num_blocks=1,</span>
<span class="sd">                   num_rows=150,</span>
<span class="sd">                   schema={</span>
<span class="sd">                      sepal length (cm): double,</span>
<span class="sd">                      sepal width (cm): double,</span>
<span class="sd">                      petal length (cm): double,</span>
<span class="sd">                      petal width (cm): double,</span>
<span class="sd">                      target: int64</span>
<span class="sd">                   }</span>
<span class="sd">                )</span>


<span class="sd">        Returns:</span>
<span class="sd">            Serialized bytes containing the lineage of this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_serializable_lineage</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Lineage-based serialization is not supported for this stream, which &quot;</span>
                <span class="s2">&quot;means that it cannot be used as a tunable hyperparameter. &quot;</span>
                <span class="s2">&quot;Lineage-based serialization is explicitly NOT supported for unioned &quot;</span>
                <span class="s2">&quot;or zipped datasets (see docstrings for those methods), and is only &quot;</span>
                <span class="s2">&quot;supported for datasets created from data that we know will still &quot;</span>
                <span class="s2">&quot;exist at deserialization time, e.g. external data in persistent cloud &quot;</span>
                <span class="s2">&quot;object stores or in-memory data from long-lived clusters. Concretely, &quot;</span>
                <span class="s2">&quot;all ray.data.read_*() APIs should support lineage-based &quot;</span>
                <span class="s2">&quot;serialization, while all of the ray.data.from_*() APIs do not. To &quot;</span>
                <span class="s2">&quot;allow this stream to be serialized to storage, write the data to an &quot;</span>
                <span class="s2">&quot;external store (such as AWS S3, GCS, or Azure Blob Storage) using the &quot;</span>
                <span class="s2">&quot;Dataset.write_*() APIs, and serialize a new dataset reading &quot;</span>
                <span class="s2">&quot;from the external store using the ray.data.read_*() APIs.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Copy Dataset and clear the blocks from the execution plan so only the</span>
        <span class="c1"># Dataset&#39;s lineage is serialized.</span>
        <span class="n">plan_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">deep_copy</span><span class="p">(</span><span class="n">preserve_uuid</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logical_plan_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan_copy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_epoch</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span> <span class="n">logical_plan_copy</span><span class="p">)</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">clear_block_refs</span><span class="p">()</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">())</span>

        <span class="k">def</span> <span class="nf">_reduce_remote_fn</span><span class="p">(</span><span class="n">rf</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">):</span>
            <span class="c1"># Custom reducer for Ray remote function handles that allows for</span>
            <span class="c1"># cross-cluster serialization.</span>
            <span class="c1"># This manually unsets the last export session and job to force re-exporting</span>
            <span class="c1"># of the function when the handle is deserialized on a new cluster.</span>
            <span class="c1"># TODO(Clark): Fix this in core Ray, see issue:</span>
            <span class="c1"># https://github.com/ray-project/ray/issues/24152.</span>
            <span class="n">reconstructor</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">__reduce__</span><span class="p">()</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_last_export_session_and_job&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span> <span class="n">reconstructor</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span>

        <span class="n">context</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">global_worker</span><span class="o">.</span><span class="n">get_serialization_context</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">context</span><span class="o">.</span><span class="n">_register_cloudpickle_reducer</span><span class="p">(</span>
                <span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">,</span> <span class="n">_reduce_remote_fn</span>
            <span class="p">)</span>
            <span class="n">serialized</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">context</span><span class="o">.</span><span class="n">_unregister_cloudpickle_reducer</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">serialized</span></div>

<div class="viewcode-block" id="Dataset.deserialize_lineage"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.deserialize_lineage.html#ray.data.Dataset.deserialize_lineage">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">deserialize_lineage</span><span class="p">(</span><span class="n">serialized_ds</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Deserialize the provided lineage-serialized Dataset.</span>

<span class="sd">        This assumes that the provided serialized bytes were serialized using</span>
<span class="sd">        :py:meth:`Dataset.serialize_lineage`.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">                serialized_ds = ds.serialize_lineage()</span>
<span class="sd">                ds = ray.data.Dataset.deserialize_lineage(serialized_ds)</span>
<span class="sd">                print(ds)</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                Dataset(</span>
<span class="sd">                   num_blocks=1,</span>
<span class="sd">                   num_rows=150,</span>
<span class="sd">                   schema={</span>
<span class="sd">                      sepal length (cm): double,</span>
<span class="sd">                      sepal width (cm): double,</span>
<span class="sd">                      petal length (cm): double,</span>
<span class="sd">                      petal width (cm): double,</span>
<span class="sd">                      target: int64</span>
<span class="sd">                   }</span>
<span class="sd">                )</span>

<span class="sd">        Args:</span>
<span class="sd">            serialized_ds: The serialized Dataset that we wish to deserialize.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A deserialized ``Dataset`` instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">serialized_ds</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">context</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataContext</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the DataContext used to create this Dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_context</span>

    <span class="k">def</span> <span class="nf">_divide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">):</span>
        <span class="n">block_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">left</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">block_list</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">block_idx</span><span class="p">)</span>
        <span class="n">l_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">left</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
            <span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">r_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">right</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="n">block_list</span><span class="o">.</span><span class="n">_owned_by_consumer</span>
            <span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">l_ds</span><span class="p">,</span> <span class="n">r_ds</span>

<div class="viewcode-block" id="Dataset.default_batch_format"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.default_batch_format.html#ray.data.Dataset.default_batch_format">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;The batch format is no longer exposed as a public API.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">default_batch_format</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;default_batch_format() is not allowed in Ray 2.5&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.dataset_format"><a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.dataset_format.html#ray.data.Dataset.dataset_format">[docs]</a>    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;The dataset format is no longer exposed as a public API.&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">dataset_format</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BlockFormat</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dataset_format() is not allowed in Ray 2.5&quot;</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_aggregate_on</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">agg_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper for aggregating on a particular subset of the dataset.</span>

<span class="sd">        This validates the `on` argument, and converts a list of column names</span>
<span class="sd">        or lambdas to a multi-aggregation. A null `on` results in a</span>
<span class="sd">        multi-aggregation on all columns for an Arrow Dataset, and a single</span>
<span class="sd">        aggregation on the entire row for a simple Dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">aggs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_multicolumn_aggs</span><span class="p">(</span><span class="n">agg_cls</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="o">*</span><span class="n">aggs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_multicolumn_aggs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">agg_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span>
        <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span>
        <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">skip_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Build set of aggregations for applying a single aggregation to</span>
<span class="sd">        multiple columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Expand None into an aggregation for each column.</span>
        <span class="k">if</span> <span class="n">on</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_cols</span><span class="p">:</span>
                    <span class="n">skip_cols</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">on</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">names</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">skip_cols</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">on</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">on</span> <span class="o">=</span> <span class="p">[</span><span class="n">on</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">agg_cls</span><span class="p">(</span><span class="n">on_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="o">=</span><span class="n">ignore_nulls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">on_</span> <span class="ow">in</span> <span class="n">on</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_aggregate_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">U</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># NOTE (kfstorm): We cannot call `result[0]` directly on</span>
                <span class="c1"># `PandasRow` because indexing a column with position is not</span>
                <span class="c1"># supported by pandas.</span>
                <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@repr_with_fallback</span><span class="p">([</span><span class="s2">&quot;ipywidgets&quot;</span><span class="p">,</span> <span class="s2">&quot;8&quot;</span><span class="p">])</span>
    <span class="k">def</span> <span class="nf">_repr_mimebundle_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a mimebundle with an ipywidget repr and a simple text repr.</span>

<span class="sd">        Depending on the frontend where the data is being displayed,</span>
<span class="sd">        different mimetypes are used from this bundle.</span>
<span class="sd">        See https://ipython.readthedocs.io/en/stable/config/integrating.html</span>
<span class="sd">        for information about this method, and</span>
<span class="sd">        https://ipywidgets.readthedocs.io/en/latest/embedding.html</span>
<span class="sd">        for more information about the jupyter widget mimetype.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A mimebundle containing an ipywidget repr and a simple text repr.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">ipywidgets</span>

        <span class="n">title</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;h2&gt;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&lt;/h2&gt;&quot;</span><span class="p">)</span>
        <span class="n">tab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tab_repr_</span><span class="p">()</span>
        <span class="n">widget</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span><span class="n">title</span><span class="p">,</span> <span class="n">tab</span><span class="p">],</span> <span class="n">layout</span><span class="o">=</span><span class="n">ipywidgets</span><span class="o">.</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s2">&quot;100%&quot;</span><span class="p">))</span>

        <span class="c1"># Get the widget mime bundle, but replace the plaintext</span>
        <span class="c1"># with the Datastream repr</span>
        <span class="n">bundle</span> <span class="o">=</span> <span class="n">widget</span><span class="o">.</span><span class="n">_repr_mimebundle_</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">bundle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;text/plain&quot;</span><span class="p">:</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">bundle</span>

    <span class="k">def</span> <span class="nf">_tab_repr_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">Tab</span>

        <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;num_blocks&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">(),</span>
            <span class="s2">&quot;num_rows&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_meta_count</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="c1"># Show metadata if available, but don&#39;t trigger execution.</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;rendered_html_common.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="s2">&quot;&lt;h5&gt;Unknown schema&lt;/h5&gt;&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;rendered_html_common.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;&lt;h5&gt;Data type: &lt;code&gt;</span><span class="si">{</span><span class="n">html</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">schema</span><span class="p">))</span><span class="si">}</span><span class="s2">&lt;/code&gt;&lt;/h5&gt;&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">schema_data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">sname</span><span class="p">,</span> <span class="n">stype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
                <span class="n">schema_data</span><span class="p">[</span><span class="n">sname</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">stype</span><span class="p">,</span> <span class="s2">&quot;__name__&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">stype</span><span class="p">))</span>

            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;scrollableTable.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">table</span><span class="o">=</span><span class="n">tabulate</span><span class="p">(</span>
                    <span class="n">tabular_data</span><span class="o">=</span><span class="n">schema_data</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                    <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">,</span>
                    <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Name&quot;</span><span class="p">,</span> <span class="s2">&quot;Type&quot;</span><span class="p">],</span>
                <span class="p">),</span>
                <span class="n">max_height</span><span class="o">=</span><span class="s2">&quot;300px&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">children</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">HTML</span><span class="p">(</span>
                <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;scrollableTable.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                    <span class="n">table</span><span class="o">=</span><span class="n">tabulate</span><span class="p">(</span>
                        <span class="n">tabular_data</span><span class="o">=</span><span class="n">metadata</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                        <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">,</span>
                        <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Field&quot;</span><span class="p">,</span> <span class="s2">&quot;Value&quot;</span><span class="p">],</span>
                    <span class="p">),</span>
                    <span class="n">max_height</span><span class="o">=</span><span class="s2">&quot;300px&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">schema_repr</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Tab</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">titles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Metadata&quot;</span><span class="p">,</span> <span class="s2">&quot;Schema&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">get_plan_as_string</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__bool__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="c1"># Prevents `__len__` from being called to check if it is None</span>
        <span class="c1"># see: issue #25152</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="s2">&quot;Use `ds.count()` to compute the length of a distributed Dataset. &quot;</span>
            <span class="s2">&quot;This may be an expensive operation.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;`Dataset` objects aren&#39;t iterable. To iterate records, call &quot;</span>
            <span class="s2">&quot;`ds.iter_rows()` or `ds.iter_batches()`. For more information, read &quot;</span>
            <span class="s2">&quot;https://docs.ray.io/en/latest/data/consuming-datasets.html.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_block_num_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">get_num_rows</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_num_rows</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="n">get_num_rows</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()])</span>

    <span class="k">def</span> <span class="nf">_block_size_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">get_size_bytes</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_size_bytes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="p">[</span><span class="n">get_size_bytes</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_internal_block_refs</span><span class="p">()]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_meta_count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">meta_count</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_uuid</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span>

    <span class="k">def</span> <span class="nf">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uuid</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">uuid</span>

    <span class="k">def</span> <span class="nf">_get_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span>

    <span class="k">def</span> <span class="nf">_set_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

    <span class="k">def</span> <span class="nf">_synchronize_progress_bar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Flush progress bar output by shutting down the current executor.</span>

<span class="sd">        This should be called at the end of all blocking APIs (e.g., `take`), but not</span>
<span class="sd">        async APIs (e.g., `iter_batches`).</span>

<span class="sd">        The streaming executor runs in a separate generator / thread, so it is</span>
<span class="sd">        possible the shutdown logic runs even after a call to retrieve rows from the</span>
<span class="sd">        stream has finished. Explicit shutdown avoids this, which can clobber console</span>
<span class="sd">        output (https://github.com/ray-project/ray/issues/32414).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Note: excludes _current_executor which is not serializable.</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;plan&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="p">,</span>
            <span class="s2">&quot;uuid&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span><span class="p">,</span>
            <span class="s2">&quot;lazy&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">,</span>
            <span class="s2">&quot;logical_plan&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;plan&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;uuid&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epoch</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;lazy&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;logical_plan&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="ow">and</span> <span class="n">ray</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ray</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span></div>


<span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">MaterializedDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Generic</span><span class="p">[</span><span class="n">T</span><span class="p">]):</span>
    <span class="sd">&quot;&quot;&quot;A Dataset materialized in Ray memory, e.g., via `.materialize()`.</span>

<span class="sd">    The blocks of a MaterializedDataset object are materialized into Ray object store</span>
<span class="sd">    memory, which means that this class can be shared or iterated over by multiple Ray</span>
<span class="sd">    tasks without re-executing the underlying computations for producing the stream.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">pass</span>


<span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;beta&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Schema</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Dataset schema.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        names: List of column names of this Dataset.</span>
<span class="sd">        types: List of Arrow types of the Dataset. Note that the &quot;object&quot; type is</span>
<span class="sd">            not Arrow compatible and hence is returned as `object`.</span>
<span class="sd">        base_schema: The underlying Arrow or Pandas schema.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_schema</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.lib.Schema&quot;</span><span class="p">,</span> <span class="s2">&quot;PandasBlockSchema&quot;</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span> <span class="o">=</span> <span class="n">base_schema</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Lists the columns of this Dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">names</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">types</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="nb">object</span><span class="p">],</span> <span class="s2">&quot;pyarrow.DataType&quot;</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Lists the types of this Dataset in Arrow format</span>

<span class="sd">        For non-Arrow compatible types, we return &quot;object&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorType</span><span class="p">,</span> <span class="n">TensorDtype</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>

        <span class="n">arrow_types</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">types</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">TensorDtype</span><span class="p">):</span>
                <span class="c1"># Manually convert our Pandas tensor extension type to Arrow.</span>
                <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">ArrowTensorType</span><span class="p">(</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">from_numpy_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">from_numpy_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">))</span>
                <span class="k">except</span> <span class="n">pa</span><span class="o">.</span><span class="n">ArrowNotImplementedError</span><span class="p">:</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error converting dtype </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> to Arrow.&quot;</span><span class="p">)</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">arrow_types</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Schema</span><span class="p">)</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">base_schema</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">column_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">)])</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="mi">2</span>

        <span class="n">output</span> <span class="o">=</span> <span class="s2">&quot;Column&quot;</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;Type</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Type&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="nb">type</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="n">name</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">def</span> <span class="nf">_get_size_bytes</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">size_bytes</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_block_to_ndarray</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_block_to_arrow</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_arrow</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_sliding_window</span><span class="p">(</span><span class="n">iterable</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates an iterator consisting of n-width sliding windows over</span>
<span class="sd">    iterable. The sliding windows are constructed lazily such that an</span>
<span class="sd">    element on the base iterator (iterable) isn&#39;t consumed until the</span>
<span class="sd">    first sliding window containing that element is reached.</span>

<span class="sd">    If n &gt; len(iterable), then a single len(iterable) window is</span>
<span class="sd">    returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        iterable: The iterable on which the sliding window is</span>
<span class="sd">            created.</span>
<span class="sd">        n: The width of the sliding window.</span>

<span class="sd">    Returns:</span>
<span class="sd">        An iterator of n-width windows over iterable.</span>
<span class="sd">        If n &gt; len(iterable), then a single len(iterable) window is</span>
<span class="sd">        returned.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>
    <span class="n">window</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">islice</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">window</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">yield</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">window</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">it</span><span class="p">:</span>
        <span class="n">window</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span>
        <span class="k">yield</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">window</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_do_write</span><span class="p">(</span>
    <span class="n">ds</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="n">DataContext</span><span class="p">,</span>
    <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Block</span><span class="p">],</span>
    <span class="n">meta</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">BlockMetadata</span><span class="p">],</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">write_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">WriteResult</span><span class="p">]]:</span>
    <span class="n">write_args</span> <span class="o">=</span> <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">write_args</span><span class="p">)</span>
    <span class="n">DataContext</span><span class="o">.</span><span class="n">_set_current</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">do_write</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">meta</span><span class="p">,</span> <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span> <span class="o">**</span><span class="n">write_args</span><span class="p">)</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>谢谢你的反馈！</span>
  </div>
  <div id="csat-inputs">
    <span>是否能帮助到你？</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>是<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>否<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">反馈</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">提交</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2024, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>