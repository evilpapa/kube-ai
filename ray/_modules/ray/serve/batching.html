
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.serve.batching &#8212; Ray 2.7.2</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/versionwarning.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../_static/js/docsearch.js"></script>
    <script defer="defer" src="../../../_static/js/csat.js"></script>
    <script defer="defer" src="../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../_static/js/top-navigation.js"></script>
    <script src="../../../_static/js/tags.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/serve/batching.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
  data-modal-disclaimer = "Results are automated and may be incorrect or contain inappropriate information. Do not include any personal data or confidential information."
  data-modal-title = "Ray Docs AI - Ask a Question"
  data-button-position-bottom = "60px"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 2.7.2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    欢迎来到 Ray ！
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/index.html">
   概述
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/getting-started.html">
   入门
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/installation.html">
   安装
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/use-cases.html">
   用例
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/examples.html">
   示例库
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/ray-libraries.html">
   生态
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/walkthrough.html">
   Ray 核心
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data/data.html">
   Ray 数据
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../train/train.html">
   Ray 训练
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../tune/index.html">
   Ray 调参
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/index.html">
   更多类库
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cluster/getting-started.html">
   Ray 集群
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-observability/index.html">
   监控调试
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-references/api.html">
   参考
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-contribute/index.html">
   开发者指引
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-security/index.html">
   安全
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/serve/batching.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.serve.batching</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">wraps</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">inspect</span> <span class="kn">import</span> <span class="n">iscoroutinefunction</span><span class="p">,</span> <span class="n">isasyncgenfunction</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">overload</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">AsyncGenerator</span><span class="p">,</span>
    <span class="n">Iterable</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.serve.exceptions</span> <span class="kn">import</span> <span class="n">RayServeException</span>
<span class="kn">from</span> <span class="nn">ray._private.utils</span> <span class="kn">import</span> <span class="n">get_or_create_event_loop</span>
<span class="kn">from</span> <span class="nn">ray.serve._private.utils</span> <span class="kn">import</span> <span class="n">extract_self_if_method_call</span>
<span class="kn">from</span> <span class="nn">ray._private.signature</span> <span class="kn">import</span> <span class="n">extract_signature</span><span class="p">,</span> <span class="n">flatten_args</span><span class="p">,</span> <span class="n">recover_args</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">_SingleRequest</span><span class="p">:</span>
    <span class="n">self_arg</span><span class="p">:</span> <span class="n">Any</span>
    <span class="n">flattened_args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>
    <span class="n">future</span><span class="p">:</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Future</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">_GeneratorResult</span><span class="p">:</span>
    <span class="n">result</span><span class="p">:</span> <span class="n">Any</span>
    <span class="n">next_future</span><span class="p">:</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Future</span>


<span class="k">def</span> <span class="nf">_batch_args_kwargs</span><span class="p">(</span>
    <span class="n">list_of_flattened_args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;Batch a list of flatten args and returns regular args and kwargs&quot;&quot;&quot;</span>
    <span class="c1"># Ray&#39;s flatten arg format is a list with alternating key and values</span>
    <span class="c1"># e.g. args=(1, 2), kwargs={&quot;key&quot;: &quot;val&quot;} got turned into</span>
    <span class="c1">#      [None, 1, None, 2, &quot;key&quot;, &quot;val&quot;]</span>
    <span class="n">arg_lengths</span> <span class="o">=</span> <span class="p">{</span><span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="k">for</span> <span class="n">args</span> <span class="ow">in</span> <span class="n">list_of_flattened_args</span><span class="p">}</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">arg_lengths</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="p">),</span> <span class="s2">&quot;All batch requests should have the same number of parameters.&quot;</span>
    <span class="n">arg_length</span> <span class="o">=</span> <span class="n">arg_lengths</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>

    <span class="n">batched_flattened_args</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">arg_length</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">batched_flattened_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">list_of_flattened_args</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batched_flattened_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">list_of_flattened_args</span><span class="p">]</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">recover_args</span><span class="p">(</span><span class="n">batched_flattened_args</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_BatchQueue</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_wait_timeout_s</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">handle_batch_func</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Async queue that accepts individual items and returns batches.</span>

<span class="sd">        Respects max_batch_size and timeout_s; a batch will be returned when</span>
<span class="sd">        max_batch_size elements are available or the timeout has passed since</span>
<span class="sd">        the previous get.</span>

<span class="sd">        If handle_batch_func is passed in, a background coroutine will run to</span>
<span class="sd">        poll from the queue and call handle_batch_func on the results.</span>

<span class="sd">        Cannot be pickled.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            max_batch_size: max number of elements to return in a batch.</span>
<span class="sd">            timeout_s: time to wait before returning an incomplete</span>
<span class="sd">                batch.</span>
<span class="sd">            handle_batch_func(Optional[Callable]): callback to run in the</span>
<span class="sd">                background to handle batches if provided.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">:</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Queue</span><span class="p">[</span><span class="n">_SingleRequest</span><span class="p">]</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">max_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span> <span class="o">=</span> <span class="n">batch_wait_timeout_s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_put_event</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_handle_batch_task</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">handle_batch_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_handle_batch_task</span> <span class="o">=</span> <span class="n">get_or_create_event_loop</span><span class="p">()</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_process_batches</span><span class="p">(</span><span class="n">handle_batch_func</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">put</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">_SingleRequest</span><span class="p">,</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Future</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">put_nowait</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_put_event</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">wait_for_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Wait for batch respecting self.max_batch_size and self.timeout_s.</span>

<span class="sd">        Returns a batch of up to self.max_batch_size items. Waits for up to</span>
<span class="sd">        to self.timeout_s after receiving the first request that will be in</span>
<span class="sd">        the next batch. After the timeout, returns as many items as are ready.</span>

<span class="sd">        Always returns a batch with at least one item - will block</span>
<span class="sd">        indefinitely until an item comes in.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">get</span><span class="p">())</span>

        <span class="c1"># Cache current max_batch_size and batch_wait_timeout_s for this batch.</span>
        <span class="n">max_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span>
        <span class="n">batch_wait_timeout_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span>

        <span class="c1"># Wait self.timeout_s seconds for new queue arrivals.</span>
        <span class="n">batch_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">remaining_batch_time_s</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="n">batch_wait_timeout_s</span> <span class="o">-</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">batch_start_time</span><span class="p">),</span> <span class="mi">0</span>
            <span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Wait for new arrivals.</span>
                <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">wait_for</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">queue_put_event</span><span class="o">.</span><span class="n">wait</span><span class="p">(),</span> <span class="n">remaining_batch_time_s</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">TimeoutError</span><span class="p">:</span>
                <span class="k">pass</span>

            <span class="c1"># Add all new arrivals to the batch.</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_batch_size</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">empty</span><span class="p">():</span>
                <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">get_nowait</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue_put_event</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

            <span class="k">if</span> <span class="p">(</span>
                <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">batch_start_time</span> <span class="o">&gt;=</span> <span class="n">batch_wait_timeout_s</span>
                <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">max_batch_size</span>
            <span class="p">):</span>
                <span class="k">break</span>

        <span class="k">return</span> <span class="n">batch</span>

    <span class="k">def</span> <span class="nf">_validate_results</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">input_batch_length</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">!=</span> <span class="n">input_batch_length</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">RayServeException</span><span class="p">(</span>
                <span class="s2">&quot;Batched function doesn&#39;t preserve batch size. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;The input list has length </span><span class="si">{</span><span class="n">input_batch_length</span><span class="si">}</span><span class="s2"> but the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;returned list has length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">_consume_func_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">func_generator</span><span class="p">:</span> <span class="n">AsyncGenerator</span><span class="p">,</span>
        <span class="n">initial_futures</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">asyncio</span><span class="o">.</span><span class="n">Future</span><span class="p">],</span>
        <span class="n">input_batch_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Consumes batch function generator.</span>

<span class="sd">        This function only runs if the function decorated with @serve.batch</span>
<span class="sd">        is a generator.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">FINISHED_TOKEN</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">futures</span> <span class="o">=</span> <span class="n">initial_futures</span>
            <span class="k">async</span> <span class="k">for</span> <span class="n">results</span> <span class="ow">in</span> <span class="n">func_generator</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_validate_results</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">input_batch_length</span><span class="p">)</span>
                <span class="n">next_futures</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">result</span><span class="p">,</span> <span class="n">future</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">futures</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">future</span> <span class="ow">is</span> <span class="n">FINISHED_TOKEN</span><span class="p">:</span>
                        <span class="c1"># This caller has already terminated.</span>
                        <span class="n">next_futures</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">FINISHED_TOKEN</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">result</span> <span class="ow">in</span> <span class="p">[</span><span class="ne">StopIteration</span><span class="p">,</span> <span class="ne">StopAsyncIteration</span><span class="p">]:</span>
                        <span class="c1"># User&#39;s code returned sentinel. No values left</span>
                        <span class="c1"># for caller. Terminate iteration for caller.</span>
                        <span class="n">future</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="ne">StopAsyncIteration</span><span class="p">)</span>
                        <span class="n">next_futures</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">FINISHED_TOKEN</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">next_future</span> <span class="o">=</span> <span class="n">get_or_create_event_loop</span><span class="p">()</span><span class="o">.</span><span class="n">create_future</span><span class="p">()</span>
                        <span class="n">future</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">_GeneratorResult</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">next_future</span><span class="p">))</span>
                        <span class="n">next_futures</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_future</span><span class="p">)</span>
                <span class="n">futures</span> <span class="o">=</span> <span class="n">next_futures</span>

            <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">futures</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">future</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">FINISHED_TOKEN</span><span class="p">:</span>
                    <span class="n">future</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="ne">StopAsyncIteration</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">futures</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">future</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">FINISHED_TOKEN</span><span class="p">:</span>
                    <span class="n">future</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">_process_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Loops infinitely and processes queued request batches.&quot;&quot;&quot;</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SingleRequest</span><span class="p">]</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait_for_batch</span><span class="p">()</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="n">self_arg</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">self_arg</span>
            <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n">_batch_args_kwargs</span><span class="p">([</span><span class="n">item</span><span class="o">.</span><span class="n">flattened_args</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
            <span class="n">futures</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">future</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>

            <span class="c1"># Method call.</span>
            <span class="k">if</span> <span class="n">self_arg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">func_future_or_generator</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">self_arg</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="c1"># Normal function call.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">func_future_or_generator</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">isasyncgenfunction</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
                <span class="n">func_generator</span> <span class="o">=</span> <span class="n">func_future_or_generator</span>
                <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_consume_func_generator</span><span class="p">(</span><span class="n">func_generator</span><span class="p">,</span> <span class="n">futures</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">func_future</span> <span class="o">=</span> <span class="n">func_future_or_generator</span>
                    <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">func_future</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_results</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">result</span><span class="p">,</span> <span class="n">future</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">futures</span><span class="p">):</span>
                        <span class="n">future</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">futures</span><span class="p">:</span>
                        <span class="n">future</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_handle_batch_task</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="ow">not</span> <span class="n">get_or_create_event_loop</span><span class="p">()</span><span class="o">.</span><span class="n">is_running</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="k">return</span>

        <span class="c1"># TODO(edoakes): although we try to gracefully shutdown here, it still</span>
        <span class="c1"># causes some errors when the process exits due to the asyncio loop</span>
        <span class="c1"># already being destroyed.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_handle_batch_task</span><span class="o">.</span><span class="n">cancel</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">_LazyBatchQueueWrapper</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Stores a _BatchQueue and updates its settings.</span>

<span class="sd">    _BatchQueue cannot be pickled, you must construct it lazily</span>
<span class="sd">    at runtime inside a replica. This class initializes a queue only upon</span>
<span class="sd">    first access.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">batch_wait_timeout_s</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">handle_batch_func</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_queue_cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">_BatchQueue</span><span class="p">]</span> <span class="o">=</span> <span class="n">_BatchQueue</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">_BatchQueue</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">max_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span> <span class="o">=</span> <span class="n">batch_wait_timeout_s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">handle_batch_func</span> <span class="o">=</span> <span class="n">handle_batch_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_queue_cls</span> <span class="o">=</span> <span class="n">batch_queue_cls</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">queue</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">[</span><span class="n">_BatchQueue</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns _BatchQueue.</span>

<span class="sd">        Initializes queue when called for the first time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_queue_cls</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">handle_batch_func</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span>

    <span class="k">def</span> <span class="nf">set_max_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_max_batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Updates queue&#39;s max_batch_size.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">new_max_batch_size</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span><span class="o">.</span><span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">new_max_batch_size</span>

    <span class="k">def</span> <span class="nf">set_batch_wait_timeout_s</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_wait_timeout_s</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span> <span class="o">=</span> <span class="n">new_batch_wait_timeout_s</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span> <span class="o">=</span> <span class="n">new_batch_wait_timeout_s</span>

    <span class="k">def</span> <span class="nf">get_max_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span>

    <span class="k">def</span> <span class="nf">get_batch_wait_timeout_s</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span>


<span class="k">def</span> <span class="nf">_validate_max_batch_size</span><span class="p">(</span><span class="n">max_batch_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">max_batch_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">max_batch_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="n">max_batch_size</span><span class="o">.</span><span class="n">is_integer</span><span class="p">():</span>
            <span class="n">max_batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_batch_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;max_batch_size must be integer &gt;= 1, got </span><span class="si">{</span><span class="n">max_batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">max_batch_size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;max_batch_size must be an integer &gt;= 1, got </span><span class="si">{</span><span class="n">max_batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_validate_batch_wait_timeout_s</span><span class="p">(</span><span class="n">batch_wait_timeout_s</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_wait_timeout_s</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;batch_wait_timeout_s must be a float &gt;= 0, &quot;</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">batch_wait_timeout_s</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">batch_wait_timeout_s</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;batch_wait_timeout_s must be a float &gt;= 0, &quot;</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">batch_wait_timeout_s</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>


<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;R&quot;</span><span class="p">)</span>
<span class="n">F</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;F&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="n">Callable</span><span class="p">[[</span><span class="n">List</span><span class="p">[</span><span class="n">T</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">R</span><span class="p">]])</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;G&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="n">Callable</span><span class="p">[[</span><span class="n">T</span><span class="p">],</span> <span class="n">R</span><span class="p">])</span>


<span class="c1"># Normal decorator use case (called with no arguments).</span>
<span class="nd">@overload</span>
<span class="k">def</span> <span class="nf">batch</span><span class="p">(</span><span class="n">func</span><span class="p">:</span> <span class="n">F</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">G</span><span class="p">:</span>
    <span class="k">pass</span>


<span class="c1"># &quot;Decorator factory&quot; use case (called with arguments).</span>
<span class="nd">@overload</span>
<span class="k">def</span> <span class="nf">batch</span><span class="p">(</span>
    <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_wait_timeout_s</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">F</span><span class="p">],</span> <span class="n">G</span><span class="p">]:</span>
    <span class="k">pass</span>


<div class="viewcode-block" id="batch"><a class="viewcode-back" href="../../../serve/api/doc/ray.serve.batch.html#ray.serve.batch">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;stable&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">batch</span><span class="p">(</span>
    <span class="n">_func</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_wait_timeout_s</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">batch_queue_cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">_BatchQueue</span><span class="p">]</span> <span class="o">=</span> <span class="n">_BatchQueue</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts a function to asynchronously handle batches.</span>

<span class="sd">    The function can be a standalone function or a class method. In both</span>
<span class="sd">    cases, the function must be `async def` and take a list of objects as</span>
<span class="sd">    its sole argument and return a list of the same length as a result.</span>

<span class="sd">    When invoked, the caller passes a single object. These will be batched</span>
<span class="sd">    and executed asynchronously once there is a batch of `max_batch_size`</span>
<span class="sd">    or `batch_wait_timeout_s` has elapsed, whichever occurs first.</span>

<span class="sd">    `max_batch_size` and `batch_wait_timeout_s` can be updated using setter</span>
<span class="sd">    methods from the batch_handler (`set_max_batch_size` and</span>
<span class="sd">    `set_batch_wait_timeout_s`).</span>

<span class="sd">    Example:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">            from ray import serve</span>
<span class="sd">            from starlette.requests import Request</span>

<span class="sd">            @serve.deployment</span>
<span class="sd">            class BatchedDeployment:</span>
<span class="sd">                @serve.batch(max_batch_size=10, batch_wait_timeout_s=0.1)</span>
<span class="sd">                async def batch_handler(self, requests: List[Request]) -&gt; List[str]:</span>
<span class="sd">                    response_batch = []</span>
<span class="sd">                    for r in requests:</span>
<span class="sd">                        name = (await requests.json())[&quot;name&quot;]</span>
<span class="sd">                        response_batch.append(f&quot;Hello {name}!&quot;)</span>

<span class="sd">                    return response_batch</span>

<span class="sd">                def update_batch_params(self, max_batch_size, batch_wait_timeout_s):</span>
<span class="sd">                    self.batch_handler.set_max_batch_size(max_batch_size)</span>
<span class="sd">                    self.batch_handler.set_batch_wait_timeout_s(batch_wait_timeout_s)</span>

<span class="sd">                async def __call__(self, request: Request):</span>
<span class="sd">                    return await self.batch_handler(request)</span>

<span class="sd">            app = BatchedDeployment.bind()</span>

<span class="sd">    Arguments:</span>
<span class="sd">        max_batch_size: the maximum batch size that will be executed in</span>
<span class="sd">            one call to the underlying function.</span>
<span class="sd">        batch_wait_timeout_s: the maximum duration to wait for</span>
<span class="sd">            `max_batch_size` elements before running the current batch.</span>
<span class="sd">        batch_queue_cls: the class to use for the underlying batch queue.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># `_func` will be None in the case when the decorator is parametrized.</span>
    <span class="c1"># See the comment at the end of this function for a detailed explanation.</span>
    <span class="k">if</span> <span class="n">_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">_func</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;@serve.batch can only be used to decorate functions or methods.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">iscoroutinefunction</span><span class="p">(</span><span class="n">_func</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Functions decorated with @serve.batch must be &#39;async def&#39;&quot;</span><span class="p">)</span>

    <span class="n">_validate_max_batch_size</span><span class="p">(</span><span class="n">max_batch_size</span><span class="p">)</span>
    <span class="n">_validate_batch_wait_timeout_s</span><span class="p">(</span><span class="n">batch_wait_timeout_s</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_batch_decorator</span><span class="p">(</span><span class="n">_func</span><span class="p">):</span>
        <span class="n">lazy_batch_queue_wrapper</span> <span class="o">=</span> <span class="n">_LazyBatchQueueWrapper</span><span class="p">(</span>
            <span class="n">max_batch_size</span><span class="p">,</span>
            <span class="n">batch_wait_timeout_s</span><span class="p">,</span>
            <span class="n">_func</span><span class="p">,</span>
            <span class="n">batch_queue_cls</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">async</span> <span class="k">def</span> <span class="nf">batch_handler_generator</span><span class="p">(</span>
            <span class="n">first_future</span><span class="p">:</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Future</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Generator that handles generator batch functions.&quot;&quot;&quot;</span>

            <span class="n">future</span> <span class="o">=</span> <span class="n">first_future</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">async_response</span><span class="p">:</span> <span class="n">_GeneratorResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">future</span>
                    <span class="n">future</span> <span class="o">=</span> <span class="n">async_response</span><span class="o">.</span><span class="n">next_future</span>
                    <span class="k">yield</span> <span class="n">async_response</span><span class="o">.</span><span class="n">result</span>
                <span class="k">except</span> <span class="ne">StopAsyncIteration</span><span class="p">:</span>
                    <span class="k">break</span>

        <span class="k">def</span> <span class="nf">enqueue_request</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Future</span><span class="p">:</span>
            <span class="bp">self</span> <span class="o">=</span> <span class="n">extract_self_if_method_call</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">_func</span><span class="p">)</span>
            <span class="n">flattened_args</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="n">flatten_args</span><span class="p">(</span><span class="n">extract_signature</span><span class="p">(</span><span class="n">_func</span><span class="p">),</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># For functions, inject the batch queue as an</span>
                <span class="c1"># attribute of the function.</span>
                <span class="n">batch_queue_object</span> <span class="o">=</span> <span class="n">_func</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For methods, inject the batch queue as an</span>
                <span class="c1"># attribute of the object.</span>
                <span class="n">batch_queue_object</span> <span class="o">=</span> <span class="bp">self</span>
                <span class="c1"># Trim the self argument from methods</span>
                <span class="n">flattened_args</span> <span class="o">=</span> <span class="n">flattened_args</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

            <span class="n">batch_queue</span> <span class="o">=</span> <span class="n">lazy_batch_queue_wrapper</span><span class="o">.</span><span class="n">queue</span>

            <span class="c1"># Magic batch_queue_object attributes that can be used to change the</span>
            <span class="c1"># batch queue attributes on the fly.</span>
            <span class="c1"># This is purposefully undocumented for now while we figure out</span>
            <span class="c1"># the best API.</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">batch_queue_object</span><span class="p">,</span> <span class="s2">&quot;_ray_serve_max_batch_size&quot;</span><span class="p">):</span>
                <span class="n">new_max_batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="n">batch_queue_object</span><span class="p">,</span> <span class="s2">&quot;_ray_serve_max_batch_size&quot;</span>
                <span class="p">)</span>
                <span class="n">_validate_max_batch_size</span><span class="p">(</span><span class="n">new_max_batch_size</span><span class="p">)</span>
                <span class="n">batch_queue</span><span class="o">.</span><span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">new_max_batch_size</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">batch_queue_object</span><span class="p">,</span> <span class="s2">&quot;_ray_serve_batch_wait_timeout_s&quot;</span><span class="p">):</span>
                <span class="n">new_batch_wait_timeout_s</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="n">batch_queue_object</span><span class="p">,</span> <span class="s2">&quot;_ray_serve_batch_wait_timeout_s&quot;</span>
                <span class="p">)</span>
                <span class="n">_validate_batch_wait_timeout_s</span><span class="p">(</span><span class="n">new_batch_wait_timeout_s</span><span class="p">)</span>
                <span class="n">batch_queue</span><span class="o">.</span><span class="n">batch_wait_timeout_s</span> <span class="o">=</span> <span class="n">new_batch_wait_timeout_s</span>

            <span class="n">future</span> <span class="o">=</span> <span class="n">get_or_create_event_loop</span><span class="p">()</span><span class="o">.</span><span class="n">create_future</span><span class="p">()</span>
            <span class="n">batch_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">_SingleRequest</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flattened_args</span><span class="p">,</span> <span class="n">future</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">future</span>

        <span class="c1"># TODO (shrekris-anyscale): deprecate batch_queue_cls argument and</span>
        <span class="c1"># convert batch_wrapper into a class once `self` argument is no</span>
        <span class="c1"># longer needed in `enqueue_request`.</span>
        <span class="nd">@wraps</span><span class="p">(</span><span class="n">_func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">generator_batch_wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">first_future</span> <span class="o">=</span> <span class="n">enqueue_request</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">batch_handler_generator</span><span class="p">(</span><span class="n">first_future</span><span class="p">)</span>

        <span class="nd">@wraps</span><span class="p">(</span><span class="n">_func</span><span class="p">)</span>
        <span class="k">async</span> <span class="k">def</span> <span class="nf">batch_wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># This will raise if the underlying call raised an exception.</span>
            <span class="k">return</span> <span class="k">await</span> <span class="n">enqueue_request</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">isasyncgenfunction</span><span class="p">(</span><span class="n">_func</span><span class="p">):</span>
            <span class="n">wrapper</span> <span class="o">=</span> <span class="n">generator_batch_wrapper</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">wrapper</span> <span class="o">=</span> <span class="n">batch_wrapper</span>

        <span class="c1"># We store the lazy_batch_queue_wrapper&#39;s getters and setters as</span>
        <span class="c1"># batch_wrapper attributes, so they can be accessed in user code.</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">_get_max_batch_size</span> <span class="o">=</span> <span class="n">lazy_batch_queue_wrapper</span><span class="o">.</span><span class="n">get_max_batch_size</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">_get_batch_wait_timeout_s</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">lazy_batch_queue_wrapper</span><span class="o">.</span><span class="n">get_batch_wait_timeout_s</span>
        <span class="p">)</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">set_max_batch_size</span> <span class="o">=</span> <span class="n">lazy_batch_queue_wrapper</span><span class="o">.</span><span class="n">set_max_batch_size</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">set_batch_wait_timeout_s</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">lazy_batch_queue_wrapper</span><span class="o">.</span><span class="n">set_batch_wait_timeout_s</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="c1"># Unfortunately, this is required to handle both non-parametrized</span>
    <span class="c1"># (@serve.batch) and parametrized (@serve.batch(**kwargs)) usage.</span>
    <span class="c1"># In the former case, `serve.batch` will be called with the underlying</span>
    <span class="c1"># function as the sole argument. In the latter case, it will first be</span>
    <span class="c1"># called with **kwargs, then the result of that call will be called</span>
    <span class="c1"># with the underlying function as the sole argument (i.e., it must be a</span>
    <span class="c1"># &quot;decorator factory.&quot;).</span>
    <span class="k">return</span> <span class="n">_batch_decorator</span><span class="p">(</span><span class="n">_func</span><span class="p">)</span> <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">_func</span><span class="p">)</span> <span class="k">else</span> <span class="n">_batch_decorator</span></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>谢谢你的反馈！</span>
  </div>
  <div id="csat-inputs">
    <span>是否能帮助到你？</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>是<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>否<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">反馈</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">提交</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2024, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>