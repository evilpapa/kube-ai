
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.data.read_api &#8212; Ray 2.7.2</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/versionwarning.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../_static/js/docsearch.js"></script>
    <script defer="defer" src="../../../_static/js/csat.js"></script>
    <script defer="defer" src="../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../_static/js/top-navigation.js"></script>
    <script src="../../../_static/js/tags.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/data/read_api.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
  data-modal-disclaimer = "Results are automated and may be incorrect or contain inappropriate information. Do not include any personal data or confidential information."
  data-modal-title = "Ray Docs AI - Ask a Question"
  data-button-position-bottom = "60px"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 2.7.2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    欢迎来到 Ray ！
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/index.html">
   概述
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/getting-started.html">
   入门
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/installation.html">
   安装
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/use-cases.html">
   用例
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/examples.html">
   示例库
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-overview/ray-libraries.html">
   生态
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-core/walkthrough.html">
   Ray 核心
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data/data.html">
   Ray 数据
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../train/train.html">
   Ray 训练
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../tune/index.html">
   Ray 调参
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-more-libs/index.html">
   更多类库
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cluster/getting-started.html">
   Ray 集群
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-observability/index.html">
   监控调试
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-references/api.html">
   参考
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-contribute/index.html">
   开发者指引
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ray-security/index.html">
   安全
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/data/read_api.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.data.read_api</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray._private.auto_init_hook</span> <span class="kn">import</span> <span class="n">wrap_auto_init</span>
<span class="kn">from</span> <span class="nn">ray.air.util.tensor_extensions.utils</span> <span class="kn">import</span> <span class="n">_create_possibly_ragged_ndarray</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.block_list</span> <span class="kn">import</span> <span class="n">BlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.delegating_block_builder</span> <span class="kn">import</span> <span class="n">DelegatingBlockBuilder</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.lazy_block_list</span> <span class="kn">import</span> <span class="n">LazyBlockList</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.from_operators</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">FromArrow</span><span class="p">,</span>
    <span class="n">FromItems</span><span class="p">,</span>
    <span class="n">FromNumpy</span><span class="p">,</span>
    <span class="n">FromPandas</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.read_operator</span> <span class="kn">import</span> <span class="n">Read</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.optimizers</span> <span class="kn">import</span> <span class="n">LogicalPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">ExecutionPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.plan_read_op</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">apply_output_blocks_handling_to_read_task</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.remote_fn</span> <span class="kn">import</span> <span class="n">cached_remote_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.stats</span> <span class="kn">import</span> <span class="n">DatasetStats</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.util</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_autodetect_parallelism</span><span class="p">,</span>
    <span class="n">_is_local_scheme</span><span class="p">,</span>
    <span class="n">_lazy_import_pyarrow_dataset</span><span class="p">,</span>
    <span class="n">get_table_block_metadata</span><span class="p">,</span>
    <span class="n">ndarray_to_block</span><span class="p">,</span>
    <span class="n">pandas_df_to_arrow_block</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.block</span> <span class="kn">import</span> <span class="n">Block</span><span class="p">,</span> <span class="n">BlockAccessor</span><span class="p">,</span> <span class="n">BlockExecStats</span><span class="p">,</span> <span class="n">BlockMetadata</span>
<span class="kn">from</span> <span class="nn">ray.data.context</span> <span class="kn">import</span> <span class="n">WARN_PREFIX</span><span class="p">,</span> <span class="n">DataContext</span>
<span class="kn">from</span> <span class="nn">ray.data.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">MaterializedDataset</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BaseFileMetadataProvider</span><span class="p">,</span>
    <span class="n">BinaryDatasource</span><span class="p">,</span>
    <span class="n">Connection</span><span class="p">,</span>
    <span class="n">CSVDatasource</span><span class="p">,</span>
    <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">ImageDatasource</span><span class="p">,</span>
    <span class="n">JSONDatasource</span><span class="p">,</span>
    <span class="n">MongoDatasource</span><span class="p">,</span>
    <span class="n">NumpyDatasource</span><span class="p">,</span>
    <span class="n">ParquetBaseDatasource</span><span class="p">,</span>
    <span class="n">ParquetDatasource</span><span class="p">,</span>
    <span class="n">ParquetMetadataProvider</span><span class="p">,</span>
    <span class="n">PathPartitionFilter</span><span class="p">,</span>
    <span class="n">RangeDatasource</span><span class="p">,</span>
    <span class="n">SQLDatasource</span><span class="p">,</span>
    <span class="n">TextDatasource</span><span class="p">,</span>
    <span class="n">TFRecordDatasource</span><span class="p">,</span>
    <span class="n">WebDatasetDatasource</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource._default_metadata_providers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_generic_metadata_provider</span><span class="p">,</span>
    <span class="n">get_image_metadata_provider</span><span class="p">,</span>
    <span class="n">get_parquet_bulk_metadata_provider</span><span class="p">,</span>
    <span class="n">get_parquet_metadata_provider</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.datasource</span> <span class="kn">import</span> <span class="n">Reader</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.file_based_datasource</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">,</span>
    <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.partitioning</span> <span class="kn">import</span> <span class="n">Partitioning</span>
<span class="kn">from</span> <span class="nn">ray.types</span> <span class="kn">import</span> <span class="n">ObjectRef</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">Deprecated</span><span class="p">,</span> <span class="n">DeveloperAPI</span><span class="p">,</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.util.placement_group</span> <span class="kn">import</span> <span class="n">PlacementGroup</span>
<span class="kn">from</span> <span class="nn">ray.util.scheduling_strategies</span> <span class="kn">import</span> <span class="n">NodeAffinitySchedulingStrategy</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dask</span>
    <span class="kn">import</span> <span class="nn">datasets</span>
    <span class="kn">import</span> <span class="nn">mars</span>
    <span class="kn">import</span> <span class="nn">modin</span>
    <span class="kn">import</span> <span class="nn">pandas</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span>
    <span class="kn">import</span> <span class="nn">pymongoarrow.api</span>
    <span class="kn">import</span> <span class="nn">pyspark</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">from</span> <span class="nn">tensorflow_metadata.proto.v0</span> <span class="kn">import</span> <span class="n">schema_pb2</span>


<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="from_items"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_items.html#ray.data.from_items">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_items</span><span class="p">(</span>
    <span class="n">items</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a list of local Python objects.</span>

<span class="sd">    Use this method to create small datasets from data that fits in memory.</span>

<span class="sd">    Examples:</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.from_items([1, 2, 3, 4, 5])</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        MaterializedDataset(num_blocks=..., num_rows=5, schema={item: int64})</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column  Type</span>
<span class="sd">        ------  ----</span>
<span class="sd">        item    int64</span>

<span class="sd">    Args:</span>
<span class="sd">        items: List of local Python objects.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see</span>
<span class="sd">            :ref:`Tuning read parallelism &lt;read_parallelism&gt;`.</span>
<span class="sd">            Parallelism is upper bounded by ``len(items)``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` holding the items.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">builtins</span>

    <span class="k">if</span> <span class="n">parallelism</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;parallelism must be -1 or &gt; 0, got: </span><span class="si">{</span><span class="n">parallelism</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">detected_parallelism</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_autodetect_parallelism</span><span class="p">(</span>
        <span class="n">parallelism</span><span class="p">,</span>
        <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">get_current_placement_group</span><span class="p">(),</span>
        <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="c1"># Truncate parallelism to number of items to avoid empty blocks.</span>
    <span class="n">detected_parallelism</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">detected_parallelism</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">detected_parallelism</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">block_size</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">detected_parallelism</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">block_size</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="c1"># NOTE: We need to explicitly use the builtins range since we override range below,</span>
    <span class="c1"># with the definition of ray.data.range.</span>
    <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">BlockMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">builtins</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">detected_parallelism</span><span class="p">):</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">BlockExecStats</span><span class="o">.</span><span class="n">builder</span><span class="p">()</span>
        <span class="n">builder</span> <span class="o">=</span> <span class="n">DelegatingBlockBuilder</span><span class="p">()</span>
        <span class="c1"># Evenly distribute remainder across block slices while preserving record order.</span>
        <span class="n">block_start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
        <span class="n">block_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">builtins</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">block_start</span><span class="p">,</span> <span class="n">block_end</span><span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Mapping</span><span class="p">):</span>
                <span class="n">item</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;item&quot;</span><span class="p">:</span> <span class="n">item</span><span class="p">}</span>
            <span class="n">builder</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">block</span><span class="p">))</span>
        <span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">(</span>
                <span class="n">input_files</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exec_stats</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">from_items_op</span> <span class="o">=</span> <span class="n">FromItems</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">from_items_op</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromItems&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="range"><a class="viewcode-back" href="../../../data/api/doc/ray.data.range.html#ray.data.range">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` from a range of integers [0..n).</span>

<span class="sd">    This function allows for easy creation of synthetic datasets for testing or</span>
<span class="sd">    benchmarking :ref:`Ray Data &lt;data&gt;`.</span>

<span class="sd">    Examples:</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range(10000)</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset(num_blocks=..., num_rows=10000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; ds.map(lambda row: {&quot;id&quot;: row[&quot;id&quot;] * 2}).take(4)</span>
<span class="sd">        [{&#39;id&#39;: 0}, {&#39;id&#39;: 2}, {&#39;id&#39;: 4}, {&#39;id&#39;: 6}]</span>

<span class="sd">    Args:</span>
<span class="sd">        n: The upper bound of the range of integers.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see</span>
<span class="sd">            :ref:`Tuning read parallelism &lt;read_parallelism&gt;`.</span>
<span class="sd">            Parallelism is upper bounded by n.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` producing the integers from the range 0 to n.</span>

<span class="sd">    .. seealso::</span>

<span class="sd">        :meth:`~ray.data.range_tensor`</span>
<span class="sd">                    Call this method for creating synthetic datasets of tensor data.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">RangeDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
        <span class="n">block_format</span><span class="o">=</span><span class="s2">&quot;arrow&quot;</span><span class="p">,</span>
        <span class="n">column_name</span><span class="o">=</span><span class="s2">&quot;id&quot;</span><span class="p">,</span>
    <span class="p">)</span></div>


<span class="nd">@Deprecated</span>
<span class="k">def</span> <span class="nf">range_table</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">DeprecationWarning</span><span class="p">(</span><span class="s2">&quot;In Ray 2.5, use range() instead of range_table().&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="range_tensor"><a class="viewcode-back" href="../../../data/api/doc/ray.data.range_tensor.html#ray.data.range_tensor">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">range_tensor</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` tensors of the provided shape from range</span>
<span class="sd">    [0...n].</span>

<span class="sd">    This function allows for easy creation of synthetic tensor datasets for testing or</span>
<span class="sd">    benchmarking :ref:`Ray Data &lt;data&gt;`.</span>

<span class="sd">    Examples:</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range_tensor(1000, shape=(2, 2))</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset(</span>
<span class="sd">           num_blocks=...,</span>
<span class="sd">           num_rows=1000,</span>
<span class="sd">           schema={data: numpy.ndarray(shape=(2, 2), dtype=int64)}</span>
<span class="sd">        )</span>
<span class="sd">        &gt;&gt;&gt; ds.map_batches(lambda row: {&quot;data&quot;: row[&quot;data&quot;] * 2}).take(2)</span>
<span class="sd">        [{&#39;data&#39;: array([[0, 0],</span>
<span class="sd">               [0, 0]])}, {&#39;data&#39;: array([[2, 2],</span>
<span class="sd">               [2, 2]])}]</span>

<span class="sd">    Args:</span>
<span class="sd">        n: The upper bound of the range of tensor records.</span>
<span class="sd">        shape: The shape of each tensor in the dataset.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see</span>
<span class="sd">            :ref:`Tuning read parallelism &lt;read_parallelism&gt;`.</span>
<span class="sd">            Parallelism is upper bounded by n.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` producing the tensor data from range 0 to n.</span>

<span class="sd">    .. seealso::</span>

<span class="sd">        :meth:`~ray.data.range`</span>
<span class="sd">                    Call this method to create synthetic datasets of integer data.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">RangeDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
        <span class="n">block_format</span><span class="o">=</span><span class="s2">&quot;tensor&quot;</span><span class="p">,</span>
        <span class="n">column_name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">tensor_shape</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_datasource"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_datasource.html#ray.data.read_datasource">[docs]</a><span class="nd">@PublicAPI</span>
<span class="nd">@wrap_auto_init</span>
<span class="k">def</span> <span class="nf">read_datasource</span><span class="p">(</span>
    <span class="n">datasource</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">read_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Read a stream from a custom :class:`~ray.data.Datasource`.</span>

<span class="sd">    Args:</span>
<span class="sd">        datasource: The :class:`~ray.data.Datasource` to read data from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism might be</span>
<span class="sd">            limited by the available partitioning of the datasource. If set to -1,</span>
<span class="sd">            parallelism is automatically chosen based on the available cluster</span>
<span class="sd">            resources and estimated in-memory data size.</span>
<span class="sd">        read_args: Additional kwargs to pass to the :class:`~ray.data.Datasource`</span>
<span class="sd">            implementation.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`ray.remote` in the read tasks.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` that reads data from the :class:`~ray.data.Datasource`.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">ray_remote_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ray_remote_args</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">local_uri</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="n">read_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;paths&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">paths</span> <span class="ow">and</span> <span class="n">_is_local_scheme</span><span class="p">(</span><span class="n">paths</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">ray</span><span class="o">.</span><span class="n">is_connected</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The local scheme paths </span><span class="si">{</span><span class="n">paths</span><span class="si">}</span><span class="s2"> are not supported in Ray Client.&quot;</span>
            <span class="p">)</span>
        <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span>
            <span class="n">soft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">local_uri</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="s2">&quot;scheduling_strategy&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ray_remote_args</span><span class="p">:</span>
        <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">scheduling_strategy</span>

    <span class="n">force_local</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">cur_pg</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">get_current_placement_group</span><span class="p">()</span>
    <span class="n">pa_ds</span> <span class="o">=</span> <span class="n">_lazy_import_pyarrow_dataset</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">pa_ds</span><span class="p">:</span>
        <span class="n">partitioning</span> <span class="o">=</span> <span class="n">read_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataset_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;partitioning&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">partitioning</span><span class="p">,</span> <span class="n">pa_ds</span><span class="o">.</span><span class="n">Partitioning</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Forcing local metadata resolution since the provided partitioning &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">partitioning</span><span class="si">}</span><span class="s2"> is not serializable.&quot;</span>
            <span class="p">)</span>
            <span class="n">force_local</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="n">force_local</span><span class="p">:</span>
        <span class="p">(</span>
            <span class="n">requested_parallelism</span><span class="p">,</span>
            <span class="n">min_safe_parallelism</span><span class="p">,</span>
            <span class="n">inmemory_size</span><span class="p">,</span>
            <span class="n">reader</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">_get_reader</span><span class="p">(</span><span class="n">datasource</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">cur_pg</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">,</span> <span class="n">local_uri</span><span class="p">,</span> <span class="n">read_args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Prepare read in a remote task at same node.</span>
        <span class="c1"># NOTE: in Ray client mode, this is expected to be run on head node.</span>
        <span class="c1"># So we aren&#39;t attempting metadata resolution from the client machine.</span>
        <span class="n">scheduling_strategy</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
            <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span>
            <span class="n">soft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">get_reader</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span>
            <span class="n">_get_reader</span><span class="p">,</span> <span class="n">retry_exceptions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_cpus</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">scheduling_strategy</span><span class="o">=</span><span class="n">scheduling_strategy</span><span class="p">)</span>

        <span class="p">(</span><span class="n">requested_parallelism</span><span class="p">,</span> <span class="n">min_safe_parallelism</span><span class="p">,</span> <span class="n">inmemory_size</span><span class="p">,</span> <span class="n">reader</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="n">get_reader</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span>
                <span class="n">datasource</span><span class="p">,</span>
                <span class="n">ctx</span><span class="p">,</span>
                <span class="n">cur_pg</span><span class="p">,</span>
                <span class="n">parallelism</span><span class="p">,</span>
                <span class="n">local_uri</span><span class="p">,</span>
                <span class="n">_wrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">read_args</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># TODO(hchen/chengsu): Remove the duplicated get_read_tasks call here after</span>
    <span class="c1"># removing LazyBlockList code path.</span>
    <span class="n">read_tasks</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">get_read_tasks</span><span class="p">(</span><span class="n">requested_parallelism</span><span class="p">)</span>

    <span class="c1"># Compute the number of blocks the read will return. If the number of blocks is</span>
    <span class="c1"># expected to be less than the requested parallelism, boost the number of blocks</span>
    <span class="c1"># by adding an additional split into `k` pieces to each read task.</span>
    <span class="n">additional_split_factor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">read_tasks</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">inmemory_size</span><span class="p">:</span>
            <span class="n">expected_block_size</span> <span class="o">=</span> <span class="n">inmemory_size</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected block size </span><span class="si">{</span><span class="n">expected_block_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">size_based_splits</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span>
                <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">expected_block_size</span> <span class="o">/</span> <span class="n">ctx</span><span class="o">.</span><span class="n">target_max_block_size</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">size_based_splits</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size based split factor </span><span class="si">{</span><span class="n">size_based_splits</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">estimated_num_blocks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">*</span> <span class="n">size_based_splits</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Blocks after size splits </span><span class="si">{</span><span class="n">estimated_num_blocks</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Add more output splitting for each read task if needed.</span>
        <span class="k">if</span> <span class="n">estimated_num_blocks</span> <span class="o">&lt;</span> <span class="n">requested_parallelism</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">requested_parallelism</span> <span class="o">/</span> <span class="n">estimated_num_blocks</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;To satisfy the requested parallelism of </span><span class="si">{</span><span class="n">requested_parallelism</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;each read task output is split into </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> smaller blocks.&quot;</span>
            <span class="p">)</span>
            <span class="n">estimated_num_blocks</span> <span class="o">=</span> <span class="n">estimated_num_blocks</span> <span class="o">*</span> <span class="n">k</span>
            <span class="n">additional_split_factor</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Estimated num output blocks </span><span class="si">{estimated_num_blocks}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">estimated_num_blocks</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">read_task</span> <span class="ow">in</span> <span class="n">read_tasks</span><span class="p">:</span>
        <span class="n">apply_output_blocks_handling_to_read_task</span><span class="p">(</span>
            <span class="n">read_task</span><span class="p">,</span>
            <span class="n">additional_split_factor</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">read_stage_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Read</span><span class="si">{</span><span class="n">datasource</span><span class="o">.</span><span class="n">get_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">available_cpu_slots</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">available_resources</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">requested_parallelism</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">available_cpu_slots</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">read_tasks</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">5000</span>
    <span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">WARN_PREFIX</span><span class="si">}</span><span class="s2"> The requested parallelism of </span><span class="si">{</span><span class="n">requested_parallelism</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="s2">&quot;is more than 4x the number of available CPU slots in the cluster of &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">available_cpu_slots</span><span class="si">}</span><span class="s2">. This can &quot;</span>
            <span class="s2">&quot;lead to slowdowns during the data reading phase due to excessive &quot;</span>
            <span class="s2">&quot;task creation. Reduce the parallelism to match with the available &quot;</span>
            <span class="s2">&quot;CPU slots in the cluster, or set parallelism to -1 for Ray Data &quot;</span>
            <span class="s2">&quot;to automatically determine the parallelism. &quot;</span>
            <span class="s2">&quot;You can ignore this message if the cluster is expected to autoscale.&quot;</span>
        <span class="p">)</span>

    <span class="n">block_list</span> <span class="o">=</span> <span class="n">LazyBlockList</span><span class="p">(</span>
        <span class="n">read_tasks</span><span class="p">,</span>
        <span class="n">read_stage_name</span><span class="o">=</span><span class="n">read_stage_name</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">block_list</span><span class="o">.</span><span class="n">_estimated_num_blocks</span> <span class="o">=</span> <span class="n">estimated_num_blocks</span>

    <span class="n">read_op</span> <span class="o">=</span> <span class="n">Read</span><span class="p">(</span>
        <span class="n">datasource</span><span class="p">,</span>
        <span class="n">reader</span><span class="p">,</span>
        <span class="n">requested_parallelism</span><span class="p">,</span>
        <span class="n">additional_split_factor</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">read_op</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
        <span class="n">plan</span><span class="o">=</span><span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">block_list</span><span class="p">,</span> <span class="n">block_list</span><span class="o">.</span><span class="n">stats</span><span class="p">(),</span> <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">lazy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="o">=</span><span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_mongo"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_mongo.html#ray.data.read_mongo">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_mongo</span><span class="p">(</span>
    <span class="n">uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">database</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">collection</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pymongoarrow.api.Schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">mongo_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a MongoDB database.</span>

<span class="sd">    The data to read from is specified via the ``uri``, ``database`` and ``collection``</span>
<span class="sd">    of the MongoDB. The dataset is created from the results of executing</span>
<span class="sd">    ``pipeline`` against the ``collection``. If ``pipeline`` is None, the entire</span>
<span class="sd">    ``collection`` is read.</span>

<span class="sd">    .. tip::</span>

<span class="sd">        For more details about these MongoDB concepts, see the following:</span>
<span class="sd">        - URI: https://www.mongodb.com/docs/manual/reference/connection-string/</span>
<span class="sd">        - Database and Collection: https://www.mongodb.com/docs/manual/core/databases-and-collections/</span>
<span class="sd">        - Pipeline: https://www.mongodb.com/docs/manual/core/aggregation-pipeline/</span>

<span class="sd">    To read the MongoDB in parallel, the execution of the pipeline is run on partitions</span>
<span class="sd">    of the collection, with a Ray read task to handle a partition. Partitions are</span>
<span class="sd">    created in an attempt to evenly distribute the documents into the specified number</span>
<span class="sd">    of partitions. The number of partitions is determined by ``parallelism`` which can</span>
<span class="sd">    be requested from this interface or automatically chosen if unspecified (see the</span>
<span class="sd">    ``parallelism`` arg below).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from pymongoarrow.api import Schema # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_mongo( # doctest: +SKIP</span>
<span class="sd">        ...     uri=&quot;mongodb://username:password@mongodb0.example.com:27017/?authSource=admin&quot;, # noqa: E501</span>
<span class="sd">        ...     database=&quot;my_db&quot;,</span>
<span class="sd">        ...     collection=&quot;my_collection&quot;,</span>
<span class="sd">        ...     pipeline=[{&quot;$match&quot;: {&quot;col2&quot;: {&quot;$gte&quot;: 0, &quot;$lt&quot;: 100}}}, {&quot;$sort&quot;: &quot;sort_field&quot;}], # noqa: E501</span>
<span class="sd">        ...     schema=Schema({&quot;col1&quot;: pa.string(), &quot;col2&quot;: pa.int64()}),</span>
<span class="sd">        ...     parallelism=10,</span>
<span class="sd">        ... )</span>

<span class="sd">    Args:</span>
<span class="sd">        uri: The URI of the source MongoDB where the dataset is</span>
<span class="sd">            read from. For the URI format, see details in the `MongoDB docs &lt;https:/\</span>
<span class="sd">                /www.mongodb.com/docs/manual/reference/connection-string/&gt;`_.</span>
<span class="sd">        database: The name of the database hosted in the MongoDB. This database</span>
<span class="sd">            must exist otherwise ValueError is raised.</span>
<span class="sd">        collection: The name of the collection in the database. This collection</span>
<span class="sd">            must exist otherwise ValueError is raised.</span>
<span class="sd">        pipeline: A `MongoDB pipeline &lt;https://www.mongodb.com/docs/manual/core\</span>
<span class="sd">            /aggregation-pipeline/&gt;`_, which is executed on the given collection</span>
<span class="sd">            with results used to create Dataset. If None, the entire collection will</span>
<span class="sd">            be read.</span>
<span class="sd">        schema: The schema used to read the collection. If None, it&#39;ll be inferred from</span>
<span class="sd">            the results of pipeline.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>
<span class="sd">        mongo_args: kwargs passed to `aggregate_arrow_all() &lt;https://mongo-arrow\</span>
<span class="sd">            .readthedocs.io/en/latest/api/api.html#pymongoarrow.api\</span>
<span class="sd">            aggregate_arrow_all&gt;`_ in pymongoarrow in producing</span>
<span class="sd">            Arrow-formatted results.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` producing rows from the results of executing the pipeline on the specified MongoDB collection.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if ``database`` doesn&#39;t exist.</span>
<span class="sd">        ValueError: if ``collection`` doesn&#39;t exist.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">MongoDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">uri</span><span class="o">=</span><span class="n">uri</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">database</span><span class="p">,</span>
        <span class="n">collection</span><span class="o">=</span><span class="n">collection</span><span class="p">,</span>
        <span class="n">pipeline</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">mongo_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_parquet"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_parquet.html#ray.data.read_parquet">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_parquet</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tensor_column_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ParquetMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` from parquet files.</span>


<span class="sd">    Examples:</span>
<span class="sd">        Read a file in remote storage.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column        Type</span>
<span class="sd">        ------        ----</span>
<span class="sd">        sepal.length  double</span>
<span class="sd">        sepal.width   double</span>
<span class="sd">        petal.length  double</span>
<span class="sd">        petal.width   double</span>
<span class="sd">        variety       string</span>


<span class="sd">        Read a directory in remote storage.</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris-parquet/&quot;)</span>

<span class="sd">        Read multiple local files.</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_parquet(</span>
<span class="sd">        ...    [&quot;local:///path/to/file1&quot;, &quot;local:///path/to/file2&quot;]) # doctest: +SKIP</span>

<span class="sd">        Specify a schema for the parquet file.</span>
<span class="sd">        &gt;&gt;&gt; import pyarrow as pa</span>
<span class="sd">        &gt;&gt;&gt; fields = [(&quot;sepal.length&quot;, pa.float32()),</span>
<span class="sd">        ...           (&quot;sepal.width&quot;, pa.float32()),</span>
<span class="sd">        ...           (&quot;petal.length&quot;, pa.float32()),</span>
<span class="sd">        ...           (&quot;petal.width&quot;, pa.float32()),</span>
<span class="sd">        ...           (&quot;variety&quot;, pa.string())]</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;,</span>
<span class="sd">        ...     schema=pa.schema(fields))</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column        Type</span>
<span class="sd">        ------        ----</span>
<span class="sd">        sepal.length  float</span>
<span class="sd">        sepal.width   float</span>
<span class="sd">        petal.length  float</span>
<span class="sd">        petal.width   float</span>
<span class="sd">        variety       string</span>


<span class="sd">        The Parquet reader also supports projection and filter pushdown, allowing column</span>
<span class="sd">        selection and row filtering to be pushed down to the file scan.</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import pyarrow as pa</span>

<span class="sd">            # Create a Dataset by reading a Parquet file, pushing column selection and</span>
<span class="sd">            # row filtering down to the file scan.</span>
<span class="sd">            ds = ray.data.read_parquet(</span>
<span class="sd">                &quot;s3://anonymous@ray-example-data/iris.parquet&quot;,</span>
<span class="sd">                columns=[&quot;sepal.length&quot;, &quot;variety&quot;],</span>
<span class="sd">                filter=pa.dataset.field(&quot;sepal.length&quot;) &gt; 5.0,</span>
<span class="sd">            )</span>

<span class="sd">            ds.show(2)</span>

<span class="sd">        .. testoutput::</span>

<span class="sd">            {&#39;sepal.length&#39;: 5.1, &#39;variety&#39;: &#39;Setosa&#39;}</span>
<span class="sd">            {&#39;sepal.length&#39;: 5.4, &#39;variety&#39;: &#39;Setosa&#39;}</span>

<span class="sd">        For further arguments you can pass to PyArrow as a keyword argument, see the</span>
<span class="sd">        `PyArrow API reference &lt;https://arrow.apache.org/docs/python/generated/\</span>
<span class="sd">        pyarrow.dataset.Scanner.html#pyarrow.dataset.Scanner.from_fragment&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file path or directory, or a list of file paths. Multiple</span>
<span class="sd">            directories are not supported.</span>
<span class="sd">        filesystem: The PyArrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are specified in the</span>
<span class="sd">            `pyarrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">            filesystems.html#filesystem-implementations&gt;`_. Specify this parameter if</span>
<span class="sd">            you need to provide specific configurations to the filesystem. By default,</span>
<span class="sd">            the filesystem is automatically selected based on the scheme of the paths.</span>
<span class="sd">            For example, if the path begins with ``s3://``, the ``S3FileSystem`` is</span>
<span class="sd">            used. If ``None``, this function uses a system-chosen implementation.</span>
<span class="sd">        columns: A list of column names to read. Only the specified columns are</span>
<span class="sd">            read during the file scan.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`. Parallelism is upper bounded by the total number of</span>
<span class="sd">            records in all the parquet files.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>
<span class="sd">        tensor_column_schema: A dict of column name to PyArrow dtype and shape</span>
<span class="sd">            mappings for converting a Parquet column containing serialized</span>
<span class="sd">            tensors (ndarrays) as their elements to PyArrow tensors. This function</span>
<span class="sd">            assumes that the tensors are serialized in the raw</span>
<span class="sd">            NumPy array format in C-contiguous order (e.g., via</span>
<span class="sd">            `arr.tobytes()`).</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases you do not need to set this parameter.</span>
<span class="sd">        partition_filter: A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`. Use</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">        arrow_parquet_args: Other parquet read options to pass to PyArrow. For the full</span>
<span class="sd">            set of arguments, see the`PyArrow API &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.dataset.Scanner.html\</span>
<span class="sd">                    #pyarrow.dataset.Scanner.from_fragment&gt;`_</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` producing records read from the specified parquet</span>
<span class="sd">        files.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_parquet_metadata_provider</span><span class="p">()</span>
    <span class="n">arrow_parquet_args</span> <span class="o">=</span> <span class="n">_resolve_parquet_args</span><span class="p">(</span>
        <span class="n">tensor_column_schema</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">ParquetDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_images"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_images.html#ray.data.read_images">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;beta&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_images</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_file_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">PathPartitionFilter</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">ImageDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">(),</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">include_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` from image files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; path = &quot;s3://anonymous@ray-example-data/batoidea/JPEGImages/&quot;</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_images(path)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column  Type</span>
<span class="sd">        ------  ----</span>
<span class="sd">        image   numpy.ndarray(shape=(32, 32, 3), dtype=uint8)</span>

<span class="sd">        If you need image file paths, set ``include_paths=True``.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_images(path, include_paths=True)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column  Type</span>
<span class="sd">        ------  ----</span>
<span class="sd">        image   numpy.ndarray(shape=(32, 32, 3), dtype=uint8)</span>
<span class="sd">        path    string</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)[0][&quot;path&quot;]</span>
<span class="sd">        &#39;ray-example-data/batoidea/JPEGImages/1.jpeg&#39;</span>

<span class="sd">        If your images are arranged like:</span>

<span class="sd">        .. code::</span>

<span class="sd">            root/dog/xxx.png</span>
<span class="sd">            root/dog/xxy.png</span>

<span class="sd">            root/cat/123.png</span>
<span class="sd">            root/cat/nsdf3.png</span>

<span class="sd">        Then you can include the labels by specifying a</span>
<span class="sd">        :class:`~ray.data.datasource.partitioning.Partitioning`.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from ray.data.datasource.partitioning import Partitioning</span>
<span class="sd">        &gt;&gt;&gt; root = &quot;s3://anonymous@ray-example-data/image-datasets/dir-partitioned&quot;</span>
<span class="sd">        &gt;&gt;&gt; partitioning = Partitioning(&quot;dir&quot;, field_names=[&quot;class&quot;], base_dir=root)</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_images(root, size=(224, 224), partitioning=partitioning)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column  Type</span>
<span class="sd">        ------  ----</span>
<span class="sd">        image   numpy.ndarray(shape=(224, 224, 3), dtype=uint8)</span>
<span class="sd">        class   string</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file or directory, or a list of file or directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The pyarrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are specified in the</span>
<span class="sd">            `pyarrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">            filesystems.html#filesystem-implementations&gt;`_. Specify this parameter if</span>
<span class="sd">            you need to provide specific configurations to the filesystem. By default,</span>
<span class="sd">            the filesystem is automatically selected based on the scheme of the paths.</span>
<span class="sd">            For example, if the path begins with ``s3://``, the `S3FileSystem` is used.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`. Parallelism is upper bounded by the total number of</span>
<span class="sd">            records in all the CSV files.</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases, you do not need to set this. If ``None``, this</span>
<span class="sd">            function uses a system-chosen implementation.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>
<span class="sd">        arrow_open_file_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_file &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                    #pyarrow.fs.FileSystem.open_input_file&gt;`_.</span>
<span class="sd">            when opening input files to read.</span>
<span class="sd">        partition_filter:  A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`. Use</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match ``*.png``, ``*.jpg``, ``*.jpeg``, ``*.tiff``, ``*.bmp``, or ``*.gif``.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        size: The desired height and width of loaded images. If unspecified, images</span>
<span class="sd">            retain their original shape.</span>
<span class="sd">        mode: A `Pillow mode &lt;https://pillow.readthedocs.io/en/stable/handbook/concepts\</span>
<span class="sd">            .html#modes&gt;`_</span>
<span class="sd">            describing the desired type and depth of pixels. If unspecified, image</span>
<span class="sd">            modes are inferred by</span>
<span class="sd">            `Pillow &lt;https://pillow.readthedocs.io/en/stable/index.html&gt;`_.</span>
<span class="sd">        include_paths: If ``True``, include the path to each image. File paths are</span>
<span class="sd">            stored in the ``&#39;path&#39;`` column.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file/directory paths in ``paths``</span>
<span class="sd">            that are not found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` producing tensors that represent the images at</span>
<span class="sd">        the specified paths. For information on working with tensors, read the</span>
<span class="sd">        :ref:`tensor data guide &lt;working_with_tensors&gt;`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if ``size`` contains non-positive numbers.</span>
<span class="sd">        ValueError: if ``mode`` is unsupported.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_image_metadata_provider</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">ImageDatasource</span><span class="p">(),</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_file_args</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
        <span class="n">include_paths</span><span class="o">=</span><span class="n">include_paths</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_parquet_bulk"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_parquet_bulk.html#ray.data.read_parquet_bulk">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_parquet_bulk</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_file_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tensor_column_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">ParquetBaseDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">()</span>
    <span class="p">),</span>
    <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create :class:`~ray.data.Dataset` from parquet files without reading metadata.</span>

<span class="sd">    Use :meth:`~ray.data.read_parquet` for most cases.</span>

<span class="sd">    Use :meth:`~ray.data.read_parquet_bulk` if all the provided paths point to files</span>
<span class="sd">    and metadata fetching using :meth:`~ray.data.read_parquet` takes too long or the</span>
<span class="sd">    parquet files do not all have a unified schema.</span>

<span class="sd">    Performance slowdowns are possible when using this method with parquet files that</span>
<span class="sd">    are very large.</span>

<span class="sd">    .. warning::</span>

<span class="sd">        Only provide file paths as input (i.e., no directory paths). An</span>
<span class="sd">        OSError is raised if one or more paths point to directories. If your</span>
<span class="sd">        use-case requires directory paths, use :meth:`~ray.data.read_parquet`</span>
<span class="sd">        instead.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Read multiple local files. You should always provide only input file paths</span>
<span class="sd">        (i.e. no directory paths) when known to minimize read latency.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_parquet_bulk( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;])</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file path or a list of file paths.</span>
<span class="sd">        filesystem: The PyArrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are</span>
<span class="sd">            specified in the</span>
<span class="sd">            `PyArrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">                filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">            Specify this parameter if you need to provide specific configurations to</span>
<span class="sd">            the filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">            on the scheme of the paths. For example, if the path begins with ``s3://``,</span>
<span class="sd">            the `S3FileSystem` is used.</span>
<span class="sd">        columns: A list of column names to read. Only the</span>
<span class="sd">            specified columns are read during the file scan.</span>
<span class="sd">        parallelism: The amount of parallelism to use for</span>
<span class="sd">            the dataset. Defaults to -1, which automatically determines the optimal</span>
<span class="sd">            parallelism for your configuration. You should not need to manually set</span>
<span class="sd">            this value in most cases. For details on how the parallelism is</span>
<span class="sd">            automatically determined and guidance on how to tune it, see</span>
<span class="sd">            :ref:`Tuning read parallelism &lt;read_parallelism&gt;`. Parallelism is</span>
<span class="sd">            upper bounded by the total number of records in all the parquet files.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>
<span class="sd">        arrow_open_file_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_file &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                    #pyarrow.fs.FileSystem.open_input_file&gt;`_.</span>
<span class="sd">            when opening input files to read.</span>
<span class="sd">        tensor_column_schema: A dict of column name to PyArrow dtype and shape</span>
<span class="sd">            mappings for converting a Parquet column containing serialized</span>
<span class="sd">            tensors (ndarrays) as their elements to PyArrow tensors. This function</span>
<span class="sd">            assumes that the tensors are serialized in the raw</span>
<span class="sd">            NumPy array format in C-contiguous order (e.g. via</span>
<span class="sd">            `arr.tobytes()`).</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases, you do not need to set this. If ``None``, this</span>
<span class="sd">            function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`. Use</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match &quot;*.parquet*&quot;.</span>
<span class="sd">        arrow_parquet_args: Other parquet read options to pass to PyArrow. For the full</span>
<span class="sd">            set of arguments, see</span>
<span class="sd">            the `PyArrow API &lt;https://arrow.apache.org/docs/python/generated/\</span>
<span class="sd">                pyarrow.dataset.Scanner.html#pyarrow.dataset.Scanner.from_fragment&gt;`_</span>

<span class="sd">    Returns:</span>
<span class="sd">       :class:`~ray.data.Dataset` producing records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_parquet_bulk_metadata_provider</span><span class="p">()</span>
    <span class="n">arrow_parquet_args</span> <span class="o">=</span> <span class="n">_resolve_parquet_args</span><span class="p">(</span>
        <span class="n">tensor_column_schema</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">ParquetBaseDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_file_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_json"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_json.html#ray.data.read_json">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_json</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">PathPartitionFilter</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">JSONDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">(),</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="n">Partitioning</span><span class="p">(</span><span class="s2">&quot;hive&quot;</span><span class="p">),</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">arrow_json_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` from JSON and JSONL files.</span>

<span class="sd">    For JSON file, the whole file is read as one row.</span>
<span class="sd">    For JSONL file, each line of file is read as separate row.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Read a JSON file in remote storage.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_json(&quot;s3://anonymous@ray-example-data/log.json&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column     Type</span>
<span class="sd">        ------     ----</span>
<span class="sd">        timestamp  timestamp[s]</span>
<span class="sd">        size       int64</span>

<span class="sd">        Read a JSONL file in remote storage.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_json(&quot;s3://anonymous@ray-example-data/train.jsonl&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column  Type</span>
<span class="sd">        ------  ----</span>
<span class="sd">        input   string</span>

<span class="sd">        Read multiple local files.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_json( # doctest: +SKIP</span>
<span class="sd">        ...    [&quot;local:///path/to/file1&quot;, &quot;local:///path/to/file2&quot;])</span>

<span class="sd">        Read multiple directories.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_json( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;s3://bucket/path1&quot;, &quot;s3://bucket/path2&quot;])</span>

<span class="sd">        By default, :meth:`~ray.data.read_json` parses</span>
<span class="sd">        `Hive-style partitions &lt;https://athena.guide/articles/\</span>
<span class="sd">        hive-style-partitioning/&gt;`_</span>
<span class="sd">        from file paths. If your data adheres to a different partitioning scheme, set</span>
<span class="sd">        the ``partitioning`` parameter.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_json(&quot;s3://anonymous@ray-example-data/year=2022/month=09/sales.json&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)</span>
<span class="sd">        [{&#39;order_number&#39;: 10107, &#39;quantity&#39;: 30, &#39;year&#39;: &#39;2022&#39;, &#39;month&#39;: &#39;09&#39;}]</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file or directory, or a list of file or directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The PyArrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are specified in the</span>
<span class="sd">            `PyArrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">            filesystems.html#filesystem-implementations&gt;`_. Specify this parameter if</span>
<span class="sd">            you need to provide specific configurations to the filesystem. By default,</span>
<span class="sd">            the filesystem is automatically selected based on the scheme of the paths.</span>
<span class="sd">            For example, if the path begins with ``s3://``, the `S3FileSystem` is used.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`. Parallelism is upper bounded by the total number of</span>
<span class="sd">            records in all the JSON files.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_file &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                    #pyarrow.fs.FileSystem.open_input_stream&gt;`_.</span>
<span class="sd">            when opening input files to read.</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases, you do not need to set this. If ``None``, this</span>
<span class="sd">            function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`.</span>
<span class="sd">            Use with a custom callback to read only selected partitions of a</span>
<span class="sd">            dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match &quot;*.json&quot; or &quot;*.jsonl&quot;.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. By default, this function parses</span>
<span class="sd">            `Hive-style partitions &lt;https://athena.guide/articles/\</span>
<span class="sd">                hive-style-partitioning/&gt;`_.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>
<span class="sd">        arrow_json_args: JSON read options to pass to `pyarrow.json.read_json &lt;https://\</span>
<span class="sd">            arrow.apache.org/docs/python/generated/pyarrow.json.read_json.html#pyarrow.\</span>
<span class="sd">            json.read_json&gt;`_.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` producing records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_generic_metadata_provider</span><span class="p">(</span><span class="n">JSONDatasource</span><span class="o">.</span><span class="n">_FILE_EXTENSION</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">JSONDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_json_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_csv"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_csv.html#ray.data.read_csv">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_csv</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="n">Partitioning</span><span class="p">(</span><span class="s2">&quot;hive&quot;</span><span class="p">),</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` from CSV files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Read a file in remote storage.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column             Type</span>
<span class="sd">        ------             ----</span>
<span class="sd">        sepal length (cm)  double</span>
<span class="sd">        sepal width (cm)   double</span>
<span class="sd">        petal length (cm)  double</span>
<span class="sd">        petal width (cm)   double</span>
<span class="sd">        target             int64</span>

<span class="sd">        Read multiple local files.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_csv( # doctest: +SKIP</span>
<span class="sd">        ...    [&quot;local:///path/to/file1&quot;, &quot;local:///path/to/file2&quot;])</span>

<span class="sd">        Read a directory from remote storage.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris-csv/&quot;)</span>

<span class="sd">        Read files that use a different delimiter. For more uses of ParseOptions see</span>
<span class="sd">        https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html  # noqa: #501</span>

<span class="sd">        &gt;&gt;&gt; from pyarrow import csv</span>
<span class="sd">        &gt;&gt;&gt; parse_options = csv.ParseOptions(delimiter=&quot;\\t&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_csv(</span>
<span class="sd">        ...     &quot;s3://anonymous@ray-example-data/iris.tsv&quot;,</span>
<span class="sd">        ...     parse_options=parse_options)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column        Type</span>
<span class="sd">        ------        ----</span>
<span class="sd">        sepal.length  double</span>
<span class="sd">        sepal.width   double</span>
<span class="sd">        petal.length  double</span>
<span class="sd">        petal.width   double</span>
<span class="sd">        variety       string</span>

<span class="sd">        Convert a date column with a custom format from a CSV file. For more uses of ConvertOptions see https://arrow.apache.org/docs/python/generated/pyarrow.csv.ConvertOptions.html  # noqa: #501</span>

<span class="sd">        &gt;&gt;&gt; from pyarrow import csv</span>
<span class="sd">        &gt;&gt;&gt; convert_options = csv.ConvertOptions(</span>
<span class="sd">        ...     timestamp_parsers=[&quot;%m/%d/%Y&quot;])</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_csv(</span>
<span class="sd">        ...     &quot;s3://anonymous@ray-example-data/dow_jones.csv&quot;,</span>
<span class="sd">        ...     convert_options=convert_options)</span>

<span class="sd">        By default, :meth:`~ray.data.read_csv` parses</span>
<span class="sd">        `Hive-style partitions &lt;https://athena.guide/\</span>
<span class="sd">        articles/hive-style-partitioning/&gt;`_</span>
<span class="sd">        from file paths. If your data adheres to a different partitioning scheme, set</span>
<span class="sd">        the ``partitioning`` parameter.</span>

<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/year=2022/month=09/sales.csv&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)</span>
<span class="sd">        [{&#39;order_number&#39;: 10107, &#39;quantity&#39;: 30, &#39;year&#39;: &#39;2022&#39;, &#39;month&#39;: &#39;09&#39;}]</span>

<span class="sd">        By default, :meth:`~ray.data.read_csv` reads all files from file paths. If you want to filter</span>
<span class="sd">        files by file extensions, set the ``partition_filter`` parameter.</span>

<span class="sd">        Read only ``*.csv`` files from a directory.</span>

<span class="sd">        &gt;&gt;&gt; from ray.data.datasource import FileExtensionFilter</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_csv(&quot;s3://anonymous@ray-example-data/different-extensions/&quot;,</span>
<span class="sd">        ...     partition_filter=FileExtensionFilter(&quot;csv&quot;))</span>
<span class="sd">        Dataset(num_blocks=..., num_rows=1, schema={a: int64, b: int64})</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file or directory, or a list of file or directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The PyArrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are specified in the</span>
<span class="sd">            `pyarrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">            filesystems.html#filesystem-implementations&gt;`_. Specify this parameter if</span>
<span class="sd">            you need to provide specific configurations to the filesystem. By default,</span>
<span class="sd">            the filesystem is automatically selected based on the scheme of the paths.</span>
<span class="sd">            For example, if the path begins with ``s3://``, the `S3FileSystem` is used.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`. Parallelism is upper bounded by the total number of</span>
<span class="sd">            records in all the CSV files.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_file &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                    #pyarrow.fs.FileSystem.open_input_stream&gt;`_.</span>
<span class="sd">            when opening input files to read.</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases, you do not need to set this. If ``None``, this</span>
<span class="sd">            function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`.</span>
<span class="sd">            Use with a custom callback to read only selected partitions of a</span>
<span class="sd">            dataset. By default, no files are filtered.</span>
<span class="sd">            To filter out all file paths except those whose file extension</span>
<span class="sd">            matches e.g., &quot;*.csv*&quot;, you can provide a</span>
<span class="sd">            :class:`~ray.data.datasource.FileExtensionFilter`.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. By default, this function parses</span>
<span class="sd">            `Hive-style partitions &lt;https://athena.guide/articles/\</span>
<span class="sd">                hive-style-partitioning/&gt;`_.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>
<span class="sd">        arrow_csv_args: CSV read options to pass to</span>
<span class="sd">            `pyarrow.csv.open_csv &lt;https://arrow.apache.org/docs/python/generated/\</span>
<span class="sd">            pyarrow.csv.open_csv.html#pyarrow.csv.open_csv&gt;`_</span>
<span class="sd">            when opening CSV files.</span>


<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` producing records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_generic_metadata_provider</span><span class="p">(</span><span class="n">CSVDatasource</span><span class="o">.</span><span class="n">_FILE_EXTENSION</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">CSVDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_text"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_text.html#ray.data.read_text">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_text</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">encoding</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">,</span>
    <span class="n">drop_empty_lines</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from lines stored in text files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Read a file in remote storage.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_text(&quot;s3://anonymous@ray-example-data/this.txt&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column  Type</span>
<span class="sd">        ------  ----</span>
<span class="sd">        text    string</span>

<span class="sd">        Read multiple local files.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_text( # doctest: +SKIP</span>
<span class="sd">        ...    [&quot;local:///path/to/file1&quot;, &quot;local:///path/to/file2&quot;])</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file or directory, or a list of file or directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        encoding: The encoding of the files (e.g., &quot;utf-8&quot; or &quot;ascii&quot;).</span>
<span class="sd">        filesystem: The PyArrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are specified in the</span>
<span class="sd">            `PyArrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">            filesystems.html#filesystem-implementations&gt;`_. Specify this parameter if</span>
<span class="sd">            you need to provide specific configurations to the filesystem. By default,</span>
<span class="sd">            the filesystem is automatically selected based on the scheme of the paths.</span>
<span class="sd">            For example, if the path begins with ``s3://``, the `S3FileSystem` is used.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`. Parallelism is upper bounded by the total number of</span>
<span class="sd">            lines in all the text files.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks and</span>
<span class="sd">            in the subsequent text decoding map task.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_file &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                    #pyarrow.fs.FileSystem.open_input_stream&gt;`_.</span>
<span class="sd">            when opening input files to read.</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases, you do not need to set this. If ``None``, this</span>
<span class="sd">            function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`.</span>
<span class="sd">            Use with a custom callback to read only selected partitions of a</span>
<span class="sd">            dataset. By default, no files are filtered.</span>
<span class="sd">            To filter out all file paths except those whose file extension</span>
<span class="sd">            matches e.g., &quot;*.txt*&quot;, you can provide a</span>
<span class="sd">            :class:`~ray.data.datasource.FileExtensionFilter`.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` producing lines of text read from the specified</span>
<span class="sd">        paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_generic_metadata_provider</span><span class="p">(</span><span class="n">TextDatasource</span><span class="o">.</span><span class="n">_FILE_EXTENSION</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">TextDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">drop_empty_lines</span><span class="o">=</span><span class="n">drop_empty_lines</span><span class="p">,</span>
        <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_numpy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_numpy.html#ray.data.read_numpy">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_numpy</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">PathPartitionFilter</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">NumpyDatasource</span><span class="o">.</span><span class="n">file_extension_filter</span><span class="p">(),</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">numpy_load_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create an Arrow dataset from numpy files.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Read a directory of files in remote storage.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_numpy(&quot;s3://bucket/path&quot;) # doctest: +SKIP</span>

<span class="sd">        Read multiple local files.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_numpy([&quot;/path/to/file1&quot;, &quot;/path/to/file2&quot;]) # doctest: +SKIP</span>

<span class="sd">        Read multiple directories.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_numpy( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;s3://bucket/path1&quot;, &quot;s3://bucket/path2&quot;])</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files of the dataset.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_stream &lt;https://arrow.apache.org/docs/python/generated/pyarrow.fs.FileSystem.html&gt;`_.</span>
<span class="sd">        numpy_load_args: Other options to pass to np.load.</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately. If</span>
<span class="sd">            ``None``, this function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match &quot;*.npy*&quot;.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset holding Tensor records read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_generic_metadata_provider</span><span class="p">(</span><span class="n">NumpyDatasource</span><span class="o">.</span><span class="n">_FILE_EXTENSION</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">NumpyDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="o">**</span><span class="n">numpy_load_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_tfrecords"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_tfrecords.html#ray.data.read_tfrecords">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_tfrecords</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">tf_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;schema_pb2.Schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from TFRecord files that contain</span>
<span class="sd">    `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/Example&gt;`_</span>
<span class="sd">    messages.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This function exclusively supports ``tf.train.Example`` messages. If a file</span>
<span class="sd">        contains a message that isn&#39;t of type ``tf.train.Example``, then this function</span>
<span class="sd">        fails.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_tfrecords(&quot;s3://anonymous@ray-example-data/iris.tfrecords&quot;)</span>
<span class="sd">        Dataset(</span>
<span class="sd">           num_blocks=...,</span>
<span class="sd">           num_rows=150,</span>
<span class="sd">           schema={...}</span>
<span class="sd">        )</span>

<span class="sd">        We can also read compressed TFRecord files, which use one of the</span>
<span class="sd">        `compression types supported by Arrow &lt;https://arrow.apache.org/docs/python/\</span>
<span class="sd">            generated/pyarrow.CompressedInputStream.html&gt;`_:</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_tfrecords(</span>
<span class="sd">        ...     &quot;s3://anonymous@ray-example-data/iris.tfrecords.gz&quot;,</span>
<span class="sd">        ...     arrow_open_stream_args={&quot;compression&quot;: &quot;gzip&quot;},</span>
<span class="sd">        ... )</span>
<span class="sd">        Dataset(</span>
<span class="sd">           num_blocks=...,</span>
<span class="sd">           num_rows=150,</span>
<span class="sd">           schema={...}</span>
<span class="sd">        )</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file or directory, or a list of file or directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The PyArrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are specified in the</span>
<span class="sd">            `PyArrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">            filesystems.html#filesystem-implementations&gt;`_. Specify this parameter if</span>
<span class="sd">            you need to provide specific configurations to the filesystem. By default,</span>
<span class="sd">            the filesystem is automatically selected based on the scheme of the paths.</span>
<span class="sd">            For example, if the path begins with ``s3://``, the `S3FileSystem` is used.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`. Parallelism is upper bounded by the total number of</span>
<span class="sd">            records in all the CSV files.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_file &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                    #pyarrow.fs.FileSystem.open_input_stream&gt;`_.</span>
<span class="sd">            when opening input files to read. To read a compressed TFRecord file,</span>
<span class="sd">            pass the corresponding compression type (e.g., for ``GZIP`` or ``ZLIB``),</span>
<span class="sd">            use ``arrow_open_stream_args={&#39;compression_type&#39;: &#39;gzip&#39;}``).</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases, you do not need to set this. If ``None``, this</span>
<span class="sd">            function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`.</span>
<span class="sd">            Use with a custom callback to read only selected partitions of a</span>
<span class="sd">            dataset.</span>
<span class="sd">            By default, this filters out any file paths whose file extension does not</span>
<span class="sd">            match ``&quot;*.tfrecords*&quot;``.</span>
<span class="sd">        ignore_missing_paths:  If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>
<span class="sd">        tf_schema: Optional TensorFlow Schema which is used to explicitly set the schema</span>
<span class="sd">            of the underlying Dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` that contains the example features.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If a file contains a message that isn&#39;t a ``tf.train.Example``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_generic_metadata_provider</span><span class="p">(</span>
            <span class="n">TFRecordDatasource</span><span class="o">.</span><span class="n">_FILE_EXTENSION</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">TFRecordDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="n">tf_schema</span><span class="o">=</span><span class="n">tf_schema</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_webdataset"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_webdataset.html#ray.data.read_webdataset">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_webdataset</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">decoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">callable</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">fileselect</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">filerename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">suffixes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose_open</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from</span>
<span class="sd">    `WebDataset &lt;https://webdataset.github.io/webdataset/&gt;`_ files.</span>

<span class="sd">    Args:</span>
<span class="sd">        paths: A single file/directory path or a list of file/directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        filesystem: The filesystem implementation to read from.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Parallelism may be</span>
<span class="sd">            limited by the number of files in the dataset.</span>
<span class="sd">        arrow_open_stream_args: Key-word arguments passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_stream &lt;https://arrow.apache.org/docs/python/generated/pyarrow.fs.FileSystem.html&gt;`_.</span>
<span class="sd">            To read a compressed TFRecord file,</span>
<span class="sd">            pass the corresponding compression type (e.g. for ``GZIP`` or ``ZLIB``, use</span>
<span class="sd">            ``arrow_open_stream_args={&#39;compression_type&#39;: &#39;gzip&#39;}``).</span>
<span class="sd">        meta_provider: File metadata provider. Custom metadata providers may</span>
<span class="sd">            be able to resolve file metadata more quickly and/or accurately. If</span>
<span class="sd">            ``None``, this function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: Path-based partition filter, if any. Can be used</span>
<span class="sd">            with a custom callback to read only selected partitions of a dataset.</span>
<span class="sd">        decoder: A function or list of functions to decode the data.</span>
<span class="sd">        fileselect: A callable or list of glob patterns to select files.</span>
<span class="sd">        filerename: A function or list of tuples to rename files prior to grouping.</span>
<span class="sd">        suffixes: A function or list of suffixes to select for creating samples.</span>
<span class="sd">        verbose_open: Whether to print the file names as they are opened.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` that contains the example features.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If a file contains a message that isn&#39;t a `tf.train.Example`_.</span>

<span class="sd">    .. _tf.train.Example: https://www.tensorflow.org/api_docs/python/tf/train/Example</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_generic_metadata_provider</span><span class="p">(</span>
            <span class="n">WebDatasetDatasource</span><span class="o">.</span><span class="n">_FILE_EXTENSION</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">WebDatasetDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
        <span class="n">fileselect</span><span class="o">=</span><span class="n">fileselect</span><span class="p">,</span>
        <span class="n">filerename</span><span class="o">=</span><span class="n">filerename</span><span class="p">,</span>
        <span class="n">suffixes</span><span class="o">=</span><span class="n">suffixes</span><span class="p">,</span>
        <span class="n">verbose_open</span><span class="o">=</span><span class="n">verbose_open</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_binary_files"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_binary_files.html#ray.data.read_binary_files">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">read_binary_files</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">include_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">meta_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseFileMetadataProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PathPartitionFilter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partitioning</span><span class="p">:</span> <span class="n">Partitioning</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ignore_missing_paths</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from binary files of arbitrary contents.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Read a file in remote storage.</span>

<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; path = &quot;s3://anonymous@ray-example-data/pdf-sample_0.pdf&quot;</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_binary_files(path)</span>
<span class="sd">        &gt;&gt;&gt; ds.schema()</span>
<span class="sd">        Column  Type</span>
<span class="sd">        ------  ----</span>
<span class="sd">        bytes   binary</span>

<span class="sd">        Read multiple local files.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.read_binary_files( # doctest: +SKIP</span>
<span class="sd">        ...     [&quot;local:///path/to/file1&quot;, &quot;local:///path/to/file2&quot;])</span>

<span class="sd">        Read a file with the filepaths included as a column in the dataset.</span>

<span class="sd">        &gt;&gt;&gt; path = &quot;s3://anonymous@ray-example-data/pdf-sample_0.pdf&quot;</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.read_binary_files(path, include_paths=True)</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)[0][&quot;path&quot;]</span>
<span class="sd">        &#39;ray-example-data/pdf-sample_0.pdf&#39;</span>


<span class="sd">    Args:</span>
<span class="sd">        paths: A single file or directory, or a list of file or directory paths.</span>
<span class="sd">            A list of paths can contain both files and directories.</span>
<span class="sd">        include_paths: If ``True``, include the path to each file. File paths are</span>
<span class="sd">            stored in the ``&#39;path&#39;`` column.</span>
<span class="sd">        filesystem: The PyArrow filesystem</span>
<span class="sd">            implementation to read from. These filesystems are specified in the</span>
<span class="sd">            `PyArrow docs &lt;https://arrow.apache.org/docs/python/api/\</span>
<span class="sd">            filesystems.html#filesystem-implementations&gt;`_. Specify this parameter if</span>
<span class="sd">            you need to provide specific configurations to the filesystem. By default,</span>
<span class="sd">            the filesystem is automatically selected based on the scheme of the paths.</span>
<span class="sd">            For example, if the path begins with ``s3://``, the `S3FileSystem` is used.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`. Parallelism is upper bounded by the total number of</span>
<span class="sd">            files.</span>
<span class="sd">        arrow_open_stream_args: kwargs passed to</span>
<span class="sd">            `pyarrow.fs.FileSystem.open_input_file &lt;https://arrow.apache.org/docs/\</span>
<span class="sd">                python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                    #pyarrow.fs.FileSystem.open_input_stream&gt;`_.</span>
<span class="sd">        meta_provider: A :ref:`file metadata provider &lt;metadata_provider&gt;`. Custom</span>
<span class="sd">            metadata providers may be able to resolve file metadata more quickly and/or</span>
<span class="sd">            accurately. In most cases, you do not need to set this. If ``None``, this</span>
<span class="sd">            function uses a system-chosen implementation.</span>
<span class="sd">        partition_filter: A</span>
<span class="sd">            :class:`~ray.data.datasource.partitioning.PathPartitionFilter`.</span>
<span class="sd">            Use with a custom callback to read only selected partitions of a</span>
<span class="sd">            dataset. By default, no files are filtered.</span>
<span class="sd">            By default, this does not filter out any files.</span>
<span class="sd">        partitioning: A :class:`~ray.data.datasource.partitioning.Partitioning` object</span>
<span class="sd">            that describes how paths are organized. Defaults to ``None``.</span>
<span class="sd">        ignore_missing_paths: If True, ignores any file paths in ``paths`` that are not</span>
<span class="sd">            found. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` producing rows read from the specified paths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_arrow_format</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">meta_provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_provider</span> <span class="o">=</span> <span class="n">get_generic_metadata_provider</span><span class="p">(</span><span class="n">BinaryDatasource</span><span class="o">.</span><span class="n">_FILE_EXTENSION</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">BinaryDatasource</span><span class="p">(),</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">include_paths</span><span class="o">=</span><span class="n">include_paths</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="o">=</span><span class="n">meta_provider</span><span class="p">,</span>
        <span class="n">partition_filter</span><span class="o">=</span><span class="n">partition_filter</span><span class="p">,</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">ignore_missing_paths</span><span class="o">=</span><span class="n">ignore_missing_paths</span><span class="p">,</span>
        <span class="n">output_arrow_format</span><span class="o">=</span><span class="n">output_arrow_format</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="read_sql"><a class="viewcode-back" href="../../../data/api/doc/ray.data.read_sql.html#ray.data.read_sql">[docs]</a><span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">read_sql</span><span class="p">(</span>
    <span class="n">sql</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">connection_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Connection</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Read from a database that provides a</span>
<span class="sd">    `Python DB API2-compliant &lt;https://peps.python.org/pep-0249/&gt;`_ connector.</span>

<span class="sd">    .. note::</span>

<span class="sd">        By default, ``read_sql`` launches multiple read tasks, and each task executes a</span>
<span class="sd">        ``LIMIT`` and ``OFFSET`` to fetch a subset of the rows. However, for many</span>
<span class="sd">        databases, ``OFFSET`` is slow.</span>

<span class="sd">        As a workaround, set ``parallelism=1`` to directly fetch all rows in a single</span>
<span class="sd">        task. Note that this approach requires all result rows to fit in the memory of</span>
<span class="sd">        single task. If the rows don&#39;t fit, your program may raise an out of memory</span>
<span class="sd">        error.</span>

<span class="sd">    Examples:</span>

<span class="sd">        For examples of reading from larger databases like MySQL and PostgreSQL, see</span>
<span class="sd">        :ref:`Reading from SQL Databases &lt;reading_sql&gt;`.</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import sqlite3</span>

<span class="sd">            import ray</span>

<span class="sd">            # Create a simple database</span>
<span class="sd">            connection = sqlite3.connect(&quot;example.db&quot;)</span>
<span class="sd">            connection.execute(&quot;CREATE TABLE movie(title, year, score)&quot;)</span>
<span class="sd">            connection.execute(</span>
<span class="sd">                \&quot;\&quot;\&quot;</span>
<span class="sd">                INSERT INTO movie VALUES</span>
<span class="sd">                    (&#39;Monty Python and the Holy Grail&#39;, 1975, 8.2),</span>
<span class="sd">                    (&quot;Monty Python Live at the Hollywood Bowl&quot;, 1982, 7.9),</span>
<span class="sd">                    (&quot;Monty Python&#39;s Life of Brian&quot;, 1979, 8.0),</span>
<span class="sd">                    (&quot;Rocky II&quot;, 1979, 7.3)</span>
<span class="sd">                \&quot;\&quot;\&quot;</span>
<span class="sd">            )</span>
<span class="sd">            connection.commit()</span>
<span class="sd">            connection.close()</span>

<span class="sd">            def create_connection():</span>
<span class="sd">                return sqlite3.connect(&quot;example.db&quot;)</span>

<span class="sd">            # Get all movies</span>
<span class="sd">            ds = ray.data.read_sql(&quot;SELECT * FROM movie&quot;, create_connection)</span>
<span class="sd">            # Get movies after the year 1980</span>
<span class="sd">            ds = ray.data.read_sql(</span>
<span class="sd">                &quot;SELECT title, score FROM movie WHERE year &gt;= 1980&quot;, create_connection</span>
<span class="sd">            )</span>
<span class="sd">            # Get the number of movies per year</span>
<span class="sd">            ds = ray.data.read_sql(</span>
<span class="sd">                &quot;SELECT year, COUNT(*) FROM movie GROUP BY year&quot;, create_connection</span>
<span class="sd">            )</span>

<span class="sd">        .. testcode::</span>
<span class="sd">            :hide:</span>

<span class="sd">            import os</span>
<span class="sd">            os.remove(&quot;example.db&quot;)</span>

<span class="sd">    Args:</span>
<span class="sd">        sql: The SQL query to execute.</span>
<span class="sd">        connection_factory: A function that takes no arguments and returns a</span>
<span class="sd">            Python DB API2</span>
<span class="sd">            `Connection object &lt;https://peps.python.org/pep-0249/#connection-objects&gt;`_.</span>
<span class="sd">        parallelism: The requested parallelism of the read. Defaults to -1,</span>
<span class="sd">            which automatically determines the optimal parallelism for your</span>
<span class="sd">            configuration. You should not need to manually set this value in most cases.</span>
<span class="sd">            For details on how the parallelism is automatically determined and guidance</span>
<span class="sd">            on how to tune it, see :ref:`Tuning read parallelism</span>
<span class="sd">            &lt;read_parallelism&gt;`.</span>
<span class="sd">        ray_remote_args: kwargs passed to :meth:`~ray.remote` in the read tasks.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`Dataset` containing the queried data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">datasource</span> <span class="o">=</span> <span class="n">SQLDatasource</span><span class="p">(</span><span class="n">connection_factory</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
        <span class="n">datasource</span><span class="p">,</span>
        <span class="n">sql</span><span class="o">=</span><span class="n">sql</span><span class="p">,</span>
        <span class="n">parallelism</span><span class="o">=</span><span class="n">parallelism</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_dask"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_dask.html#ray.data.from_dask">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_dask</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="s2">&quot;dask.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a</span>
<span class="sd">    `Dask DataFrame &lt;https://docs.dask.org/en/stable/generated/dask.dataframe.DataFrame.html#dask.dataframe.DataFrame&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: A `Dask DataFrame`_.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.MaterializedDataset` holding rows read from the DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="kn">import</span> <span class="nn">dask</span>

    <span class="kn">from</span> <span class="nn">ray.util.dask</span> <span class="kn">import</span> <span class="n">ray_dask_get</span>

    <span class="n">partitions</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_delayed</span><span class="p">()</span>
    <span class="n">persisted_partitions</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="o">*</span><span class="n">partitions</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">ray_dask_get</span><span class="p">)</span>

    <span class="kn">import</span> <span class="nn">pandas</span>

    <span class="k">def</span> <span class="nf">to_ref</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">df</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected a Ray object ref or a Pandas DataFrame, &quot;</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="n">ds</span> <span class="o">=</span> <span class="n">from_pandas_refs</span><span class="p">(</span>
        <span class="p">[</span><span class="n">to_ref</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">part</span><span class="o">.</span><span class="n">dask</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span> <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">persisted_partitions</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span></div>


<div class="viewcode-block" id="from_mars"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_mars.html#ray.data.from_mars">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_mars</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="s2">&quot;mars.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a</span>
<span class="sd">    `Mars DataFrame &lt;https://mars-project.readthedocs.io/en/latest/reference/dataframe/index.html&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: A `Mars DataFrame`_, which must be executed by Mars-on-Ray.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.MaterializedDataset` holding rows read from the DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="kn">import</span> <span class="nn">mars.dataframe</span> <span class="k">as</span> <span class="nn">md</span>

    <span class="n">ds</span><span class="p">:</span> <span class="n">Dataset</span> <span class="o">=</span> <span class="n">md</span><span class="o">.</span><span class="n">to_ray_dataset</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span></div>


<div class="viewcode-block" id="from_modin"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_modin.html#ray.data.from_modin">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_modin</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="s2">&quot;modin.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a</span>
<span class="sd">    `Modin DataFrame &lt;https://modin.readthedocs.io/en/stable/flow/modin/pandas/dataframe.html&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: A `Modin DataFrame`_, which must be using the Ray backend.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.MaterializedDataset` rows read from the DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="kn">from</span> <span class="nn">modin.distributed.dataframe.pandas.partitions</span> <span class="kn">import</span> <span class="n">unwrap_partitions</span>

    <span class="n">parts</span> <span class="o">=</span> <span class="n">unwrap_partitions</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">from_pandas_refs</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span></div>


<div class="viewcode-block" id="from_pandas"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_pandas.html#ray.data.from_pandas">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_pandas</span><span class="p">(</span>
    <span class="n">dfs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">]]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a list of pandas dataframes.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; df = pd.DataFrame({&quot;a&quot;: [1, 2, 3], &quot;b&quot;: [4, 5, 6]})</span>
<span class="sd">        &gt;&gt;&gt; ray.data.from_pandas(df)</span>
<span class="sd">        MaterializedDataset(num_blocks=1, num_rows=3, schema={a: int64, b: int64})</span>

<span class="sd">       Create a Ray Dataset from a list of Pandas DataFrames.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.from_pandas([df, df])</span>
<span class="sd">        MaterializedDataset(num_blocks=2, num_rows=6, schema={a: int64, b: int64})</span>

<span class="sd">    Args:</span>
<span class="sd">        dfs: A pandas dataframe or a list of pandas dataframes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` holding data read from the dataframes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dfs</span><span class="p">]</span>

    <span class="kn">from</span> <span class="nn">ray.air.util.data_batch_conversion</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">_cast_ndarray_columns_to_tensor_extension</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">enable_tensor_extension_casting</span><span class="p">:</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">_cast_ndarray_columns_to_tensor_extension</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">from_pandas_refs</span><span class="p">([</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">])</span></div>


<div class="viewcode-block" id="from_pandas_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_pandas_refs.html#ray.data.from_pandas_refs">[docs]</a><span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">from_pandas_refs</span><span class="p">(</span>
    <span class="n">dfs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a list of Ray object references to</span>
<span class="sd">    pandas dataframes.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; df_ref = ray.put(pd.DataFrame({&quot;a&quot;: [1, 2, 3], &quot;b&quot;: [4, 5, 6]}))</span>
<span class="sd">        &gt;&gt;&gt; ray.data.from_pandas_refs(df_ref)</span>
<span class="sd">        MaterializedDataset(num_blocks=1, num_rows=3, schema={a: int64, b: int64})</span>

<span class="sd">        Create a Ray Dataset from a list of Pandas Dataframes references.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.from_pandas_refs([df_ref, df_ref])</span>
<span class="sd">        MaterializedDataset(num_blocks=2, num_rows=6, schema={a: int64, b: int64})</span>

<span class="sd">    Args:</span>
<span class="sd">        dfs: A Ray object reference to a pandas dataframe, or a list of</span>
<span class="sd">             Ray object references to pandas dataframes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` holding data read from the dataframes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dfs</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected list of Ray object refs, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got list containing </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Expected Ray object ref or list of Ray object refs, &quot;</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">enable_pandas_block</span><span class="p">:</span>
        <span class="n">get_metadata</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">get_table_block_metadata</span><span class="p">)</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="n">get_metadata</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">])</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromPandas</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span>
                <span class="n">BlockList</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromPandas&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="mi">0</span><span class="p">,</span>
            <span class="kc">True</span><span class="p">,</span>
            <span class="n">logical_plan</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">df_to_block</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">pandas_df_to_arrow_block</span><span class="p">,</span> <span class="n">num_returns</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">df_to_block</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="p">]</span>
    <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">))</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromPandas</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromPandas&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_numpy"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_numpy.html#ray.data.from_numpy">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_numpy</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` from a list of NumPy ndarrays.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; arr = np.array([1])</span>
<span class="sd">        &gt;&gt;&gt; ray.data.from_numpy(arr)</span>
<span class="sd">        MaterializedDataset(num_blocks=1, num_rows=1, schema={data: int64})</span>

<span class="sd">        Create a Ray Dataset from a list of NumPy arrays.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.from_numpy([arr, arr])</span>
<span class="sd">        MaterializedDataset(num_blocks=2, num_rows=2, schema={data: int64})</span>

<span class="sd">    Args:</span>
<span class="sd">        ndarrays: A NumPy ndarray or a list of NumPy ndarrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` holding data from the given ndarrays.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">ndarrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">ndarrays</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">from_numpy_refs</span><span class="p">([</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">ndarray</span> <span class="ow">in</span> <span class="n">ndarrays</span><span class="p">])</span></div>


<div class="viewcode-block" id="from_numpy_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_numpy_refs.html#ray.data.from_numpy_refs">[docs]</a><span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">from_numpy_refs</span><span class="p">(</span>
    <span class="n">ndarrays</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a :class:`~ray.data.Dataset` from a list of Ray object references to</span>
<span class="sd">    NumPy ndarrays.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; arr_ref = ray.put(np.array([1]))</span>
<span class="sd">        &gt;&gt;&gt; ray.data.from_numpy_refs(arr_ref)</span>
<span class="sd">        MaterializedDataset(num_blocks=1, num_rows=1, schema={data: int64})</span>

<span class="sd">        Create a Ray Dataset from a list of NumPy array references.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.from_numpy_refs([arr_ref, arr_ref])</span>
<span class="sd">        MaterializedDataset(num_blocks=2, num_rows=2, schema={data: int64})</span>

<span class="sd">    Args:</span>
<span class="sd">        ndarrays: A Ray object reference to a NumPy ndarray or a list of Ray object</span>
<span class="sd">            references to NumPy ndarrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` holding data from the given ndarrays.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
        <span class="n">ndarrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">ndarrays</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarrays</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ndarray</span> <span class="ow">in</span> <span class="n">ndarrays</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected list of Ray object refs, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got list containing </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Expected Ray object ref or list of Ray object refs, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="n">ndarray_to_block_remote</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">ndarray_to_block</span><span class="p">,</span> <span class="n">num_returns</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">ndarray_to_block_remote</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span> <span class="k">for</span> <span class="n">ndarray</span> <span class="ow">in</span> <span class="n">ndarrays</span><span class="p">]</span>
    <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">))</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span>

    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromNumpy</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromNumpy&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_arrow"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_arrow.html#ray.data.from_arrow">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_arrow</span><span class="p">(</span>
    <span class="n">tables</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a list of PyArrow tables.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import pyarrow as pa</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; table = pa.table({&quot;x&quot;: [1]})</span>
<span class="sd">        &gt;&gt;&gt; ray.data.from_arrow(table)</span>
<span class="sd">        MaterializedDataset(num_blocks=1, num_rows=1, schema={x: int64})</span>

<span class="sd">        Create a Ray Dataset from a list of PyArrow tables.</span>

<span class="sd">        &gt;&gt;&gt; ray.data.from_arrow([table, table])</span>
<span class="sd">        MaterializedDataset(num_blocks=2, num_rows=2, schema={x: int64})</span>


<span class="sd">    Args:</span>
<span class="sd">        tables: A PyArrow table, or a list of PyArrow tables,</span>
<span class="sd">                or its streaming format in bytes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`~ray.data.Dataset` holding data from the PyArrow tables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">)):</span>
        <span class="n">tables</span> <span class="o">=</span> <span class="p">[</span><span class="n">tables</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">from_arrow_refs</span><span class="p">([</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">])</span></div>


<div class="viewcode-block" id="from_arrow_refs"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_arrow_refs.html#ray.data.from_arrow_refs">[docs]</a><span class="nd">@DeveloperAPI</span>
<span class="k">def</span> <span class="nf">from_arrow_refs</span><span class="p">(</span>
    <span class="n">tables</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">ObjectRef</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]],</span>
        <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]],</span>
    <span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a list of Ray object references to</span>
<span class="sd">    PyArrow tables.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import pyarrow as pa</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; table_ref = ray.put(pa.table({&quot;x&quot;: [1]}))</span>
<span class="sd">        &gt;&gt;&gt; ray.data.from_arrow_refs(table_ref)</span>
<span class="sd">        MaterializedDataset(num_blocks=1, num_rows=1, schema={x: int64})</span>

<span class="sd">        Create a Ray Dataset from a list of PyArrow table references</span>

<span class="sd">        &gt;&gt;&gt; ray.data.from_arrow_refs([table_ref, table_ref])</span>
<span class="sd">        MaterializedDataset(num_blocks=2, num_rows=2, schema={x: int64})</span>


<span class="sd">    Args:</span>
<span class="sd">        tables: A Ray object reference to Arrow table, or list of Ray object</span>
<span class="sd">                references to Arrow tables, or its streaming format in bytes.</span>

<span class="sd">    Returns:</span>
<span class="sd">         :class:`~ray.data.Dataset` holding data read from the tables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
        <span class="n">tables</span> <span class="o">=</span> <span class="p">[</span><span class="n">tables</span><span class="p">]</span>

    <span class="n">get_metadata</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">get_table_block_metadata</span><span class="p">)</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">([</span><span class="n">get_metadata</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">])</span>
    <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">FromArrow</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
        <span class="n">ExecutionPlan</span><span class="p">(</span>
            <span class="n">BlockList</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">DatasetStats</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;FromArrow&quot;</span><span class="p">:</span> <span class="n">metadata</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">run_by_consumer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_spark"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_spark.html#ray.data.from_spark">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_spark</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="s2">&quot;pyspark.sql.DataFrame&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a</span>
<span class="sd">    `Spark DataFrame &lt;https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: A `Spark DataFrame`_, which must be created by RayDP (Spark-on-Ray).</span>
<span class="sd">        parallelism: The amount of parallelism to use for the dataset. If</span>
<span class="sd">            not provided, the parallelism is equal to the number of partitions of</span>
<span class="sd">            the original Spark DataFrame.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.MaterializedDataset` holding rows read from the DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="kn">import</span> <span class="nn">raydp</span>

    <span class="k">return</span> <span class="n">raydp</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">spark_dataframe_to_ray_dataset</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">)</span></div>


<div class="viewcode-block" id="from_huggingface"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_huggingface.html#ray.data.from_huggingface">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_huggingface</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;datasets.Dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;datasets.IterableDataset&quot;</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">MaterializedDataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.MaterializedDataset` from a</span>
<span class="sd">    `Hugging Face Datasets Dataset &lt;https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset/&gt;`_</span>
<span class="sd">    or a :class:`~ray.data.Dataset` from a `Hugging Face Datasets IterableDataset &lt;https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.IterableDataset/&gt;`_.</span>
<span class="sd">    For an `IterableDataset`, we use a streaming implementation to read data.</span>

<span class="sd">    Example:</span>

<span class="sd">        ..</span>
<span class="sd">            The following `testoutput` is mocked to avoid illustrating download</span>
<span class="sd">            logs like &quot;Downloading and preparing dataset 162.17 MiB&quot;.</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import ray</span>
<span class="sd">            import datasets</span>

<span class="sd">            hf_dataset = datasets.load_dataset(&quot;tweet_eval&quot;, &quot;emotion&quot;)</span>
<span class="sd">            ray_ds = ray.data.from_huggingface(hf_dataset[&quot;train&quot;])</span>
<span class="sd">            print(ray_ds)</span>

<span class="sd">            hf_dataset_stream = datasets.load_dataset(&quot;tweet_eval&quot;, &quot;emotion&quot;, streaming=True)</span>
<span class="sd">            ray_ds_stream = ray.data.from_huggingface(hf_dataset_stream[&quot;train&quot;])</span>
<span class="sd">            print(ray_ds_stream)</span>

<span class="sd">        .. testoutput::</span>
<span class="sd">            :options: +MOCK</span>

<span class="sd">            MaterializedDataset(</span>
<span class="sd">                num_blocks=...,</span>
<span class="sd">                num_rows=3257,</span>
<span class="sd">                schema={text: string, label: int64}</span>
<span class="sd">            )</span>
<span class="sd">            Dataset(</span>
<span class="sd">                num_blocks=...,</span>
<span class="sd">                num_rows=3257,</span>
<span class="sd">                schema={text: string, label: int64}</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: A `Hugging Face Datasets Dataset`_ or `Hugging Face Datasets IterableDataset`_.</span>
<span class="sd">            `DatasetDict &lt;https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.DatasetDict/&gt;`_</span>
<span class="sd">            and `IterableDatasetDict &lt;https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.IterableDatasetDict/&gt;`_</span>
<span class="sd">            are not supported.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`~ray.data.Dataset` holding rows from the `Hugging Face Datasets Dataset`_.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="kn">import</span> <span class="nn">datasets</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IterableDataset</span><span class="p">):</span>
        <span class="c1"># HuggingFaceDatasource should not be imported at top level, because</span>
        <span class="c1"># we only want the Hugging Face datasets package to be imported</span>
        <span class="c1"># if Hugging Face Datasets are used.</span>
        <span class="kn">from</span> <span class="nn">ray.data.datasource.huggingface_datasource</span> <span class="kn">import</span> <span class="n">HuggingFaceDatasource</span>

        <span class="c1"># For an IterableDataset, we can use a streaming implementation to read data.</span>
        <span class="k">return</span> <span class="n">read_datasource</span><span class="p">(</span>
            <span class="n">HuggingFaceDatasource</span><span class="p">(),</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="c1"># To get the resulting Arrow table from a Hugging Face Dataset after</span>
        <span class="c1"># applying transformations (e.g., train_test_split(), shard(), select()),</span>
        <span class="c1"># we create a copy of the Arrow table, which applies the indices</span>
        <span class="c1"># mapping from the transformations.</span>
        <span class="n">hf_ds_arrow</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)</span>
        <span class="n">ray_ds</span> <span class="o">=</span> <span class="n">from_arrow</span><span class="p">(</span><span class="n">hf_ds_arrow</span><span class="p">[:])</span>
        <span class="k">return</span> <span class="n">ray_ds</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">(</span><span class="n">datasets</span><span class="o">.</span><span class="n">DatasetDict</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IterableDatasetDict</span><span class="p">)):</span>
        <span class="n">available_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">raise</span> <span class="ne">DeprecationWarning</span><span class="p">(</span>
            <span class="s2">&quot;You provided a Hugging Face DatasetDict or IterableDatasetDict, &quot;</span>
            <span class="s2">&quot;which contains multiple datasets, but `from_huggingface` now &quot;</span>
            <span class="s2">&quot;only accepts a single Hugging Face Dataset. To convert just &quot;</span>
            <span class="s2">&quot;a single Hugging Face Dataset to a Ray Dataset, specify a split. &quot;</span>
            <span class="s2">&quot;For example, `ray.data.from_huggingface(my_dataset_dictionary&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;[&#39;</span><span class="si">{</span><span class="n">available_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;])`. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Available splits are </span><span class="si">{</span><span class="n">available_keys</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`dataset` must be a `datasets.Dataset`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="from_tf"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_tf.html#ray.data.from_tf">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_tf</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="s2">&quot;tf.data.Dataset&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a</span>
<span class="sd">    `TensorFlow Dataset &lt;https://www.tensorflow.org/api_docs/python/tf/data/Dataset/&gt;`_.</span>

<span class="sd">    This function is inefficient. Use it to read small datasets or prototype.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        If your dataset is large, this function may execute slowly or raise an</span>
<span class="sd">        out-of-memory error. To avoid issues, read the underyling data with a function</span>
<span class="sd">        like :meth:`~ray.data.read_images`.</span>

<span class="sd">    .. note::</span>
<span class="sd">        This function isn&#39;t parallelized. It loads the entire dataset into the local</span>
<span class="sd">        node&#39;s memory before moving the data to the distributed object store.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; import tensorflow_datasets as tfds</span>
<span class="sd">        &gt;&gt;&gt; dataset, _ = tfds.load(&#39;cifar10&#39;, split=[&quot;train&quot;, &quot;test&quot;])  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.from_tf(dataset)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">        MaterializedDataset(</span>
<span class="sd">            num_blocks=...,</span>
<span class="sd">            num_rows=50000,</span>
<span class="sd">            schema={</span>
<span class="sd">                id: binary,</span>
<span class="sd">                image: numpy.ndarray(shape=(32, 32, 3), dtype=uint8),</span>
<span class="sd">                label: int64</span>
<span class="sd">            }</span>
<span class="sd">        )</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)  # doctest: +SKIP</span>
<span class="sd">        [{&#39;id&#39;: b&#39;train_16399&#39;, &#39;image&#39;: array([[[143,  96,  70],</span>
<span class="sd">        [141,  96,  72],</span>
<span class="sd">        [135,  93,  72],</span>
<span class="sd">        ...,</span>
<span class="sd">        [ 96,  37,  19],</span>
<span class="sd">        [105,  42,  18],</span>
<span class="sd">        [104,  38,  20]],</span>
<span class="sd">        ...,</span>
<span class="sd">        [[195, 161, 126],</span>
<span class="sd">        [187, 153, 123],</span>
<span class="sd">        [186, 151, 128],</span>
<span class="sd">        ...,</span>
<span class="sd">        [212, 177, 147],</span>
<span class="sd">        [219, 185, 155],</span>
<span class="sd">        [221, 187, 157]]], dtype=uint8), &#39;label&#39;: 7}]</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: A `TensorFlow Dataset`_.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`MaterializedDataset` that contains the samples stored in the `TensorFlow Dataset`_.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="c1"># FIXME: `as_numpy_iterator` errors if `dataset` contains ragged tensors.</span>
    <span class="k">return</span> <span class="n">from_items</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">()))</span></div>


<div class="viewcode-block" id="from_torch"><a class="viewcode-back" href="../../../data/api/doc/ray.data.from_torch.html#ray.data.from_torch">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">def</span> <span class="nf">from_torch</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="s2">&quot;torch.utils.data.Dataset&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaterializedDataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a :class:`~ray.data.Dataset` from a</span>
<span class="sd">    `Torch Dataset &lt;https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset/&gt;`_.</span>

<span class="sd">    This function is inefficient. Use it to read small datasets or prototype.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        If your dataset is large, this function may execute slowly or raise an</span>
<span class="sd">        out-of-memory error. To avoid issues, read the underyling data with a function</span>
<span class="sd">        like :meth:`~ray.data.read_images`.</span>

<span class="sd">    .. note::</span>
<span class="sd">        This function isn&#39;t parallelized. It loads the entire dataset into the head</span>
<span class="sd">        node&#39;s memory before moving the data to the distributed object store.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from torchvision import datasets</span>
<span class="sd">        &gt;&gt;&gt; dataset = datasets.MNIST(&quot;data&quot;, download=True)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.from_torch(dataset)  # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ds  # doctest: +SKIP</span>
<span class="sd">        MaterializedDataset(num_blocks=..., num_rows=60000, schema={item: object})</span>
<span class="sd">        &gt;&gt;&gt; ds.take(1)  # doctest: +SKIP</span>
<span class="sd">        {&quot;item&quot;: (&lt;PIL.Image.Image image mode=L size=28x28 at 0x...&gt;, 5)}</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: A `Torch Dataset`_.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A :class:`MaterializedDataset` containing the Torch dataset samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">return</span> <span class="n">from_items</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span></div>


<span class="k">def</span> <span class="nf">_get_reader</span><span class="p">(</span>
    <span class="n">ds</span><span class="p">:</span> <span class="n">Datasource</span><span class="p">,</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="n">DataContext</span><span class="p">,</span>
    <span class="n">cur_pg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PlacementGroup</span><span class="p">],</span>
    <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">local_uri</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Reader</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Generates reader.</span>

<span class="sd">    Args:</span>
<span class="sd">        ds: Datasource to read from.</span>
<span class="sd">        ctx: Dataset config to use.</span>
<span class="sd">        cur_pg: The current placement group, if any.</span>
<span class="sd">        parallelism: The user-requested parallelism, or -1 for autodetection.</span>
<span class="sd">        kwargs: Additional kwargs to pass to the reader.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Request parallelism from the datasource, the min safe parallelism to avoid</span>
<span class="sd">        OOM, the estimated inmemory data size, and the reader generated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">_unwrap_arrow_serialization_workaround</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="c1"># NOTE: `ParquetDatasource` has separate steps to fetch metadata and sample rows,</span>
    <span class="c1"># so it needs `local_uri` parameter for now.</span>
    <span class="c1"># TODO(chengsu): stop passing `local_uri` parameter to</span>
    <span class="c1"># `ParquetDatasource.create_reader()`.</span>
    <span class="k">if</span> <span class="n">local_uri</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">ParquetDatasource</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;local_uri&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_uri</span>
    <span class="n">DataContext</span><span class="o">.</span><span class="n">_set_current</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">create_reader</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">requested_parallelism</span><span class="p">,</span> <span class="n">min_safe_parallelism</span><span class="p">,</span> <span class="n">mem_size</span> <span class="o">=</span> <span class="n">_autodetect_parallelism</span><span class="p">(</span>
        <span class="n">parallelism</span><span class="p">,</span> <span class="n">cur_pg</span><span class="p">,</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">(),</span> <span class="n">reader</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">requested_parallelism</span><span class="p">,</span>
        <span class="n">min_safe_parallelism</span><span class="p">,</span>
        <span class="n">mem_size</span><span class="p">,</span>
        <span class="n">reader</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_resolve_parquet_args</span><span class="p">(</span>
    <span class="n">tensor_column_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">tensor_column_schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">existing_block_udf</span> <span class="o">=</span> <span class="n">arrow_parquet_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_block_udf&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_block_udf</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorArray</span>

            <span class="k">for</span> <span class="n">tensor_col_name</span><span class="p">,</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tensor_column_schema</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># NOTE(Clark): We use NumPy to consolidate these potentially</span>
                <span class="c1"># non-contiguous buffers, and to do buffer bookkeeping in</span>
                <span class="c1"># general.</span>
                <span class="n">np_col</span> <span class="o">=</span> <span class="n">_create_possibly_ragged_ndarray</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">buffer</span><span class="o">=</span><span class="n">buf</span><span class="o">.</span><span class="n">as_buffer</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="n">tensor_col_name</span><span class="p">)</span>
                    <span class="p">]</span>
                <span class="p">)</span>

                <span class="n">block</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">set_column</span><span class="p">(</span>
                    <span class="n">block</span><span class="o">.</span><span class="n">_ensure_integer_index</span><span class="p">(</span><span class="n">tensor_col_name</span><span class="p">),</span>
                    <span class="n">tensor_col_name</span><span class="p">,</span>
                    <span class="n">ArrowTensorArray</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_col</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">existing_block_udf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Apply UDF after casting the tensor columns.</span>
                <span class="n">block</span> <span class="o">=</span> <span class="n">existing_block_udf</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">block</span>

        <span class="n">arrow_parquet_args</span><span class="p">[</span><span class="s2">&quot;_block_udf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_block_udf</span>
    <span class="k">return</span> <span class="n">arrow_parquet_args</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>谢谢你的反馈！</span>
  </div>
  <div id="csat-inputs">
    <span>是否能帮助到你？</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>是<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>否<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">反馈</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">提交</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2024, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>