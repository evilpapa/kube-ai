
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>TensorFlow 和 Keras 入门 &#8212; Ray 2.7.2</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/versionwarning.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../_static/js/docsearch.js"></script>
    <script defer="defer" src="../_static/js/csat.js"></script>
    <script defer="defer" src="../_static/js/termynal.js"></script>
    <script defer="defer" src="../_static/js/custom.js"></script>
    <script defer="defer" src="../_static/js/top-navigation.js"></script>
    <script src="../_static/js/tags.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/train/distributed-tensorflow-keras.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="开始使用 XGBoost 和 LightGBM" href="distributed-xgboost-lightgbm.html" />
    <link rel="prev" title="DeepSpeed 入门" href="deepspeed.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
  data-modal-disclaimer = "Results are automated and may be incorrect or contain inappropriate information. Do not include any personal data or confidential information."
  data-modal-title = "Ray Docs AI - Ask a Question"
  data-button-position-bottom = "60px"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 2.7.2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    欢迎来到 Ray ！
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/index.html">
   概述「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/getting-started.html">
   入门
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/installation.html">
   安装「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/use-cases.html">
   用例「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/examples.html">
   示例库「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/ray-libraries.html">
   生态「3%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/walkthrough.html">
   Ray 核心「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data/data.html">
   Ray 数据「75%」
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="train.html">
   Ray 训练「0%」
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="overview.html">
     概述
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-pytorch.html">
     PyTorch 指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-pytorch-lightning.html">
     PyTorch Lightning 指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-transformers.html">
     Hugging Face Transformers 指南
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="more-frameworks.html">
     更多框架
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="huggingface-accelerate.html">
       Hugging Face Accelerate 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="deepspeed.html">
       DeepSpeed 指南
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       TensorFlow and Keras 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="distributed-xgboost-lightgbm.html">
       XGBoost and LightGBM 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="horovod.html">
       Horovod 指南
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="user-guides.html">
     用户指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples.html">
     示例
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="benchmarks.html">
     基准
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="api/api.html">
     Ray 训练 API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tune/index.html">
   Ray 调参「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/index.html">
   更多类库「40%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cluster/getting-started.html">
   Ray 集群「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-observability/index.html">
   监控调试「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-references/api.html">
   参考「20%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-contribute/index.html">
   开发者指引「30%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-security/index.html">
   安全「100%」
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Ftrain/distributed-tensorflow-keras.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/train/distributed-tensorflow-keras.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/train/distributed-tensorflow-keras.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quickstart">
   Quickstart
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#update-your-training-function">
   Update your training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-a-tensorflowtrainer">
   Create a TensorflowTrainer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-a-training-function">
   Run a training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-and-preprocess-data">
   Load and preprocess data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#report-results">
   Report results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aggregate-results">
     Aggregate results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#save-and-load-checkpoints">
   Save and load checkpoints
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-checkpoints">
     Load checkpoints
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-reading">
   Further reading
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>TensorFlow 和 Keras 入门</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quickstart">
   Quickstart
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#update-your-training-function">
   Update your training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-a-tensorflowtrainer">
   Create a TensorflowTrainer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-a-training-function">
   Run a training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-and-preprocess-data">
   Load and preprocess data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#report-results">
   Report results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aggregate-results">
     Aggregate results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#save-and-load-checkpoints">
   Save and load checkpoints
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-checkpoints">
     Load checkpoints
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-reading">
   Further reading
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="tensorflow-keras">
<span id="train-tensorflow-overview"></span><h1>TensorFlow 和 Keras 入门<a class="headerlink" href="#tensorflow-keras" title="Permalink to this headline">#</a></h1>
<p>Ray Train’s <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a> integration enables you
to scale your TensorFlow and Keras training functions to many machines and GPUs.</p>
<p>On a technical level, Ray Train schedules your training workers
and configures <code class="docutils literal notranslate"><span class="pre">TF_CONFIG</span></code> for you, allowing you to run
your <code class="docutils literal notranslate"><span class="pre">MultiWorkerMirroredStrategy</span></code> training script. See <a class="reference external" href="https://www.tensorflow.org/guide/distributed_training">Distributed
training with TensorFlow</a>
for more information.</p>
<p>Most of the examples in this guide use TensorFlow with Keras, but
Ray Train also works with vanilla TensorFlow.</p>
<section id="quickstart">
<h2>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.air.integrations.keras</span> <span class="kn">import</span> <span class="n">ReportCheckpointCallback</span>
<span class="kn">from</span> <span class="nn">ray.train.tensorflow</span> <span class="kn">import</span> <span class="n">TensorflowTrainer</span>


<span class="c1"># If using GPUs, set this to True.</span>
<span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">a</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">size</span> <span class="o">=</span> <span class="mi">100</span>


<span class="k">def</span> <span class="nf">build_model</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">()),</span>
            <span class="c1"># Add feature dimension, expanding (batch_size,) to (batch_size, 1).</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
        <span class="c1"># Model building/compiling need to be within `strategy.scope()`.</span>
        <span class="n">multi_worker_model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>
        <span class="n">multi_worker_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)),</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">],</span>
        <span class="p">)</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">to_tf</span><span class="p">(</span>
            <span class="n">feature_columns</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">label_columns</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span>
        <span class="p">)</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">multi_worker_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">tf_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ReportCheckpointCallback</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span>


<span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_items</span><span class="p">(</span>
    <span class="p">[{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="mi">200</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="mi">200</span><span class="p">}</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">)]</span>
<span class="p">)</span>
<span class="n">scaling_config</span> <span class="o">=</span> <span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TensorflowTrainer</span><span class="p">(</span>
    <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_func</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">scaling_config</span><span class="p">,</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="update-your-training-function">
<h2>Update your training function<a class="headerlink" href="#update-your-training-function" title="Permalink to this headline">#</a></h2>
<p>First, update your <a class="reference internal" href="overview.html#train-overview-training-function"><span class="std std-ref">training function</span></a> to support distributed
training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The current TensorFlow implementation supports
<code class="docutils literal notranslate"><span class="pre">MultiWorkerMirroredStrategy</span></code> (and <code class="docutils literal notranslate"><span class="pre">MirroredStrategy</span></code>). If there are
other strategies you wish to see supported by Ray Train, submit a <a class="reference external" href="https://github.com/ray-project/ray/issues">feature request on GitHub</a>.</p>
</div>
<p>These instructions closely follow TensorFlow’s <a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras">Multi-worker training
with Keras</a>
tutorial. One key difference is that Ray Train handles the environment
variable set up for you.</p>
<p><strong>Step 1:</strong> Wrap your model in <code class="docutils literal notranslate"><span class="pre">MultiWorkerMirroredStrategy</span></code>.</p>
<p>The <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy">MultiWorkerMirroredStrategy</a>
enables synchronous distributed training. You <em>must</em> build and compile the <code class="docutils literal notranslate"><span class="pre">Model</span></code> within the scope of the strategy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">()</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># build model</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Step 2:</strong> Update your <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> batch size to the <em>global</em> batch
size.</p>
<p>Set <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> appropriately because <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch">batch</a>
splits evenly across worker processes.</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="gd">-batch_size = worker_batch_size</span><span class="w"></span>
<span class="gi">+batch_size = worker_batch_size * train.get_context().get_world_size()</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Ray doesn’t automatically set any environment variables or configuration
related to local parallelism or threading
<a class="reference internal" href="../ray-core/configure.html#omp-num-thread-note"><span class="std std-ref">aside from “OMP_NUM_THREADS”</span></a>.
If you want greater control over TensorFlow threading, use
the <code class="docutils literal notranslate"><span class="pre">tf.config.threading</span></code> module (eg.
<code class="docutils literal notranslate"><span class="pre">tf.config.threading.set_inter_op_parallelism_threads(num_cpus)</span></code>)
at the beginning of your <code class="docutils literal notranslate"><span class="pre">train_loop_per_worker</span></code> function.</p>
</div>
</section>
<section id="create-a-tensorflowtrainer">
<h2>Create a TensorflowTrainer<a class="headerlink" href="#create-a-tensorflowtrainer" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Trainer</span></code>s are the primary Ray Train classes for managing state and
execute training. For distributed Tensorflow,
use a <a class="reference internal" href="api/doc/ray.train.tensorflow.TensorflowTrainer.html#ray.train.tensorflow.TensorflowTrainer" title="ray.train.tensorflow.TensorflowTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorflowTrainer</span></code></a>
that you can setup like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.tensorflow</span> <span class="kn">import</span> <span class="n">TensorflowTrainer</span>
<span class="c1"># For GPU Training, set `use_gpu` to True.</span>
<span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TensorflowTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>To customize the backend setup, you can pass a
<a class="reference internal" href="api/doc/ray.train.tensorflow.TensorflowConfig.html#ray.train.tensorflow.TensorflowConfig" title="ray.train.tensorflow.TensorflowConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorflowConfig</span></code></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.tensorflow</span> <span class="kn">import</span> <span class="n">TensorflowTrainer</span><span class="p">,</span> <span class="n">TensorflowConfig</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TensorflowTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">tensorflow_backend</span><span class="o">=</span><span class="n">TensorflowConfig</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For more configurability, see the <a class="reference internal" href="api/doc/ray.train.data_parallel_trainer.DataParallelTrainer.html#ray.train.data_parallel_trainer.DataParallelTrainer" title="ray.train.data_parallel_trainer.DataParallelTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallelTrainer</span></code></a> API.</p>
</section>
<section id="run-a-training-function">
<h2>Run a training function<a class="headerlink" href="#run-a-training-function" title="Permalink to this headline">#</a></h2>
<p>With a distributed training function and a Ray Train <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, you are now
ready to start training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="load-and-preprocess-data">
<h2>Load and preprocess data<a class="headerlink" href="#load-and-preprocess-data" title="Permalink to this headline">#</a></h2>
<p>TensorFlow by default uses its own internal dataset sharding policy, as described
<a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#dataset_sharding">in the guide</a>.
If your TensorFlow dataset is compatible with distributed loading, you don’t need to
change anything.</p>
<p>If you require more advanced preprocessing, you may want to consider using Ray Data
for distributed data ingest. See <a class="reference internal" href="user-guides/data-loading-preprocessing.html#data-ingest-torch"><span class="std std-ref">Ray Data with Ray Train</span></a>.</p>
<p>The main difference is that you may want to convert your Ray Data dataset shard to
a TensorFlow dataset in your training function so that you can use the Keras
API for model training.</p>
<p><a class="reference external" href="https://github.com/ray-project/ray/blob/master/python/ray/train/examples/tf/tune_tensorflow_autoencoder_example.py">See this example</a>
for distributed data loading. The relevant parts are:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">ray.train.tensorflow</span> <span class="kn">import</span> <span class="n">prepare_dataset_shard</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="c1"># ...</span>

    <span class="c1"># Get dataset shard from Ray Train</span>
    <span class="n">dataset_shard</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>

    <span class="c1"># Define a helper function to build a TensorFlow dataset</span>
    <span class="k">def</span> <span class="nf">to_tf_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">to_tensor_iterator</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iter_tf_batches</span><span class="p">(</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
            <span class="p">):</span>
                <span class="k">yield</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>

        <span class="n">output_signature</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_generator</span><span class="p">(</span>
            <span class="n">to_tensor_iterator</span><span class="p">,</span> <span class="n">output_signature</span><span class="o">=</span><span class="n">output_signature</span>
        <span class="p">)</span>
        <span class="c1"># Call prepare_dataset_shard to disable automatic sharding</span>
        <span class="c1"># (since the dataset is already sharded)</span>
        <span class="k">return</span> <span class="n">prepare_dataset_shard</span><span class="p">(</span><span class="n">tf_dataset</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Call our helper function to build the dataset</span>
        <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">to_tf_dataset</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset_shard</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">multi_worker_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">tf_dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="report-results">
<h2>Report results<a class="headerlink" href="#report-results" title="Permalink to this headline">#</a></h2>
<p>During training, the training loop should report intermediate results and checkpoints
to Ray Train. This reporting logs the results to the console output and appends them to
local log files. The logging also triggers <a class="reference internal" href="user-guides/checkpoints.html#train-dl-configure-checkpoints"><span class="std std-ref">checkpoint bookkeeping</span></a>.</p>
<p>The easiest way to report your results with Keras is by using the
<a class="reference internal" href="api/doc/ray.train.tensorflow.keras.ReportCheckpointCallback.html#ray.train.tensorflow.keras.ReportCheckpointCallback" title="ray.train.tensorflow.keras.ReportCheckpointCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReportCheckpointCallback</span></code></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train.tensorflow.keras</span> <span class="kn">import</span> <span class="n">ReportCheckpointCallback</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="c1"># ...</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ReportCheckpointCallback</span><span class="p">()])</span>
</pre></div>
</div>
<p>This callback automatically forwards all results and checkpoints from the
Keras training function to Ray Train.</p>
<section id="aggregate-results">
<h3>Aggregate results<a class="headerlink" href="#aggregate-results" title="Permalink to this headline">#</a></h3>
<p>TensorFlow Keras automatically aggregates metrics from all workers. If you wish to have more
control over that, consider implementing a <a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/custom_training">custom training loop</a>.</p>
</section>
</section>
<section id="save-and-load-checkpoints">
<h2>Save and load checkpoints<a class="headerlink" href="#save-and-load-checkpoints" title="Permalink to this headline">#</a></h2>
<p>You can save <a class="reference internal" href="api/doc/ray.train.Checkpoint.html#ray.train.Checkpoint" title="ray.train.Checkpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Checkpoints</span></code></a> by calling <code class="docutils literal notranslate"><span class="pre">train.report(metrics,</span> <span class="pre">checkpoint=Checkpoint(...))</span></code> in the
training function. This call saves the checkpoint state from the distributed
workers on the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, where you executed your python script.</p>
<p>You can access the latest saved checkpoint through the <code class="docutils literal notranslate"><span class="pre">checkpoint</span></code> attribute of
the <a class="reference internal" href="api/doc/ray.train.Result.html#ray.train.Result" title="ray.train.Result"><code class="xref py py-class docutils literal notranslate"><span class="pre">Result</span></code></a>, and access the best saved checkpoints with the <code class="docutils literal notranslate"><span class="pre">best_checkpoints</span></code>
attribute.</p>
<p>These concrete examples demonstrate how Ray Train appropriately saves checkpoints, model weights but not models, in distributed training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">Checkpoint</span><span class="p">,</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.tensorflow</span> <span class="kn">import</span> <span class="n">TensorflowTrainer</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="c1"># create a toy dataset</span>
    <span class="c1"># data   : X - dim = (n, 4)</span>
    <span class="c1"># target : Y - dim = (n, 1)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
        <span class="c1"># toy neural network : 1-layer</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,))])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mean_squared_error&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mse&quot;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">]):</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">temp_checkpoint_dir</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_checkpoint_dir</span><span class="p">,</span> <span class="s2">&quot;model.keras&quot;</span><span class="p">))</span>
            <span class="n">checkpoint_dict</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_checkpoint_dir</span><span class="p">,</span> <span class="s2">&quot;checkpoint.json&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">checkpoint_dict</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">},</span> <span class="n">f</span><span class="p">)</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">temp_checkpoint_dir</span><span class="p">)</span>

            <span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">({</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]},</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TensorflowTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, checkpoints persist to local disk in the <a class="reference internal" href="user-guides/persistent-storage.html#train-log-dir"><span class="std std-ref">log
directory</span></a> of each run.</p>
<section id="load-checkpoints">
<h3>Load checkpoints<a class="headerlink" href="#load-checkpoints" title="Permalink to this headline">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">Checkpoint</span><span class="p">,</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.tensorflow</span> <span class="kn">import</span> <span class="n">TensorflowTrainer</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="c1"># create a toy dataset</span>
    <span class="c1"># data   : X - dim = (n, 4)</span>
    <span class="c1"># target : Y - dim = (n, 1)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
        <span class="c1"># toy neural network : 1-layer</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">get_checkpoint</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">checkpoint</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">as_directory</span><span class="p">()</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">&quot;model.keras&quot;</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,))]</span>
            <span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mean_squared_error&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mse&quot;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">]):</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">temp_checkpoint_dir</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_checkpoint_dir</span><span class="p">,</span> <span class="s2">&quot;model.keras&quot;</span><span class="p">))</span>
            <span class="n">extra_json</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_checkpoint_dir</span><span class="p">,</span> <span class="s2">&quot;checkpoint.json&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">extra_json</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">},</span> <span class="n">f</span><span class="p">)</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_directory</span><span class="p">(</span><span class="n">temp_checkpoint_dir</span><span class="p">)</span>

            <span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">({</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]},</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TensorflowTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="c1"># Start a new run from a loaded checkpoint</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TensorflowTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="further-reading">
<h2>Further reading<a class="headerlink" href="#further-reading" title="Permalink to this headline">#</a></h2>
<p>See <a class="reference internal" href="user-guides.html#train-user-guides"><span class="std std-ref">User Guides</span></a> to explore more topics:</p>
<ul class="simple">
<li><p><a class="reference internal" href="user-guides/experiment-tracking.html#train-experiment-tracking-native"><span class="std std-ref">Experiment tracking</span></a></p></li>
<li><p><a class="reference internal" href="user-guides/fault-tolerance.html#train-fault-tolerance"><span class="std std-ref">Fault tolerance and training on spot instances</span></a></p></li>
<li><p><a class="reference internal" href="user-guides/hyperparameter-optimization.html#train-tune"><span class="std std-ref">Hyperparameter optimization</span></a></p></li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="deepspeed.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">DeepSpeed 入门</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="distributed-xgboost-lightgbm.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">开始使用 XGBoost 和 LightGBM</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>谢谢你的反馈！</span>
  </div>
  <div id="csat-inputs">
    <span>是否能帮助到你？</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>是<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>否<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">反馈</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">提交</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2024, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>