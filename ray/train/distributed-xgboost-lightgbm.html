
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>开始使用 XGBoost 和 LightGBM &#8212; Ray 2.7.2</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/versionwarning.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../_static/js/docsearch.js"></script>
    <script defer="defer" src="../_static/js/csat.js"></script>
    <script defer="defer" src="../_static/js/termynal.js"></script>
    <script defer="defer" src="../_static/js/custom.js"></script>
    <script defer="defer" src="../_static/js/top-navigation.js"></script>
    <script src="../_static/js/tags.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/train/distributed-xgboost-lightgbm.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Get Started with Horovod" href="horovod.html" />
    <link rel="prev" title="TensorFlow 和 Keras 入门" href="distributed-tensorflow-keras.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
  data-modal-disclaimer = "Results are automated and may be incorrect or contain inappropriate information. Do not include any personal data or confidential information."
  data-modal-title = "Ray Docs AI - Ask a Question"
  data-button-position-bottom = "60px"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 2.7.2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    欢迎来到 Ray ！
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/index.html">
   概述「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/getting-started.html">
   入门
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/installation.html">
   安装「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/use-cases.html">
   用例「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/examples.html">
   示例库「1%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-overview/ray-libraries.html">
   生态「3%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-core/walkthrough.html">
   Ray 核心「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data/data.html">
   Ray 数据「75%」
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="train.html">
   Ray 训练「0%」
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="overview.html">
     概述
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-pytorch.html">
     PyTorch 指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-pytorch-lightning.html">
     PyTorch Lightning 指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started-transformers.html">
     Hugging Face Transformers 指南
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="more-frameworks.html">
     更多框架
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="huggingface-accelerate.html">
       Hugging Face Accelerate 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="deepspeed.html">
       DeepSpeed 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="distributed-tensorflow-keras.html">
       TensorFlow and Keras 指南
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       XGBoost and LightGBM 指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="horovod.html">
       Horovod 指南
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="user-guides.html">
     用户指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples.html">
     示例
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="benchmarks.html">
     基准
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="api/api.html">
     Ray 训练 API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tune/index.html">
   Ray 调参「0%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-more-libs/index.html">
   更多类库「40%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cluster/getting-started.html">
   Ray 集群「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-observability/index.html">
   监控调试「100%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-references/api.html">
   参考「20%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-contribute/index.html">
   开发者指引「30%」
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ray-security/index.html">
   安全「100%」
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Ftrain/distributed-xgboost-lightgbm.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/train/distributed-xgboost-lightgbm.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/train/distributed-xgboost-lightgbm.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quickstart">
   Quickstart
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basic-training-with-tree-based-models-in-train">
   Basic training with tree-based models in Train
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#save-and-load-xgboost-and-lightgbm-checkpoints">
   Save and load XGBoost and LightGBM checkpoints
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-scale-out-training">
   How to scale out training?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-many-remote-actors-should-you-use">
   How many remote actors should you use?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-use-gpus-for-training">
   How to use GPUs for training?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-preprocess-data-for-training">
   How to preprocess data for training?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-optimize-xgboost-memory-usage">
   How to optimize XGBoost memory usage?
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>开始使用 XGBoost 和 LightGBM</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quickstart">
   Quickstart
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basic-training-with-tree-based-models-in-train">
   Basic training with tree-based models in Train
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#save-and-load-xgboost-and-lightgbm-checkpoints">
   Save and load XGBoost and LightGBM checkpoints
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-scale-out-training">
   How to scale out training?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-many-remote-actors-should-you-use">
   How many remote actors should you use?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-use-gpus-for-training">
   How to use GPUs for training?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-preprocess-data-for-training">
   How to preprocess data for training?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-optimize-xgboost-memory-usage">
   How to optimize XGBoost memory usage?
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="xgboost-lightgbm">
<span id="train-gbdt-guide"></span><h1>开始使用 XGBoost 和 LightGBM<a class="headerlink" href="#xgboost-lightgbm" title="Permalink to this headline">#</a></h1>
<p>Ray Train has built-in support for XGBoost and LightGBM.</p>
<section id="quickstart">
<h2>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">#</a></h2>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-0">
XGBoost</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.xgboost</span> <span class="kn">import</span> <span class="n">XGBoostTrainer</span>

<span class="c1"># Load data.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;s3://anonymous@air-example-data/breast_cancer.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split data into train and validation.</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">XGBoostTrainer</span><span class="p">(</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span>
        <span class="c1"># Number of workers to use for data parallelism.</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="c1"># Whether to use GPU acceleration.</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">label_column</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># XGBoost specific params</span>
        <span class="s2">&quot;objective&quot;</span><span class="p">:</span> <span class="s2">&quot;binary:logistic&quot;</span><span class="p">,</span>
        <span class="c1"># &quot;tree_method&quot;: &quot;gpu_hist&quot;,  # uncomment this to use GPU for training</span>
        <span class="s2">&quot;eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="n">valid_dataset</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-1">
LightGBM</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.lightgbm</span> <span class="kn">import</span> <span class="n">LightGBMTrainer</span>

<span class="c1"># Load data.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;s3://anonymous@air-example-data/breast_cancer.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split data into train and validation.</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">LightGBMTrainer</span><span class="p">(</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span>
        <span class="c1"># Number of workers to use for data parallelism.</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="c1"># Whether to use GPU acceleration.</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">label_column</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># LightGBM specific params</span>
        <span class="s2">&quot;objective&quot;</span><span class="p">:</span> <span class="s2">&quot;binary&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;binary_logloss&quot;</span><span class="p">,</span> <span class="s2">&quot;binary_error&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="n">valid_dataset</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="basic-training-with-tree-based-models-in-train">
<h2>Basic training with tree-based models in Train<a class="headerlink" href="#basic-training-with-tree-based-models-in-train" title="Permalink to this headline">#</a></h2>
<p>Just as in the original <a class="reference external" href="https://xgboost.readthedocs.io/en/stable/parameter.html">xgboost.train()</a> and
<a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">lightgbm.train()</a> functions, the
training parameters are passed as the <code class="docutils literal notranslate"><span class="pre">params</span></code> dictionary.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-2" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-2">
XGBoost</label><div class="sd-tab-content docutils">
<p>Run <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-U</span> <span class="pre">xgboost_ray</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.xgboost</span> <span class="kn">import</span> <span class="n">XGBoostTrainer</span>

<span class="c1"># Load data.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;s3://anonymous@air-example-data/breast_cancer.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split data into train and validation.</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">XGBoostTrainer</span><span class="p">(</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span>
        <span class="c1"># Number of workers to use for data parallelism.</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="c1"># Whether to use GPU acceleration.</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">label_column</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># XGBoost specific params</span>
        <span class="s2">&quot;objective&quot;</span><span class="p">:</span> <span class="s2">&quot;binary:logistic&quot;</span><span class="p">,</span>
        <span class="c1"># &quot;tree_method&quot;: &quot;gpu_hist&quot;,  # uncomment this to use GPU for training</span>
        <span class="s2">&quot;eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="n">valid_dataset</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-3">
LightGBM</label><div class="sd-tab-content docutils">
<p>Run <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-U</span> <span class="pre">lightgbm_ray</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.lightgbm</span> <span class="kn">import</span> <span class="n">LightGBMTrainer</span>

<span class="c1"># Load data.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;s3://anonymous@air-example-data/breast_cancer.csv&quot;</span><span class="p">)</span>

<span class="c1"># Split data into train and validation.</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">LightGBMTrainer</span><span class="p">(</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span>
        <span class="c1"># Number of workers to use for data parallelism.</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="c1"># Whether to use GPU acceleration.</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">label_column</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># LightGBM specific params</span>
        <span class="s2">&quot;objective&quot;</span><span class="p">:</span> <span class="s2">&quot;binary&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;binary_logloss&quot;</span><span class="p">,</span> <span class="s2">&quot;binary_error&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="n">valid_dataset</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Trainer constructors pass Ray-specific parameters.</p>
</section>
<section id="save-and-load-xgboost-and-lightgbm-checkpoints">
<span id="train-gbdt-checkpoints"></span><h2>Save and load XGBoost and LightGBM checkpoints<a class="headerlink" href="#save-and-load-xgboost-and-lightgbm-checkpoints" title="Permalink to this headline">#</a></h2>
<p>When you train a new tree on every boosting round,
you can save a checkpoint to snapshot the training progress so far.
<a class="reference internal" href="api/doc/ray.train.xgboost.XGBoostTrainer.html#ray.train.xgboost.XGBoostTrainer" title="ray.train.xgboost.XGBoostTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">XGBoostTrainer</span></code></a> and <a class="reference internal" href="api/doc/ray.train.lightgbm.LightGBMTrainer.html#ray.train.lightgbm.LightGBMTrainer" title="ray.train.lightgbm.LightGBMTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightGBMTrainer</span></code></a>
both implement checkpointing out of the box. These checkpoints can be loaded into memory
using static methods <a class="reference internal" href="api/doc/ray.train.xgboost.XGBoostTrainer.get_model.html#ray.train.xgboost.XGBoostTrainer.get_model" title="ray.train.xgboost.XGBoostTrainer.get_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">XGBoostTrainer.get_model</span></code></a> and
<a class="reference internal" href="api/doc/ray.train.lightgbm.LightGBMTrainer.get_model.html#ray.train.lightgbm.LightGBMTrainer.get_model" title="ray.train.lightgbm.LightGBMTrainer.get_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">LightGBMTrainer.get_model</span></code></a>.</p>
<p>The only required change is to configure <a class="reference internal" href="api/doc/ray.train.CheckpointConfig.html#ray.train.CheckpointConfig" title="ray.train.CheckpointConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">CheckpointConfig</span></code></a> to set
the checkpointing frequency. For example, the following configuration
saves a checkpoint on every boosting round and only keeps the latest checkpoint:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">RunConfig</span><span class="p">,</span> <span class="n">CheckpointConfig</span>

<span class="n">run_config</span> <span class="o">=</span> <span class="n">RunConfig</span><span class="p">(</span>
    <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">CheckpointConfig</span><span class="p">(</span>
        <span class="c1"># Checkpoint every iteration.</span>
        <span class="n">checkpoint_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="c1"># Only keep the latest checkpoint and delete the others.</span>
        <span class="n">num_to_keep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># from ray.train.xgboost import XGBoostTrainer</span>
<span class="c1"># trainer = XGBoostTrainer(..., run_config=run_config)</span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Once you enable checkpointing, you can follow <a class="reference internal" href="user-guides/fault-tolerance.html#train-fault-tolerance"><span class="std std-ref">this guide</span></a>
to enable fault tolerance.</p>
</div>
</section>
<section id="how-to-scale-out-training">
<h2>How to scale out training?<a class="headerlink" href="#how-to-scale-out-training" title="Permalink to this headline">#</a></h2>
<p>The benefit of using Ray Train is that you can seamlessly scale up your training by
adjusting the <a class="reference internal" href="api/doc/ray.train.ScalingConfig.html#ray.train.ScalingConfig" title="ray.train.ScalingConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">ScalingConfig</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ray Train doesn’t modify or otherwise alter the working
of the underlying XGBoost or LightGBM distributed training algorithms.
Ray only provides orchestration, data ingest and fault tolerance.
For more information on GBDT distributed training, refer to
<a class="reference external" href="https://xgboost.readthedocs.io">XGBoost documentation</a> and
<a class="reference external" href="https://lightgbm.readthedocs.io/">LightGBM documentation</a>.</p>
</div>
<p>Following are some examples of common use-cases:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-4" name="sd-tab-set-2" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-4">
Multi-node CPU</label><div class="sd-tab-content docutils">
<p>Setup: 4 nodes with 8 CPUs each.</p>
<p>Use-case: To utilize all resources in multi-node training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scaling_config</span> <span class="o">=</span> <span class="n">ScalingConfig</span><span class="p">(</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">trainer_resources</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;CPU&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
    <span class="n">resources_per_worker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;CPU&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Note that we pass 0 CPUs for the trainer resources, so that all resources can
be allocated to the actual distributed training workers.</p>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-2" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-5">
Single-node multi-GPU</label><div class="sd-tab-content docutils">
<p>Setup: 1 node with 8 CPUs and 4 GPUs.</p>
<p>Use-case: If you have a single node with multiple GPUs, you need to use
distributed training to leverage all GPUs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scaling_config</span> <span class="o">=</span> <span class="n">ScalingConfig</span><span class="p">(</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-6" name="sd-tab-set-2" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-6">
Multi-node multi-GPU</label><div class="sd-tab-content docutils">
<p>Setup: 4 node with 8 CPUs and 4 GPUs each.</p>
<p>Use-case: If you have a multiple nodes with multiple GPUs, you need to
schedule one worker per GPU.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scaling_config</span> <span class="o">=</span> <span class="n">ScalingConfig</span><span class="p">(</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Note that you just have to adjust the number of workers. Ray handles everything else
automatically.</p>
</div>
</div>
</section>
<section id="how-many-remote-actors-should-you-use">
<h2>How many remote actors should you use?<a class="headerlink" href="#how-many-remote-actors-should-you-use" title="Permalink to this headline">#</a></h2>
<p>This depends on your workload and your cluster setup.
Generally there is no inherent benefit of running more than
one remote actor per node for CPU-only training. This is because
XGBoost can already leverage multiple CPUs with threading.</p>
<p>However, in some cases, you should consider some starting
more than one actor per node:</p>
<ul class="simple">
<li><p>For <strong>multi GPU training</strong>, each GPU should have a separate
remote actor. Thus, if your machine has 24 CPUs and 4 GPUs,
you want to start 4 remote actors with 6 CPUs and 1 GPU
each</p></li>
<li><p>In a <strong>heterogeneous cluster</strong> , you might want to find the
<a class="reference external" href="https://en.wikipedia.org/wiki/Greatest_common_divisor">greatest common divisor</a>
for the number of CPUs.
For example, for a cluster with three nodes of 4, 8, and 12 CPUs, respectively,
you should set the number of actors to 6 and the CPUs per
actor to 4.</p></li>
</ul>
</section>
<section id="how-to-use-gpus-for-training">
<h2>How to use GPUs for training?<a class="headerlink" href="#how-to-use-gpus-for-training" title="Permalink to this headline">#</a></h2>
<p>Ray Train enables multi-GPU training for XGBoost and LightGBM. The core backends
automatically leverage NCCL2 for cross-device communication.
All you have to do is to start one actor per GPU and set GPU-compatible parameters.
For example, XGBoost’s <code class="docutils literal notranslate"><span class="pre">tree_method</span></code> to <code class="docutils literal notranslate"><span class="pre">gpu_hist</span></code>. See XGBoost
documentation for more details.</p>
<p>For instance, if you have 2 machines with 4 GPUs each, you want
to start 8 workers, and set <code class="docutils literal notranslate"><span class="pre">use_gpu=True</span></code>. There is usually
no benefit in allocating less (for example, 0.5) or more than one GPU per actor.</p>
<p>You should divide the CPUs evenly across actors per machine, so if your
machines have 16 CPUs in addition to the 4 GPUs, each actor should have
4 CPUs to use.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">XGBoostTrainer</span><span class="p">(</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span>
        <span class="c1"># Number of workers to use for data parallelism.</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="c1"># Whether to use GPU acceleration.</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># XGBoost specific params</span>
        <span class="s2">&quot;tree_method&quot;</span><span class="p">:</span> <span class="s2">&quot;gpu_hist&quot;</span><span class="p">,</span>
        <span class="s2">&quot;eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">label_column</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="n">valid_dataset</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="how-to-preprocess-data-for-training">
<span id="data-ingest-gbdt"></span><h2>How to preprocess data for training?<a class="headerlink" href="#how-to-preprocess-data-for-training" title="Permalink to this headline">#</a></h2>
<p>Particularly for tabular data, Ray Data comes with out-of-the-box <a class="reference internal" href="../data/preprocessors.html#air-preprocessors"><span class="std std-ref">preprocessors</span></a> that implement common feature preprocessing operations.
You can use this with Ray Train Trainers by applying them on the dataset before passing the dataset into a Trainer. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>

<span class="kn">from</span> <span class="nn">ray.data.preprocessors</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">ray.train.xgboost</span> <span class="kn">import</span> <span class="n">XGBoostTrainer</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_items</span><span class="p">([{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">}</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)])</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_items</span><span class="p">([{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">}</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)])</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">([</span><span class="s2">&quot;x&quot;</span><span class="p">])</span>
<span class="n">preprocessor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">XGBoostTrainer</span><span class="p">(</span>
    <span class="n">label_column</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;objective&quot;</span><span class="p">:</span> <span class="s2">&quot;reg:squarederror&quot;</span><span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="n">valid_dataset</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="how-to-optimize-xgboost-memory-usage">
<h2>How to optimize XGBoost memory usage?<a class="headerlink" href="#how-to-optimize-xgboost-memory-usage" title="Permalink to this headline">#</a></h2>
<p>XGBoost uses a compute-optimized datastructure, the <code class="docutils literal notranslate"><span class="pre">DMatrix</span></code>,
to hold training data. When converting a dataset to a <code class="docutils literal notranslate"><span class="pre">DMatrix</span></code>,
XGBoost creates intermediate copies and ends up
holding a complete copy of the full data. XGBoost converts the data
into the local data format. On a 64-bit system the format is 64-bit floats.
Depending on the system and original dataset dtype, this matrix can
thus occupy more memory than the original dataset.</p>
<p>The <strong>peak memory usage</strong> for CPU-based training is at least
<strong>3x</strong> the dataset size, assuming dtype <code class="docutils literal notranslate"><span class="pre">float32</span></code> on a 64-bit system,
plus about <strong>400,000 KiB</strong> for other resources,
like operating system requirements and storing of intermediate
results.</p>
<p><strong>Example</strong></p>
<ul class="simple">
<li><p>Machine type: AWS m5.xlarge (4 vCPUs, 16 GiB RAM)</p></li>
<li><p>Usable RAM: ~15,350,000 KiB</p></li>
<li><p>Dataset: 1,250,000 rows with 1024 features, dtype float32.
Total size: 5,000,000 KiB</p></li>
<li><p>XGBoost DMatrix size: ~10,000,000 KiB</p></li>
</ul>
<p>This dataset fits exactly on this node for training.</p>
<p>Note that the DMatrix size might be lower on a 32 bit system.</p>
<p><strong>GPUs</strong></p>
<p>Generally, the same memory requirements exist for GPU-based
training. Additionally, the GPU must have enough memory
to hold the dataset.</p>
<p>In the preceding example, the GPU must have at least
10,000,000 KiB (about 9.6 GiB) memory. However,
empirical data shows that using a <code class="docutils literal notranslate"><span class="pre">DeviceQuantileDMatrix</span></code>
seems to result in more peak GPU memory usage, possibly
for intermediate storage when loading data (about 10%).</p>
<p><strong>Best practices</strong></p>
<p>In order to reduce peak memory usage, consider the following
suggestions:</p>
<ul class="simple">
<li><p>Store data as <code class="docutils literal notranslate"><span class="pre">float32</span></code> or less. You often don’t need
more precision is often, and keeping data in a smaller format
helps reduce peak memory usage for initial data loading.</p></li>
<li><p>Pass the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> when loading data from CSV. Otherwise,
floating point values are loaded as <code class="docutils literal notranslate"><span class="pre">np.float64</span></code>
per default, increasing peak memory usage by 33%.</p></li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="distributed-tensorflow-keras.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">TensorFlow 和 Keras 入门</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="horovod.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Get Started with Horovod</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>谢谢你的反馈！</span>
  </div>
  <div id="csat-inputs">
    <span>是否能帮助到你？</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>是<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>否<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">反馈</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">提交</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2024, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>