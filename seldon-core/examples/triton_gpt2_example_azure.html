<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-54780881-2"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'UA-54780881-2');
</script>
  
  
    <title>Pretrained GPT2 Model Deployment Example &#8212; seldon-core  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=83e35b93" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css?v=79c92029" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/rtd_sphinx_search.min.css?v=e72958e9" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css?v=15a8f09d" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/rtd_search_config.js?v=b0596c34"></script>
    <script src="../_static/js/rtd_sphinx_search.min.js?v=43f26ba4"></script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Setup Azure Kubernetes Infrastructure" href="triton_gpt2_example_azure_setup.html" />
    <link rel="prev" title="Alibaba Cloud Container Service for Kubernetes (ACK) Deep MNIST Example" href="alibaba_ack_deep_mnist.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=teal>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#examples/triton_gpt2_example_azure" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="seldon-core  documentation"
           class="md-header-nav__button md-logo">
          
            &nbsp;
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Seldon Core Documentation</span>
          <span class="md-header-nav__topic"> Pretrained GPT2 Model Deployment Example </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/SeldonIO/seldon-core/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Seldon Core
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="/" class="md-tabs__link">üöÄ Our Other Projects & Products:</a></li>
            
            <li class="md-tabs__item"><a href="https://docs.seldon.io/projects/alibi/en/stable/" class="md-tabs__link">Alibi Explain</a></li>
            
            <li class="md-tabs__item"><a href="https://docs.seldon.io/projects/alibi-detect/en/stable/" class="md-tabs__link">Alibi Detect</a></li>
            
            <li class="md-tabs__item"><a href="https://mlserver.readthedocs.io/en/latest/" class="md-tabs__link">MLServer</a></li>
            
            <li class="md-tabs__item"><a href="https://tempo.readthedocs.io/en/latest/" class="md-tabs__link">Tempo SDK</a></li>
            
            <li class="md-tabs__item"><a href="https://deploy.seldon.io" class="md-tabs__link">Seldon Enterprise Platform</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/SeldonIO/seldon-deploy-sdk#seldon-deploy-sdk" class="md-tabs__link">Seldon Enterprise Platform SDK</a></li>
          <li class="md-tabs__item"><a href="../nav/tutorials.html" class="md-tabs__link">ÊïôÁ®ã</a></li>
          <li class="md-tabs__item"><a href="notebooks.html" class="md-tabs__link">Á¨îËÆ∞Êú¨</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="seldon-core documentation" class="md-nav__button md-logo">
      
        <img src="../_static/" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../index.html"
       title="seldon-core documentation">Seldon Core Documentation</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/SeldonIO/seldon-core/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Seldon Core
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="../nav/getting-started.html" class="md-nav__link">ÂºÄÂßã</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/concepts.html" class="md-nav__link">Ê¶ÇÂøµ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/configuration.html" class="md-nav__link">ÈÖçÁΩÆ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/tutorials.html" class="md-nav__link">ÊïôÁ®ã</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="notebooks.html" class="md-nav__link">Á¨îËÆ∞Êú¨</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#seldon-core" class="md-nav__link">Seldon Core ËÆæÁΩÆ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id2" class="md-nav__link">È¢ÑÂåÖË£ÖÊé®ÁêÜÊúçÂä°Á§∫‰æã</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#python" class="md-nav__link">Python ËØ≠Ë®ÄÂ∞ÅË£ÖÁ§∫‰æã</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id3" class="md-nav__link">‰∏ìÈó®ÁöÑÊ°ÜÊû∂Á§∫‰æã</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id4" class="md-nav__link">Â≠µÂåñÈ°πÁõÆÁ§∫‰æã</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id5" class="md-nav__link">Âü∫‰∫é‰∫ëÁöÑÂü∫Á°ÄÁ§∫‰æã</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id6" class="md-nav__link">È´òÁ∫ßÊú∫Âô®Â≠¶‰π†ÁõëÊéß</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id7" class="md-nav__link">Seldon Core ÊâπÂ§ÑÁêÜ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#mlops" class="md-nav__link">MLOps: Êâ©Â±ï„ÄÅÁõëÊéßÂíåÂèØËßÇÂØüÊÄß</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id8" class="md-nav__link">Áîü‰∫ßÈÖçÁΩÆÂèäÂÆûÁé∞</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#ab" class="md-nav__link">AB ÊµãËØïÂèäÊ∏êËøõÂºèÈÉ®ÁΩ≤</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id9" class="md-nav__link">Â§çÊùÇÂõæÁ§∫‰æã</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id10" class="md-nav__link">ÂÖ•Âè£</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id11" class="md-nav__link">Âü∫Á°ÄËÆæÊñΩ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id12" class="md-nav__link">Âü∫ÂáÜÊµãËØïÂíåË¥üËΩΩÊµãËØï</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id13" class="md-nav__link">ÂçáÁ∫ßÁ§∫‰æã</a>
      
    
    </li></ul>
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/reference.html" class="md-nav__link">ÂèÇËÄÉ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/contributing.html" class="md-nav__link">Ë¥°ÁåÆ</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">"Contents"</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#examples-triton-gpt2-example-azure--page-root" class="md-nav__link">Pretrained GPT2 Model Deployment Example</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Steps:" class="md-nav__link">Steps:</a>
        </li>
        <li class="md-nav__item"><a href="#Basic-requirements" class="md-nav__link">Basic requirements</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally" class="md-nav__link">Export HuggingFace TFGPT2LMHeadModel pre-trained model and save it locally</a>
        </li>
        <li class="md-nav__item"><a href="#Convert-the-TensorFlow-saved-model-to-ONNX" class="md-nav__link">Convert the TensorFlow saved model to ONNX</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Azure-Setup" class="md-nav__link">Azure Setup</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Copy-your-model-to-Azure-Blob" class="md-nav__link">Copy your model to Azure Blob</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Add-Azure-PersistentVolume-and-Claim" class="md-nav__link">Add Azure PersistentVolume and Claim</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Run-Seldon-in-your-kubernetes-cluster" class="md-nav__link">Run Seldon in your kubernetes cluster</a>
        </li>
        <li class="md-nav__item"><a href="#Deploy-your-model-with-Seldon-pre-packaged-Triton-server" class="md-nav__link">Deploy your model with Seldon pre-packaged Triton server</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)" class="md-nav__link">Interact with the model: get model metadata (a ‚Äútest‚Äù request to make sure our model is available and loaded correctly)</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach" class="md-nav__link">Run prediction test: generate a sentence completion using GPT2 model - Greedy approach</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Configure-Model-Monitoring-with-Azure-Monitor" class="md-nav__link">Configure Model Monitoring with Azure Monitor</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Configure-Prometheus-Metrics-scraping" class="md-nav__link">Configure Prometheus Metrics scraping</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Query-and-Visualize-collected-data" class="md-nav__link">Query and Visualize collected data</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Run-Load-Test-/-Performance-Test-using-vegeta" class="md-nav__link">Run Load Test / Performance Test using vegeta</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation" class="md-nav__link">Install vegeta, for more details take a look in vegeta official documentation</a>
        </li>
        <li class="md-nav__item"><a href="#Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure" class="md-nav__link">Generate vegeta target file contains ‚Äúpost‚Äù cmd with payload in the requiered structure</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Clean-up" class="md-nav__link">Clean-up</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../_sources/examples/triton_gpt2_example_azure.nblink.txt">Show Source</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <div class="admonition note">
<p>This page was generated from <a class="reference external" href="https://github.com/SeldonIO/seldon-core/blob/e665e4994eabf83fb43c68a5f85e96d5c45e91b5/examples/triton_gpt2/GPT2-ONNX-Azure.ipynb">examples/triton_gpt2/GPT2-ONNX-Azure.ipynb</a>.</p>
</div>
<section id="Pretrained-GPT2-Model-Deployment-Example">
<h1 id="examples-triton-gpt2-example-azure--page-root">Pretrained GPT2 Model Deployment Example<a class="headerlink" href="#examples-triton-gpt2-example-azure--page-root" title="Permalink to this heading">¬∂</a></h1>
<p>In this notebook, we will run an example of text generation using GPT2 model exported from HuggingFace and deployed with Seldon‚Äôs Triton pre-packed server. the example also covers converting the model to ONNX format. The implemented example below is of the Greedy approach for the next token prediction. more info: <a class="reference external" href="https://huggingface.co/transformers/model_doc/gpt2.html?highlight=gpt2">https://huggingface.co/transformers/model_doc/gpt2.html?highlight=gpt2</a></p>
<p>After we have the module deployed to Kubernetes, we will run a simple load test to evaluate the module inference performance.</p>
<section id="Steps:">
<h2 id="Steps:">Steps:<a class="headerlink" href="#Steps:" title="Permalink to this heading">¬∂</a></h2>
<ul class="simple">
<li><p>Download pretrained GPT2 model from hugging face</p></li>
<li><p>Convert the model to ONNX</p></li>
<li><p>Store model in Azure Storage Blob</p></li>
<li><p>Create PersistentVolume and PVC mounting Azure Storage Blob</p></li>
<li><p>Setup Seldon-Core in your kubernetes cluster</p></li>
<li><p>Deploy the ONNX model with Seldon‚Äôs prepackaged Triton server.</p></li>
<li><p>Run model inference, run a greedy alg example (generate sentence completion)</p></li>
<li><p>Monitor model with Azure Monitor</p></li>
<li><p>Run load test using vegeta</p></li>
<li><p>Clean-up</p></li>
</ul>
</section>
<section id="Basic-requirements">
<h2 id="Basic-requirements">Basic requirements<a class="headerlink" href="#Basic-requirements" title="Permalink to this heading">¬∂</a></h2>
<ul class="simple">
<li><p>Helm v3.0.0+</p></li>
<li><p>A Kubernetes cluster running v1.13 or above (minkube / docker-for-windows work well if enough RAM)</p></li>
<li><p>kubectl v1.14+</p></li>
<li><p>Python 3.6+</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> requirements.txt
<span class="n">transformers</span><span class="o">==</span><span class="mf">4.5.1</span>
<span class="n">torch</span><span class="o">==</span><span class="mf">1.8.1</span>
<span class="n">tokenizers</span><span class="o">&lt;</span><span class="mf">0.11</span><span class="p">,</span><span class="o">&gt;=</span><span class="mf">0.10.1</span>
<span class="n">tensorflow</span><span class="o">==</span><span class="mf">2.4.1</span>
<span class="n">tf2onnx</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--trusted-host<span class="o">=</span>pypi.python.org<span class="w"> </span>--trusted-host<span class="o">=</span>pypi.org<span class="w"> </span>--trusted-host<span class="o">=</span>files.pythonhosted.org<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</div>
<section id="Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally">
<h3 id="Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally">Export HuggingFace TFGPT2LMHeadModel pre-trained model and save it locally<a class="headerlink" href="#Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally" title="Permalink to this heading">¬∂</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">TFGPT2LMHeadModel</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TFGPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">"gpt2"</span><span class="p">,</span> <span class="n">from_pt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">"./tfgpt2model"</span><span class="p">,</span> <span class="n">saved_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Convert-the-TensorFlow-saved-model-to-ONNX">
<h3 id="Convert-the-TensorFlow-saved-model-to-ONNX">Convert the TensorFlow saved model to ONNX<a class="headerlink" href="#Convert-the-TensorFlow-saved-model-to-ONNX" title="Permalink to this heading">¬∂</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python<span class="w"> </span>-m<span class="w"> </span>tf2onnx.convert<span class="w"> </span>--saved-model<span class="w"> </span>./tfgpt2model/saved_model/1<span class="w"> </span>--opset<span class="w"> </span><span class="m">13</span><span class="w">  </span>--output<span class="w"> </span>model.onnx
</pre></div>
</div>
</div>
</section>
</section>
<section id="Azure-Setup">
<h2 id="Azure-Setup">Azure Setup<a class="headerlink" href="#Azure-Setup" title="Permalink to this heading">¬∂</a></h2>
<p>We have provided <a class="reference external" href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/triton_gpt2_example_azure_setup.html">Azure Setup Notebook</a> that deploys AKS cluster, Azure storage account and installs Azure Blob CSI driver. If AKS cluster already exists skip to creation of Blob Storage and CSI driver installtion steps. Upon completion of Azure setup following infrastructure will be created: <img alt="Azure" src="../_images/azure.jpg"/></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resource_group</span> <span class="o">=</span> <span class="s2">"seldon"</span>  <span class="c1"># feel free to replace or use this default</span>
<span class="n">aks_name</span> <span class="o">=</span> <span class="s2">"modeltests"</span>

<span class="n">storage_account_name</span> <span class="o">=</span> <span class="s2">"modeltestsgpt"</span>  <span class="c1"># fill in</span>
<span class="n">storage_container_name</span> <span class="o">=</span> <span class="s2">"gpt2onnx"</span>
</pre></div>
</div>
</div>
<section id="Copy-your-model-to-Azure-Blob">
<h3 id="Copy-your-model-to-Azure-Blob">Copy your model to Azure Blob<a class="headerlink" href="#Copy-your-model-to-Azure-Blob" title="Permalink to this heading">¬∂</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># Copy model file</span>
<span class="err">!</span><span class="n">az</span> <span class="n">extension</span> <span class="n">add</span> <span class="o">--</span><span class="n">name</span> <span class="n">storage</span><span class="o">-</span><span class="n">preview</span>
<span class="err">!</span><span class="n">az</span> <span class="n">storage</span> <span class="n">azcopy</span> <span class="n">blob</span> <span class="n">upload</span> <span class="o">--</span><span class="n">container</span> <span class="p">{</span><span class="n">storage_container_name</span><span class="p">}</span> \
                               <span class="o">--</span><span class="n">account</span><span class="o">-</span><span class="n">name</span> <span class="p">{</span><span class="n">storage_account_name</span><span class="p">}</span> \
                               <span class="o">--</span><span class="n">source</span>  <span class="o">./</span><span class="n">model</span><span class="o">.</span><span class="n">onnx</span> \
                               <span class="o">--</span><span class="n">destination</span> <span class="n">gpt2</span><span class="o">/</span><span class="mi">1</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">onnx</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Verify Uploaded file</span>
<span class="o">!</span>az<span class="w"> </span>storage<span class="w"> </span>blob<span class="w"> </span>list<span class="w"> </span><span class="err">\</span>
    <span class="o">--</span><span class="n">account</span><span class="o">-</span><span class="n">name</span> <span class="p">{</span><span class="n">storage_account_name</span><span class="p">}</span>\
    <span class="o">--</span><span class="n">container</span><span class="o">-</span><span class="n">name</span> <span class="p">{</span><span class="n">storage_container_name</span><span class="p">}</span> \
    <span class="o">--</span><span class="n">output</span> <span class="n">table</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-yellow-fg">This command has been deprecated and will be removed in future release. Use 'az storage fs file list' instead. For more information go to https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/storage/docs/ADLS%20Gen2.md</span>
<span class="ansi-yellow-fg">The behavior of this command has been altered by the following extension: storage-preview</span>
Name               IsDirectory    Blob Type    Blob Tier    Length     Content Type              Last Modified              Snapshot
-----------------  -------------  -----------  -----------  ---------  ------------------------  -------------------------  ----------
gpt2/1/model.onnx                 BlockBlob    Hot          652535462  application/octet-stream  2021-05-28T04:37:11+00:00

</pre></div></div>
</div>
</section>
</section>
<section id="Add-Azure-PersistentVolume-and-Claim">
<h2 id="Add-Azure-PersistentVolume-and-Claim">Add Azure PersistentVolume and Claim<a class="headerlink" href="#Add-Azure-PersistentVolume-and-Claim" title="Permalink to this heading">¬∂</a></h2>
<p>For more details on creating PersistentVolume using CSI driver refer to <a class="reference external" href="https://github.com/kubernetes-sigs/blob-csi-driver/blob/master/deploy/example/e2e_usage.md">https://github.com/kubernetes-sigs/blob-csi-driver/blob/master/deploy/example/e2e_usage.md</a> - Create secret - Create PersistentVolume pointing to secret and Blob Container Name and <code class="docutils literal notranslate"><span class="pre">mountOptions</span></code> specifying user id for non-root containers - Creare PersistentVolumeClaim to bind to volume</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">key</span> <span class="o">=</span> <span class="o">!</span>az<span class="w"> </span>storage<span class="w"> </span>account<span class="w"> </span>keys<span class="w"> </span>list<span class="w"> </span>--account-name<span class="w"> </span><span class="o">{</span>storage_account_name<span class="o">}</span><span class="w"> </span>-g<span class="w"> </span><span class="o">{</span>resource_group<span class="o">}</span><span class="w"> </span>--query<span class="w"> </span><span class="s1">'[0].value'</span><span class="w"> </span>-o<span class="w"> </span>tsv
<span class="n">storage_account_key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create secret to access storage account</span>
<span class="o">!</span>kubectl<span class="w"> </span>create<span class="w"> </span>secret<span class="w"> </span>generic<span class="w"> </span>azure-blobsecret<span class="w"> </span>--from-literal<span class="w"> </span><span class="nv">azurestorageaccountname</span><span class="o">={</span>storage_account_name<span class="o">}</span><span class="w"> </span>--from-literal<span class="w"> </span><span class="nv">azurestorageaccountkey</span><span class="o">=</span><span class="s2">"{storage_account_key}"</span><span class="w"> </span>--type<span class="o">=</span>Opaque
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> azure-blobfuse-pv.yaml
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">PersistentVolume</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">pv</span><span class="o">-</span><span class="n">gpt2blob</span>

<span class="n">spec</span><span class="p">:</span>
  <span class="n">capacity</span><span class="p">:</span>
    <span class="n">storage</span><span class="p">:</span> <span class="mi">10</span><span class="n">Gi</span>
  <span class="n">accessModes</span><span class="p">:</span>
    <span class="o">-</span> <span class="n">ReadWriteMany</span>
  <span class="n">persistentVolumeReclaimPolicy</span><span class="p">:</span> <span class="n">Retain</span>  <span class="c1"># "Delete" is not supported in static provisioning</span>
  <span class="n">csi</span><span class="p">:</span>
    <span class="n">driver</span><span class="p">:</span> <span class="n">blob</span><span class="o">.</span><span class="n">csi</span><span class="o">.</span><span class="n">azure</span><span class="o">.</span><span class="n">com</span>
    <span class="n">readOnly</span><span class="p">:</span> <span class="n">false</span>
    <span class="n">volumeHandle</span><span class="p">:</span> <span class="n">trainingdata</span>  <span class="c1"># make sure this volumeid is unique in the cluster</span>
    <span class="n">volumeAttributes</span><span class="p">:</span>
      <span class="n">containerName</span><span class="p">:</span> <span class="n">gpt2onnx</span> <span class="c1"># Modify if changed in Notebook</span>
    <span class="n">nodeStageSecretRef</span><span class="p">:</span>
      <span class="n">name</span><span class="p">:</span> <span class="n">azure</span><span class="o">-</span><span class="n">blobsecret</span>
      <span class="n">namespace</span><span class="p">:</span> <span class="n">default</span>
  <span class="n">mountOptions</span><span class="p">:</span>         <span class="c1"># Use same user id that is used by POD security context</span>
    <span class="o">-</span> <span class="o">-</span><span class="n">o</span> <span class="n">uid</span><span class="o">=</span><span class="mi">8888</span>
    <span class="o">-</span> <span class="o">-</span><span class="n">o</span> <span class="n">allow_other</span>
<span class="o">---</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">PersistentVolumeClaim</span>
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">pvc</span><span class="o">-</span><span class="n">gpt2blob</span>

<span class="n">spec</span><span class="p">:</span>
  <span class="n">accessModes</span><span class="p">:</span>
    <span class="o">-</span> <span class="n">ReadWriteMany</span>
  <span class="n">resources</span><span class="p">:</span>
    <span class="n">requests</span><span class="p">:</span>
      <span class="n">storage</span><span class="p">:</span> <span class="mi">10</span><span class="n">Gi</span>
  <span class="n">volumeName</span><span class="p">:</span> <span class="n">pv</span><span class="o">-</span><span class="n">gpt2blob</span>
  <span class="n">storageClassName</span><span class="p">:</span> <span class="s2">""</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w">  </span>azure-blobfuse-pv.yaml
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
persistentvolume/pv-gptblob configured
persistentvolumeclaim/pvc-gptblob unchanged
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Verify PVC is bound</span>
<span class="o">!</span>kubectl<span class="w"> </span>get<span class="w"> </span>pv,pvc
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
NAME                           CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                  STORAGECLASS   REASON   AGE
persistentvolume/pv-gpt2blob   10Gi       RWX            Retain           Bound    default/pvc-gpt2blob                           4h54m

NAME                                 STATUS   VOLUME        CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/pvc-gpt2blob   Bound    pv-gpt2blob   10Gi       RWX                           4h54m
</pre></div></div>
</div>
<section id="Run-Seldon-in-your-kubernetes-cluster">
<h3 id="Run-Seldon-in-your-kubernetes-cluster">Run Seldon in your kubernetes cluster<a class="headerlink" href="#Run-Seldon-in-your-kubernetes-cluster" title="Permalink to this heading">¬∂</a></h3>
<p>Follow the <a class="reference external" href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html">Seldon-Core Setup notebook</a> to Setup a cluster with Istio Ingress and install Seldon Core</p>
</section>
<section id="Deploy-your-model-with-Seldon-pre-packaged-Triton-server">
<h3 id="Deploy-your-model-with-Seldon-pre-packaged-Triton-server">Deploy your model with Seldon pre-packaged Triton server<a class="headerlink" href="#Deploy-your-model-with-Seldon-pre-packaged-Triton-server" title="Permalink to this heading">¬∂</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> gpt2-deploy.yaml
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">machinelearning</span><span class="o">.</span><span class="n">seldon</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">v1alpha2</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">SeldonDeployment</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">gpt2gpu</span>
<span class="n">spec</span><span class="p">:</span>
  <span class="n">annotations</span><span class="p">:</span>
    <span class="n">prometheus</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">port</span><span class="p">:</span> <span class="s2">"8002"</span>           <span class="c1"># we will explain below in Monitoring section</span>
    <span class="n">prometheus</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">path</span><span class="p">:</span> <span class="s2">"/metrics"</span>
  <span class="n">predictors</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">componentSpecs</span><span class="p">:</span>
    <span class="o">-</span> <span class="n">spec</span><span class="p">:</span>
        <span class="n">containers</span><span class="p">:</span>
        <span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">gpt2</span>
          <span class="n">resources</span><span class="p">:</span>
            <span class="n">requests</span><span class="p">:</span>
              <span class="n">memory</span><span class="p">:</span> <span class="mi">2</span><span class="n">Gi</span>
              <span class="n">cpu</span><span class="p">:</span> <span class="mi">2</span>
              <span class="n">nvidia</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gpu</span><span class="p">:</span> <span class="mi">1</span>
            <span class="n">limits</span><span class="p">:</span>
              <span class="n">memory</span><span class="p">:</span> <span class="mi">4</span><span class="n">Gi</span>
              <span class="n">cpu</span><span class="p">:</span> <span class="mi">4</span>
              <span class="n">nvidia</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gpu</span><span class="p">:</span> <span class="mi">1</span>
         <span class="n">tolerations</span><span class="p">:</span>
          <span class="o">-</span> <span class="n">key</span><span class="p">:</span> <span class="s2">"nvidia.com"</span>          <span class="c1"># to be able to run  in GPU Nodepool</span>
            <span class="n">operator</span><span class="p">:</span> <span class="s2">"Equal"</span>
            <span class="n">value</span><span class="p">:</span> <span class="s2">"gpu"</span>
            <span class="n">effect</span><span class="p">:</span> <span class="s2">"NoSchedule"</span>
    <span class="n">graph</span><span class="p">:</span>
      <span class="n">implementation</span><span class="p">:</span> <span class="n">TRITON_SERVER</span>
      <span class="n">logger</span><span class="p">:</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">all</span>
      <span class="n">modelUri</span><span class="p">:</span> <span class="n">pvc</span><span class="p">:</span><span class="o">//</span><span class="n">pvc</span><span class="o">-</span><span class="n">gpt2blob</span><span class="o">/</span>
      <span class="n">name</span><span class="p">:</span> <span class="n">gpt2</span>
      <span class="nb">type</span><span class="p">:</span> <span class="n">MODEL</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">default</span>
    <span class="n">replicas</span><span class="p">:</span> <span class="mi">1</span>
  <span class="n">protocol</span><span class="p">:</span> <span class="n">kfserving</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting gpt2-deploy.yaml
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>gpt2-deploy.yaml<span class="w"> </span>-n<span class="w"> </span>default
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
seldondeployment.machinelearning.seldon.io/gpt2 created
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>rollout<span class="w"> </span>status<span class="w"> </span>deploy/<span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>deploy<span class="w"> </span>-l<span class="w"> </span>seldon-deployment-id<span class="o">=</span>gpt2gpu<span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="k">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
deployment "gpt2gpu-default-0-gpt2" successfully rolled out
</pre></div></div>
</div>
<section id="Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)">
<h4 id="Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)">Interact with the model: get model metadata (a ‚Äútest‚Äù request to make sure our model is available and loaded correctly)<a class="headerlink" href="#Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)" title="Permalink to this heading">¬∂</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ingress_ip</span> <span class="o">=</span> <span class="o">!(</span>kubectl<span class="w"> </span>get<span class="w"> </span>svc<span class="w"> </span>--namespace<span class="w"> </span>istio-system<span class="w"> </span>istio-ingressgateway<span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="o">)</span>
<span class="n">ingress_ip</span> <span class="o">=</span> <span class="n">ingress_ip</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="o">!</span>curl<span class="w"> </span>-v<span class="w"> </span>http://<span class="o">{</span>ingress_ip<span class="o">}</span>:80/seldon/default/gpt2gpu/v2/models/gpt2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
*   Trying 20.75.117.145:80...
* TCP_NODELAY set
* Connected to 20.75.117.145 (20.75.117.145) port 80 (#0)





* Mark bundle as not supporting multiuse












* Connection #0 to host 20.75.117.145 left intact
{"name":"gpt2","versions":["1"],"platform":"onnxruntime_onnx","inputs":[{"name":"input_ids:0","datatype":"INT32","shape":[-1,-1]},{"name":"attention_mask:0","datatype":"INT32","shape":[-1,-1]}],"outputs":[{"name":"past_key_values","datatype":"FP32","shape":[12,2,-1,12,-1,64]},{"name":"logits","datatype":"FP32","shape":[-1,-1,50257]}]}
</pre></div></div>
</div>
</section>
</section>
<section id="Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach">
<h3 id="Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach">Run prediction test: generate a sentence completion using GPT2 model - Greedy approach<a class="headerlink" href="#Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach" title="Permalink to this heading">¬∂</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">http</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="s2">"I love Artificial Intelligence"</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_gen_len</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">gen_sentence</span> <span class="o">=</span> <span class="n">input_text</span>
<span class="k">while</span> <span class="n">count</span> <span class="o">&lt;</span> <span class="n">max_gen_len</span><span class="p">:</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">gen_sentence</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"tf"</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"inputs"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"input_ids:0"</span><span class="p">,</span>
                <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
                <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
                <span class="s2">"data"</span><span class="p">:</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"attention_mask:0"</span><span class="p">,</span>
                <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
                <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
                <span class="s2">"data"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
            <span class="p">},</span>
        <span class="p">]</span>
    <span class="p">}</span>

    <span class="n">tfserving_url</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">"http://"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ingress_ip</span><span class="p">)</span> <span class="o">+</span> <span class="s2">"/seldon/default/gpt2gpu/v2/models/gpt2/infer"</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"sending request to </span><span class="si">{</span><span class="n">tfserving_url</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">tfserving_url</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span> <span class="k">as</span> <span class="n">ret</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>

    <span class="c1"># extract logits</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">"outputs"</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s2">"data"</span><span class="p">])</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">"outputs"</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s2">"shape"</span><span class="p">])</span>

    <span class="c1"># take the best next token probability of the last token of input ( greedy approach)</span>
    <span class="n">next_token</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">next_token_str</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
        <span class="n">next_token</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">gen_sentence</span> <span class="o">+=</span> <span class="s2">" "</span> <span class="o">+</span> <span class="n">next_token_str</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sentence: </span><span class="si">{</span><span class="n">gen_sentence</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="se">\n</span><span class="s2">Output: </span><span class="si">{</span><span class="n">gen_sentence</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence .
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence . I
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence . I love
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence . I love the
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence . I love the way
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence . I love the way it
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence . I love the way it 's
sending request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
Sentence: I love Artificial Intelligence . I love the way it 's designed
Input: I love Artificial Intelligence
Output: I love Artificial Intelligence . I love the way it 's designed
</pre></div></div>
</div>
</section>
</section>
<section id="Configure-Model-Monitoring-with-Azure-Monitor">
<h2 id="Configure-Model-Monitoring-with-Azure-Monitor">Configure Model Monitoring with Azure Monitor<a class="headerlink" href="#Configure-Model-Monitoring-with-Azure-Monitor" title="Permalink to this heading">¬∂</a></h2>
<p>The Azure Monitor Containers Insights provides functionality to allow collecting data from any Prometheus endpoints. It removes the need to install and operate Prometheus server and manage the monitoring data as Azure Monitor provides centralized point for collecting, displaying and alerting on monitoring data. To turn on Azure Monitor Container Insights follow steps described <a class="reference external" href="https://docs.microsoft.com/en-us/azure/azure-monitor/containers/container-insights-onboard">here</a> and you should
that you have an ‚Äúomsagent‚Äù pod running.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>omsagent
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
omsagent-27lk7                                1/1     Running   3          12d
omsagent-7q49d                                1/1     Running   3          12d
omsagent-9slf6                                1/1     Running   3          12d
omsagent-kzbkr                                1/1     Running   3          12d
omsagent-q85hk                                1/1     Running   3          12d
omsagent-rs-5976fbdc8b-rgxs4                  1/1     Running   0          8d
omsagent-tpkq2                                1/1     Running   3          12d
</pre></div></div>
</div>
<section id="Configure-Prometheus-Metrics-scraping">
<h3 id="Configure-Prometheus-Metrics-scraping">Configure Prometheus Metrics scraping<a class="headerlink" href="#Configure-Prometheus-Metrics-scraping" title="Permalink to this heading">¬∂</a></h3>
<p>Once <code class="docutils literal notranslate"><span class="pre">omsagent</span></code> is running we need to configure it to collect metrics from Prometheus endpoints. Azure Monitor Containers Insights allows configuration to be applied on a cluster or node-wide scope and configure endpoints for monitoring on one of the following ways: - Provide an array of URLs - Provide an Array of Kubernetes services - Enable monitoring of any pods with Prometheus annotations For more details on how to configure the scraping endpoints and query collected data refer to <a class="reference external" href="https://docs.microsoft.com/en-us/azure/azure-monitor/containers/container-insights-prometheus-integration">MS Docs
on Configure scraping of Prometheus metrics with Container insights</a></p>
<p>Our deployed model metrics are availble from couple infrasture layers - <a class="reference external" href="https://docs.seldon.io/projects/seldon-core/en/latest/analytics/analytics.html">Seldon model orchestrator metrics</a> and <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/metrics.md">Nvidia Triton Server Metrics</a>. To enable scraping for both endpoints we updated Microsoft provided default <code class="docutils literal notranslate"><span class="pre">ConfigMap</span></code> that configures <code class="docutils literal notranslate"><span class="pre">omsagent</span></code> <a class="reference external" href="./azure-metrics-cm.yaml">azure-metrics-cm.yaml</a>: - <strong>Triton Server:</strong>
update <code class="docutils literal notranslate"><span class="pre">monitor_kubernetes_pods</span> <span class="pre">=</span> <span class="pre">true</span></code> to enable scrapting for Pods with <code class="docutils literal notranslate"><span class="pre">prometheus.io</span></code> annotations In SeldonDeployment shown above <code class="docutils literal notranslate"><span class="pre">prometheus.io/path</span></code> and <code class="docutils literal notranslate"><span class="pre">prometheus.io/port</span></code> point to default Triton metrics endpoint - <strong>Seldon Orchestrator:</strong> add our deployed model seldon service endpoint to list of Kubernetes services to be scraped: <code class="docutils literal notranslate"><span class="pre">yaml</span>¬†¬†¬†¬† <span class="pre">kubernetes_services</span> <span class="pre">=</span> <span class="pre">["http://gpt2gpu-default.default:8000/prometheus"]</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>azure-metrics-cm.yaml
</pre></div>
</div>
</div>
</section>
</section>
<section id="Query-and-Visualize-collected-data">
<h2 id="Query-and-Visualize-collected-data">Query and Visualize collected data<a class="headerlink" href="#Query-and-Visualize-collected-data" title="Permalink to this heading">¬∂</a></h2>
<p>Collected metrics are available in Logs blade of Azure Monitor in a table <strong>InsightsMetrics</strong>, you could see all metrics gathered by running query</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">InsightsMetrics</span>
<span class="l l-Scalar l-Scalar-Plain">| where Namespace == "prometheus"</span>
</pre></div>
</div>
<p>To get Model Inference Requests per minute from Seldon Metrics run the following query and pin it to Dashboard or add to Azure Monitor Workbook:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">InsightsMetrics</span>
<span class="l l-Scalar l-Scalar-Plain">| where Namespace == "prometheus"</span>
<span class="l l-Scalar l-Scalar-Plain">| where Name == "seldon_api_executor_server_requests_seconds_count"</span>
<span class="l l-Scalar l-Scalar-Plain">| extend Model = parse_json(Tags).deployment_name</span>
<span class="l l-Scalar l-Scalar-Plain">| where parse_json(Tags).service == "predictions"</span>
<span class="l l-Scalar l-Scalar-Plain">| order by TimeGenerated asc</span>
<span class="l l-Scalar l-Scalar-Plain">| extend RequestsPerMin = Val - prev(Val,1)</span>
<span class="l l-Scalar l-Scalar-Plain">| project TimeGenerated, RequestsPerMin</span>
<span class="l l-Scalar l-Scalar-Plain">| render areachart</span>
</pre></div>
</div>
<p>To get Inference Duration from Triton Metrics:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">InsightsMetrics</span>
<span class="l l-Scalar l-Scalar-Plain">| where Namespace == "prometheus"</span>
<span class="l l-Scalar l-Scalar-Plain">| where Name in ("nv_inference_request_duration_us")</span>
<span class="l l-Scalar l-Scalar-Plain">| order by TimeGenerated asc</span>
<span class="l l-Scalar l-Scalar-Plain">| extend QueueDurationSec = (Val - prev(Val, 1)) / 1000</span>
<span class="l l-Scalar l-Scalar-Plain">| project TimeGenerated, Name, QueueDurationSec</span>
<span class="l l-Scalar l-Scalar-Plain">| render areachart</span>
</pre></div>
</div>
<p>Here is example dashboard we created using queries above</p>
<p><img alt="dashboard" src="../_images/azuredashboard.jpg"/></p>
<section id="Run-Load-Test-/-Performance-Test-using-vegeta">
<h3 id="Run-Load-Test-/-Performance-Test-using-vegeta">Run Load Test / Performance Test using vegeta<a class="headerlink" href="#Run-Load-Test-/-Performance-Test-using-vegeta" title="Permalink to this heading">¬∂</a></h3>
<section id="Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation">
<h4 id="Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation">Install vegeta, for more details take a look in <a class="reference external" href="https://github.com/tsenart/vegeta#install">vegeta</a> official documentation<a class="headerlink" href="#Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation" title="Permalink to this heading">¬∂</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>https://github.com/tsenart/vegeta/releases/download/v12.8.3/vegeta-12.8.3-linux-arm64.tar.gz
<span class="o">!</span>tar<span class="w"> </span>-zxvf<span class="w"> </span>vegeta-12.8.3-linux-arm64.tar.gz
<span class="o">!</span>chmod<span class="w"> </span>+x<span class="w"> </span>vegeta
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--2021-05-28 18:40:27--  https://github.com/tsenart/vegeta/releases/download/v12.8.3/vegeta-12.8.3-linux-arm64.tar.gz
Resolving github.com (github.com)... 140.82.114.4
Connecting to github.com (github.com)|140.82.114.4|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github-releases.githubusercontent.com/12080551/ba68d580-6e90-11ea-8bd2-3f43f5c08b3c?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210528%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20210528T224014Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=2efad77c33f1663eea17d366986bfad1cd081128d45012c9b6e6659c4c80eff6&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=12080551&amp;response-content-disposition=attachment%3B%20filename%3Dvegeta-12.8.3-linux-arm64.tar.gz&amp;response-content-type=application%2Foctet-stream [following]
--2021-05-28 18:40:27--  https://github-releases.githubusercontent.com/12080551/ba68d580-6e90-11ea-8bd2-3f43f5c08b3c?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210528%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20210528T224014Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=2efad77c33f1663eea17d366986bfad1cd081128d45012c9b6e6659c4c80eff6&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=12080551&amp;response-content-disposition=attachment%3B%20filename%3Dvegeta-12.8.3-linux-arm64.tar.gz&amp;response-content-type=application%2Foctet-stream
Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...
Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3281900 (3.1M) [application/octet-stream]
Saving to: ‚Äòvegeta-12.8.3-linux-arm64.tar.gz.2‚Äô

vegeta-12.8.3-linux 100%[===================&gt;]   3.13M  2.95MB/s    in 1.1s

2021-05-28 18:40:28 (2.95 MB/s) - ‚Äòvegeta-12.8.3-linux-arm64.tar.gz.2‚Äô saved [3281900/3281900]

CHANGELOG
LICENSE
README.md
vegeta
</pre></div></div>
</div>
</section>
<section id="Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure">
<h4 id="Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure">Generate vegeta <a class="reference external" href="https://github.com/tsenart/vegeta#-targets">target file</a> contains ‚Äúpost‚Äù cmd with payload in the requiered structure<a class="headerlink" href="#Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure" title="Permalink to this heading">¬∂</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">subprocess</span> <span class="kn">import</span> <span class="n">PIPE</span><span class="p">,</span> <span class="n">Popen</span><span class="p">,</span> <span class="n">run</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">TFGPT2LMHeadModel</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="s2">"I enjoy working in Seldon"</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"tf"</span><span class="p">)</span>
<span class="n">shape</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
<span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"inputs"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"input_ids:0"</span><span class="p">,</span>
            <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
            <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
            <span class="s2">"data"</span><span class="p">:</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"attention_mask:0"</span><span class="p">,</span>
            <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
            <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
            <span class="s2">"data"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="p">},</span>
    <span class="p">]</span>
<span class="p">}</span>
<span class="n">tfserving_url</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">"http://"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ingress_ip</span><span class="p">)</span> <span class="o">+</span> <span class="s2">"/seldon/default/gpt2gpu/v2/models/gpt2/infer"</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"preparing request to </span><span class="si">{</span><span class="n">tfserving_url</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">cmd</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"method"</span><span class="p">:</span> <span class="s2">"POST"</span><span class="p">,</span>
    <span class="s2">"header"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"Content-Type"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"application/json"</span><span class="p">]},</span>
    <span class="s2">"url"</span><span class="p">:</span> <span class="n">tfserving_url</span><span class="p">,</span>
    <span class="s2">"body"</span><span class="p">:</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="nb">bytes</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">),</span> <span class="s2">"utf-8"</span><span class="p">))</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"vegeta_target.json"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
preparing request to http://20.75.117.145/seldon/default/gpt2gpu/v2/models/gpt2/infer
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>./vegeta<span class="w"> </span>attack<span class="w"> </span>-targets<span class="o">=</span>vegeta_target.json<span class="w"> </span>-rate<span class="o">=</span><span class="m">1</span><span class="w"> </span>-duration<span class="o">=</span>60s<span class="w"> </span>-format<span class="o">=</span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span>./vegeta<span class="w"> </span>report<span class="w"> </span>-type<span class="o">=</span>text
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requests      [total, rate, throughput]         60, 1.02, 0.95
Duration      [total, attack, wait]             1m3s, 58.994s, 4.445s
Latencies     [min, mean, 50, 90, 95, 99, max]  1.45s, 4.003s, 3.983s, 5.249s, 6.329s, 7.876s, 7.97s
Bytes In      [total, mean]                     475803960, 7930066.00
Bytes Out     [total, mean]                     13140, 219.00
Success       [ratio]                           100.00%
Status Codes  [code:count]                      200:60
Error Set:
</pre></div></div>
</div>
</section>
</section>
<section id="Clean-up">
<h3 id="Clean-up">Clean-up<a class="headerlink" href="#Clean-up" title="Permalink to this heading">¬∂</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>delete<span class="w"> </span>-f<span class="w"> </span>gpt2-deploy.yaml<span class="w"> </span>-n<span class="w"> </span>default
</pre></div>
</div>
</div>
</section>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="alibaba_ack_deep_mnist.html" title="Alibaba Cloud Container Service for Kubernetes (ACK) Deep MNIST Example"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> "Previous" </span> Alibaba Cloud Container Service for Kubernetes (ACK) Deep MNIST Example </span>
              </div>
            </a>
          
          
            <a href="triton_gpt2_example_azure_setup.html" title="Setup Azure Kubernetes Infrastructure"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> "Next" </span> Setup Azure Kubernetes Infrastructure </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2024, Seldon Technologies Ltd.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>