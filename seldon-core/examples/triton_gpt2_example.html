<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-54780881-2"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'UA-54780881-2');
</script>
  
  
    <title>Pretrained GPT2 Model Deployment Example &#8212; seldon-core  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=83e35b93" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css?v=79c92029" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/rtd_sphinx_search.min.css?v=e72958e9" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css?v=15a8f09d" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/rtd_search_config.js?v=b0596c34"></script>
    <script src="../_static/js/rtd_sphinx_search.min.js?v=43f26ba4"></script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="NVIDIA TensorRT MNIST Example with Triton Inference Server" href="tensorrt.html" />
    <link rel="prev" title="Runtime Metrics / Tags Example" href="runtime_metrics_tags.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=teal>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#examples/triton_gpt2_example" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="seldon-core  documentation"
           class="md-header-nav__button md-logo">
          
            &nbsp;
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Seldon Core Documentation</span>
          <span class="md-header-nav__topic"> Pretrained GPT2 Model Deployment Example </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/SeldonIO/seldon-core/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Seldon Core
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="/" class="md-tabs__link">ğŸš€ Our Other Projects & Products:</a></li>
            
            <li class="md-tabs__item"><a href="https://docs.seldon.io/projects/alibi/en/stable/" class="md-tabs__link">Alibi Explain</a></li>
            
            <li class="md-tabs__item"><a href="https://docs.seldon.io/projects/alibi-detect/en/stable/" class="md-tabs__link">Alibi Detect</a></li>
            
            <li class="md-tabs__item"><a href="https://mlserver.readthedocs.io/en/latest/" class="md-tabs__link">MLServer</a></li>
            
            <li class="md-tabs__item"><a href="https://tempo.readthedocs.io/en/latest/" class="md-tabs__link">Tempo SDK</a></li>
            
            <li class="md-tabs__item"><a href="https://deploy.seldon.io" class="md-tabs__link">Seldon Enterprise Platform</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/SeldonIO/seldon-deploy-sdk#seldon-deploy-sdk" class="md-tabs__link">Seldon Enterprise Platform SDK</a></li>
          <li class="md-tabs__item"><a href="../nav/tutorials.html" class="md-tabs__link">æ•™ç¨‹</a></li>
          <li class="md-tabs__item"><a href="notebooks.html" class="md-tabs__link">ç¬”è®°æœ¬</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="seldon-core documentation" class="md-nav__button md-logo">
      
        <img src="../_static/" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../index.html"
       title="seldon-core documentation">Seldon Core Documentation</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/SeldonIO/seldon-core/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Seldon Core
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="../nav/getting-started.html" class="md-nav__link">å¼€å§‹</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/concepts.html" class="md-nav__link">æ¦‚å¿µ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/configuration.html" class="md-nav__link">é…ç½®</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/tutorials.html" class="md-nav__link">æ•™ç¨‹</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="notebooks.html" class="md-nav__link">ç¬”è®°æœ¬</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#seldon-core" class="md-nav__link">Seldon Core è®¾ç½®</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id2" class="md-nav__link">é¢„åŒ…è£…æ¨ç†æœåŠ¡ç¤ºä¾‹</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#python" class="md-nav__link">Python è¯­è¨€å°è£…ç¤ºä¾‹</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id3" class="md-nav__link">ä¸“é—¨çš„æ¡†æ¶ç¤ºä¾‹</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id4" class="md-nav__link">å­µåŒ–é¡¹ç›®ç¤ºä¾‹</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id5" class="md-nav__link">åŸºäºäº‘çš„åŸºç¡€ç¤ºä¾‹</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id6" class="md-nav__link">é«˜çº§æœºå™¨å­¦ä¹ ç›‘æ§</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id7" class="md-nav__link">Seldon Core æ‰¹å¤„ç†</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#mlops" class="md-nav__link">MLOps: æ‰©å±•ã€ç›‘æ§å’Œå¯è§‚å¯Ÿæ€§</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id8" class="md-nav__link">ç”Ÿäº§é…ç½®åŠå®ç°</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#ab" class="md-nav__link">AB æµ‹è¯•åŠæ¸è¿›å¼éƒ¨ç½²</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id9" class="md-nav__link">å¤æ‚å›¾ç¤ºä¾‹</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id10" class="md-nav__link">å…¥å£</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id11" class="md-nav__link">åŸºç¡€è®¾æ–½</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id12" class="md-nav__link">åŸºå‡†æµ‹è¯•å’Œè´Ÿè½½æµ‹è¯•</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="notebooks.html#id13" class="md-nav__link">å‡çº§ç¤ºä¾‹</a>
      
    
    </li></ul>
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/reference.html" class="md-nav__link">å‚è€ƒ</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../nav/contributing.html" class="md-nav__link">è´¡çŒ®</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">"Contents"</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#examples-triton-gpt2-example--page-root" class="md-nav__link">Pretrained GPT2 Model Deployment Example</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Steps:" class="md-nav__link">Steps:</a>
        </li>
        <li class="md-nav__item"><a href="#Basic-requirements" class="md-nav__link">Basic requirements</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally" class="md-nav__link">Export HuggingFace TFGPT2LMHeadModel pre-trained model and save it locally</a>
        </li>
        <li class="md-nav__item"><a href="#Convert-the-TensorFlow-saved-model-to-ONNX" class="md-nav__link">Convert the TensorFlow saved model to ONNX</a>
        </li>
        <li class="md-nav__item"><a href="#Copy-your-model-to-a-local-MinIo" class="md-nav__link">Copy your model to a local MinIo</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Setup-MinIo" class="md-nav__link">Setup MinIo</a>
        </li>
        <li class="md-nav__item"><a href="#Create-a-Bucket-and-store-your-model" class="md-nav__link">Create a Bucket and store your model</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Run-Seldon-in-your-kubernetes-cluster" class="md-nav__link">Run Seldon in your kubernetes cluster</a>
        </li>
        <li class="md-nav__item"><a href="#Deploy-your-model-with-Seldon-pre-packaged-Triton-server" class="md-nav__link">Deploy your model with Seldon pre-packaged Triton server</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)" class="md-nav__link">Interact with the model: get model metadata (a â€œtestâ€ request to make sure our model is available and loaded correctly)</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach" class="md-nav__link">Run prediction test: generate a sentence completion using GPT2 model - Greedy approach</a>
        </li>
        <li class="md-nav__item"><a href="#Run-Load-Test-/-Performance-Test-using-vegeta" class="md-nav__link">Run Load Test / Performance Test using vegeta</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation" class="md-nav__link">Install vegeta, for more details take a look in vegeta official documentation</a>
        </li>
        <li class="md-nav__item"><a href="#Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure" class="md-nav__link">Generate vegeta target file contains â€œpostâ€ cmd with payload in the requiered structure</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Clean-up" class="md-nav__link">Clean-up</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../_sources/examples/triton_gpt2_example.nblink.txt">Show Source</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <div class="admonition note">
<p>This page was generated from <a class="reference external" href="https://github.com/SeldonIO/seldon-core/blob/e665e4994eabf83fb43c68a5f85e96d5c45e91b5/examples/triton_gpt2/README.ipynb">examples/triton_gpt2/README.ipynb</a>.</p>
</div>
<section id="Pretrained-GPT2-Model-Deployment-Example">
<h1 id="examples-triton-gpt2-example--page-root">Pretrained GPT2 Model Deployment Example<a class="headerlink" href="#examples-triton-gpt2-example--page-root" title="Permalink to this heading">Â¶</a></h1>
<p>In this notebook, we will run an example of text generation using GPT2 model exported from HuggingFace and deployed with Seldonâ€™s Triton pre-packed server. the example also covers converting the model to ONNX format. The implemented example below is of the Greedy approach for the next token prediction. more info: <a class="reference external" href="https://huggingface.co/transformers/model_doc/gpt2.html?highlight=gpt2">https://huggingface.co/transformers/model_doc/gpt2.html?highlight=gpt2</a></p>
<p>After we have the module deployed to Kubernetes, we will run a simple load test to evaluate the module inference performance.</p>
<section id="Steps:">
<h2 id="Steps:">Steps:<a class="headerlink" href="#Steps:" title="Permalink to this heading">Â¶</a></h2>
<ol class="arabic simple">
<li><p>Download pretrained GPT2 model from hugging face</p></li>
<li><p>Convert the model to ONNX</p></li>
<li><p>Store it in MinIo bucket</p></li>
<li><p>Setup Seldon-Core in your kubernetes cluster</p></li>
<li><p>Deploy the ONNX model with Seldonâ€™s prepackaged Triton server.</p></li>
<li><p>Interact with the model, run a greedy alg example (generate sentence completion)</p></li>
<li><p>Run load test using vegeta</p></li>
<li><p>Clean-up</p></li>
</ol>
</section>
<section id="Basic-requirements">
<h2 id="Basic-requirements">Basic requirements<a class="headerlink" href="#Basic-requirements" title="Permalink to this heading">Â¶</a></h2>
<ul class="simple">
<li><p>Helm v3.0.0+</p></li>
<li><p>A Kubernetes cluster running v1.13 or above (minkube / docker-for-windows work well if enough RAM)</p></li>
<li><p>kubectl v1.14+</p></li>
<li><p>Python 3.6+</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> requirements.txt
<span class="n">transformers</span><span class="o">==</span><span class="mf">4.5.1</span>
<span class="n">torch</span><span class="o">==</span><span class="mf">1.8.1</span>
<span class="n">tokenizers</span><span class="o">&lt;</span><span class="mf">0.11</span><span class="p">,</span><span class="o">&gt;=</span><span class="mf">0.10.1</span>
<span class="n">tensorflow</span><span class="o">==</span><span class="mf">2.4.1</span>
<span class="n">tf2onnx</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--trusted-host<span class="o">=</span>pypi.python.org<span class="w"> </span>--trusted-host<span class="o">=</span>pypi.org<span class="w"> </span>--trusted-host<span class="o">=</span>files.pythonhosted.org<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</div>
<section id="Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally">
<h3 id="Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally">Export HuggingFace TFGPT2LMHeadModel pre-trained model and save it locally<a class="headerlink" href="#Export-HuggingFace-TFGPT2LMHeadModel-pre-trained-model-and-save-it-locally" title="Permalink to this heading">Â¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">TFGPT2LMHeadModel</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TFGPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">"gpt2"</span><span class="p">,</span> <span class="n">from_pt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">"./tfgpt2model"</span><span class="p">,</span> <span class="n">saved_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Convert-the-TensorFlow-saved-model-to-ONNX">
<h3 id="Convert-the-TensorFlow-saved-model-to-ONNX">Convert the TensorFlow saved model to ONNX<a class="headerlink" href="#Convert-the-TensorFlow-saved-model-to-ONNX" title="Permalink to this heading">Â¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python<span class="w"> </span>-m<span class="w"> </span>tf2onnx.convert<span class="w"> </span>--saved-model<span class="w"> </span>./tfgpt2model/saved_model/1<span class="w"> </span>--opset<span class="w"> </span><span class="m">11</span><span class="w">  </span>--output<span class="w"> </span>model.onnx
</pre></div>
</div>
</div>
</section>
<section id="Copy-your-model-to-a-local-MinIo">
<h3 id="Copy-your-model-to-a-local-MinIo">Copy your model to a local MinIo<a class="headerlink" href="#Copy-your-model-to-a-local-MinIo" title="Permalink to this heading">Â¶</a></h3>
<section id="Setup-MinIo">
<h4 id="Setup-MinIo">Setup MinIo<a class="headerlink" href="#Setup-MinIo" title="Permalink to this heading">Â¶</a></h4>
<p>Use the provided <a class="reference external" href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/minio_setup.html">notebook</a> to install MinIo in your cluster and configure <code class="docutils literal notranslate"><span class="pre">mc</span></code> CLI tool. Instructions also <a class="reference external" href="https://docs.min.io/docs/minio-client-quickstart-guide.html">online</a>.</p>
<p>â€“ Note: You can use your prefer remote storage server (google/ AWS etc.)</p>
</section>
<section id="Create-a-Bucket-and-store-your-model">
<h4 id="Create-a-Bucket-and-store-your-model">Create a Bucket and store your model<a class="headerlink" href="#Create-a-Bucket-and-store-your-model" title="Permalink to this heading">Â¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>mc<span class="w"> </span>mb<span class="w"> </span>minio-seldon/onnx-gpt2<span class="w"> </span>-p
<span class="o">!</span>mc<span class="w"> </span>cp<span class="w"> </span>./model.onnx<span class="w"> </span>minio-seldon/onnx-gpt2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-green-intense-fg ansi-bold">Bucket created successfully `minio-seldon/onnx-gpt2`.</span>
./model.onnx:  622.37 MiB / 622.37 MiB â”ƒâ–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”ƒ 127.01 MiB/s 4s
</pre></div></div>
</div>
</section>
</section>
<section id="Run-Seldon-in-your-kubernetes-cluster">
<h3 id="Run-Seldon-in-your-kubernetes-cluster">Run Seldon in your kubernetes cluster<a class="headerlink" href="#Run-Seldon-in-your-kubernetes-cluster" title="Permalink to this heading">Â¶</a></h3>
<p>Follow the <a class="reference external" href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html">Seldon-Core Setup notebook</a> to Setup a cluster with Ambassador Ingress or Istio and install Seldon Core</p>
</section>
<section id="Deploy-your-model-with-Seldon-pre-packaged-Triton-server">
<h3 id="Deploy-your-model-with-Seldon-pre-packaged-Triton-server">Deploy your model with Seldon pre-packaged Triton server<a class="headerlink" href="#Deploy-your-model-with-Seldon-pre-packaged-Triton-server" title="Permalink to this heading">Â¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> secret.yaml

<span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">Secret</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">seldon</span><span class="o">-</span><span class="n">init</span><span class="o">-</span><span class="n">container</span><span class="o">-</span><span class="n">secret</span>
<span class="nb">type</span><span class="p">:</span> <span class="n">Opaque</span>
<span class="n">stringData</span><span class="p">:</span>
  <span class="n">RCLONE_CONFIG_S3_TYPE</span><span class="p">:</span> <span class="n">s3</span>
  <span class="n">RCLONE_CONFIG_S3_PROVIDER</span><span class="p">:</span> <span class="n">minio</span>
  <span class="n">RCLONE_CONFIG_S3_ENV_AUTH</span><span class="p">:</span> <span class="s2">"false"</span>
  <span class="n">RCLONE_CONFIG_S3_ACCESS_KEY_ID</span><span class="p">:</span> <span class="n">minioadmin</span>
  <span class="n">RCLONE_CONFIG_S3_SECRET_ACCESS_KEY</span><span class="p">:</span> <span class="n">minioadmin</span>
  <span class="n">RCLONE_CONFIG_S3_ENDPOINT</span><span class="p">:</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">minio</span><span class="o">.</span><span class="n">minio</span><span class="o">-</span><span class="n">system</span><span class="o">.</span><span class="n">svc</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">local</span><span class="p">:</span><span class="mi">9000</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting secret.yaml
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> gpt2-deploy.yaml
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">machinelearning</span><span class="o">.</span><span class="n">seldon</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">v1alpha2</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">SeldonDeployment</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">gpt2</span>
<span class="n">spec</span><span class="p">:</span>
  <span class="n">predictors</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">graph</span><span class="p">:</span>
      <span class="n">implementation</span><span class="p">:</span> <span class="n">TRITON_SERVER</span>
      <span class="n">logger</span><span class="p">:</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">all</span>
      <span class="n">modelUri</span><span class="p">:</span> <span class="n">s3</span><span class="p">:</span><span class="o">//</span><span class="n">onnx</span><span class="o">-</span><span class="n">gpt2</span>
      <span class="n">envSecretRefName</span><span class="p">:</span> <span class="n">seldon</span><span class="o">-</span><span class="n">init</span><span class="o">-</span><span class="n">container</span><span class="o">-</span><span class="n">secret</span>
      <span class="n">name</span><span class="p">:</span> <span class="n">gpt2</span>
      <span class="nb">type</span><span class="p">:</span> <span class="n">MODEL</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">default</span>
    <span class="n">replicas</span><span class="p">:</span> <span class="mi">1</span>
  <span class="n">protocol</span><span class="p">:</span> <span class="n">kfserving</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting gpt2-deploy.yaml
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>secret.yaml<span class="w"> </span>-n<span class="w"> </span>default
<span class="o">!</span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>gpt2-deploy.yaml<span class="w"> </span>-n<span class="w"> </span>default
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
secret/seldon-init-container-secret configured
seldondeployment.machinelearning.seldon.io/gpt2 created
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>rollout<span class="w"> </span>status<span class="w"> </span>deploy/<span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>deploy<span class="w"> </span>-l<span class="w"> </span>seldon-deployment-id<span class="o">=</span>gpt2<span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="k">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
deployment "gpt2-default-0-gpt2" successfully rolled out
</pre></div></div>
</div>
<section id="Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)">
<h4 id="Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)">Interact with the model: get model metadata (a â€œtestâ€ request to make sure our model is available and loaded correctly)<a class="headerlink" href="#Interact-with-the-model:-get-model-metadata-(a-%22test%22-request-to-make-sure-our-model-is-available-and-loaded-correctly)" title="Permalink to this heading">Â¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>curl<span class="w"> </span>-v<span class="w"> </span>http://localhost:80/seldon/default/gpt2/v2/models/gpt2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
*   Trying 127.0.0.1:80...
* TCP_NODELAY set
* Connected to localhost (127.0.0.1) port 80 (#0)
&gt; GET /seldon/default/gpt2/v2/models/gpt2 HTTP/1.1

&gt; Host: localhost

&gt; User-Agent: curl/7.68.0

&gt; Accept: */*

&gt;

* Mark bundle as not supporting multiuse
&lt; HTTP/1.1 200 OK

&lt; access-control-allow-headers: Accept, Accept-Encoding, Authorization, Content-Length, Content-Type, X-CSRF-Token

&lt; access-control-allow-methods: GET,OPTIONS

&lt; access-control-allow-origin: *

&lt; content-type: application/json

&lt; seldon-puid: 97dd6a08-3520-48f2-af34-7c32e5967c38

&lt; x-content-type-options: nosniff

&lt; date: Fri, 21 May 2021 14:26:22 GMT

&lt; content-length: 336

&lt; x-envoy-upstream-service-time: 3

&lt; server: istio-envoy

&lt;

* Connection #0 to host localhost left intact
{"name":"gpt2","versions":["1"],"platform":"onnxruntime_onnx","inputs":[{"name":"input_ids","datatype":"INT32","shape":[-1,-1]},{"name":"attention_mask","datatype":"INT32","shape":[-1,-1]}],"outputs":[{"name":"past_key_values","datatype":"FP32","shape":[12,2,-1,12,-1,64]},{"name":"logits","datatype":"FP32","shape":[-1,-1,50257]}]}
</pre></div></div>
</div>
</section>
</section>
<section id="Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach">
<h3 id="Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach">Run prediction test: generate a sentence completion using GPT2 model - Greedy approach<a class="headerlink" href="#Run-prediction-test:-generate-a-sentence-completion-using-GPT2-model---Greedy-approach" title="Permalink to this heading">Â¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="s2">"I enjoy working in Seldon"</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_gen_len</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">gen_sentence</span> <span class="o">=</span> <span class="n">input_text</span>
<span class="k">while</span> <span class="n">count</span> <span class="o">&lt;</span> <span class="n">max_gen_len</span><span class="p">:</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">gen_sentence</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"tf"</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"inputs"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"input_ids"</span><span class="p">,</span>
                <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
                <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
                <span class="s2">"data"</span><span class="p">:</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"attention_mask"</span><span class="p">,</span>
                <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
                <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
                <span class="s2">"data"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
            <span class="p">},</span>
        <span class="p">]</span>
    <span class="p">}</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="s2">"http://localhost:80/seldon/default/gpt2/v2/models/gpt2/infer"</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span>
    <span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">continue</span>

    <span class="c1"># extract logits</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">"outputs"</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s2">"data"</span><span class="p">])</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">"outputs"</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s2">"shape"</span><span class="p">])</span>

    <span class="c1"># take the best next token probability of the last token of input ( greedy approach)</span>
    <span class="n">next_token</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">next_token_str</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
        <span class="n">next_token</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">gen_sentence</span> <span class="o">+=</span> <span class="s2">" "</span> <span class="o">+</span> <span class="n">next_token_str</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="se">\n</span><span class="s2">Output: </span><span class="si">{</span><span class="n">gen_sentence</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Input: I enjoy working in Seldon
Output: I enjoy working in Seldon 's office , and I 'm glad to see that
</pre></div></div>
</div>
</section>
<section id="Run-Load-Test-/-Performance-Test-using-vegeta">
<h3 id="Run-Load-Test-/-Performance-Test-using-vegeta">Run Load Test / Performance Test using vegeta<a class="headerlink" href="#Run-Load-Test-/-Performance-Test-using-vegeta" title="Permalink to this heading">Â¶</a></h3>
<section id="Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation">
<h4 id="Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation">Install vegeta, for more details take a look in <a class="reference external" href="https://github.com/tsenart/vegeta#install">vegeta</a> official documentation<a class="headerlink" href="#Install-vegeta,-for-more-details-take-a-look-in-vegeta-official-documentation" title="Permalink to this heading">Â¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>https://github.com/tsenart/vegeta/releases/download/v12.8.3/vegeta-12.8.3-linux-amd64.tar.gz
<span class="o">!</span>tar<span class="w"> </span>-zxvf<span class="w"> </span>vegeta-12.8.3-linux-amd64.tar.gz
<span class="o">!</span>chmod<span class="w"> </span>+x<span class="w"> </span>vegeta
</pre></div>
</div>
</div>
</section>
<section id="Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure">
<h4 id="Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure">Generate vegeta <a class="reference external" href="https://github.com/tsenart/vegeta#-targets">target file</a> contains â€œpostâ€ cmd with payload in the requiered structure<a class="headerlink" href="#Generate-vegeta-target-file-contains-%22post%22-cmd-with-payload-in-the-requiered-structure" title="Permalink to this heading">Â¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">subprocess</span> <span class="kn">import</span> <span class="n">PIPE</span><span class="p">,</span> <span class="n">Popen</span><span class="p">,</span> <span class="n">run</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">TFGPT2LMHeadModel</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="s2">"I enjoy working in Seldon"</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"tf"</span><span class="p">)</span>
<span class="n">shape</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
<span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"inputs"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"input_ids"</span><span class="p">,</span>
            <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
            <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
            <span class="s2">"data"</span><span class="p">:</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"attention_mask"</span><span class="p">,</span>
            <span class="s2">"datatype"</span><span class="p">:</span> <span class="s2">"INT32"</span><span class="p">,</span>
            <span class="s2">"shape"</span><span class="p">:</span> <span class="n">shape</span><span class="p">,</span>
            <span class="s2">"data"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="p">},</span>
    <span class="p">]</span>
<span class="p">}</span>

<span class="n">cmd</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"method"</span><span class="p">:</span> <span class="s2">"POST"</span><span class="p">,</span>
    <span class="s2">"header"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"Content-Type"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"application/json"</span><span class="p">]},</span>
    <span class="s2">"url"</span><span class="p">:</span> <span class="s2">"http://localhost:80/seldon/default/gpt2/v2/models/gpt2/infer"</span><span class="p">,</span>
    <span class="s2">"body"</span><span class="p">:</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="nb">bytes</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">),</span> <span class="s2">"utf-8"</span><span class="p">))</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"vegeta_target.json"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>vegeta<span class="w"> </span>attack<span class="w"> </span>-targets<span class="o">=</span>vegeta_target.json<span class="w"> </span>-rate<span class="o">=</span><span class="m">1</span><span class="w"> </span>-duration<span class="o">=</span>60s<span class="w"> </span>-format<span class="o">=</span>json<span class="w"> </span><span class="p">|</span><span class="w"> </span>vegeta<span class="w"> </span>report<span class="w"> </span>-type<span class="o">=</span>text
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requests      [total, rate, throughput]         60, 1.02, 1.01
Duration      [total, attack, wait]             59.198s, 59s, 197.751ms
Latencies     [min, mean, 50, 90, 95, 99, max]  179.123ms, 280.177ms, 214.79ms, 325.753ms, 457.825ms, 1.936s, 2.009s
Bytes In      [total, mean]                     475783920, 7929732.00
Bytes Out     [total, mean]                     13140, 219.00
Success       [ratio]                           100.00%
Status Codes  [code:count]                      200:60
Error Set:
</pre></div></div>
</div>
</section>
</section>
<section id="Clean-up">
<h3 id="Clean-up">Clean-up<a class="headerlink" href="#Clean-up" title="Permalink to this heading">Â¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>kubectl<span class="w"> </span>delete<span class="w"> </span>-f<span class="w"> </span>gpt2-deploy.yaml<span class="w"> </span>-n<span class="w"> </span>default
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
seldondeployment.machinelearning.seldon.io "gpt2" deleted
</pre></div></div>
</div>
</section>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="runtime_metrics_tags.html" title="Runtime Metrics / Tags Example"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> "Previous" </span> Runtime Metrics / Tags Example </span>
              </div>
            </a>
          
          
            <a href="tensorrt.html" title="NVIDIA TensorRT MNIST Example with Triton Inference Server"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> "Next" </span> NVIDIA TensorRT MNIST Example with Triton Inference Server </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2024, Seldon Technologies Ltd.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>